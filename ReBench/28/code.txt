#[version = "0.0.5"]
def @main(%x0: Tensor[(1, 3, 224, 224), int8], %x1: Tensor[(1, 3, 224, 29), int8], %x2: Tensor[(1, 3, 224, 74), int8], %x3: Tensor[(1, 3, 224, 11), int8], %x4: Tensor[(3,), float32], %x5: Tensor[(3,), float32], %x6: Tensor[(3,), float32], %x7: Tensor[(3,), float32], %x8: Tensor[(3, 224), float32]) {
    %0 = qnn.dequantize(%x0, 2.0f, 0, axis=-1);
    %1 = abs(%0);
    %2 = qnn.quantize(%1, 2.0f, 0, out_dtype="int8", axis=-1);
    %3 = qnn.dequantize(%2, 2.0f, 0, axis=-1);
    %4 = squeeze(%3, axis=[0]);
    %5 = qnn.quantize(%4, 2.0f, 0, out_dtype="int8", axis=-1);
    %6 = qnn.dequantize(%2, 0.5f, 0, axis=-1);
    %7 = qnn.dequantize(%x1, 1.5f, 0, axis=-1);
    %8 = qnn.dequantize(%x2, 2.5f, 0, axis=-1);
    %9 = qnn.dequantize(%x3, 3.5f, 0, axis=-1);
    %10 = (%6, %7, %8, %9);
    %11 = concatenate(%10, axis=-1);
    %12 = qnn.quantize(%11, 3.5f, 0, out_dtype="int8", axis=-1);
    %13 = ones(shape=[1], dtype="float32");
    %14 = multiply(%13, %11);
    %15 = transpose(%3, axes=[0, 3, 1, 2]);
    %16 = layout_transform(%15, src_layout="NCHW", dst_layout="NCHW4c");
    %17 = nn.relu(%16);
    %18 = layout_transform(%17, src_layout="NCHW4c", dst_layout="NCHW");
    %19 = transpose(%18, axes=[0, 2, 3, 1]);
    %20 = cast(%4, dtype="bfloat16");
    %21 = clip(%20, a_min=-0.2f, a_max=0.4f);
    %22 = nn.batch_norm(%7, %x7, %x6, %x5, %x4, axis=1, epsilon=1e-05f, center=1, scale=1);
    %23 = %22.0;
    %24 = %22.0;
    %25 = add(%23, %24);
    %26 = ones_like(%x5);
    %27 = add(%x5, %26);
    %28 = ones_like(3.5f);
    %29 = add(3.5f, %28);
    %30 = cast(%4, dtype="int32");
    %31 = cast_like(%30, %x8);
    %32 = (%5, %12, %14, %19, %21, %25, %27, %29, %31);
    %32
}
