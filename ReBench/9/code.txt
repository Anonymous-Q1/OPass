#[version = "0.0.5"]
def @main(%x0: Tensor[(1, 3, 224, 224), int8], %x1: Tensor[(1, 3, 224, 224), int8], %x2: Tensor[(3, 3, 3, 3), float32], %x3: Tensor[(3, 3, 1, 1), float32], %x4: Tensor[(3, 3, 3, 3), float32], %x5: Tensor[(1, 3, 224, 89), int8], %x6: Tensor[(1, 3, 224, 32), int8], %x7: Tensor[(1, 3, 224, 4), int8], %x8: Tensor[(224,), float32], %x9: Tensor[(224,), float32], %x10: Tensor[(224,), float32], %x11: Tensor[(224,), float32]) {
    %0 = qnn.dequantize(%x0, 0.1f, 0, axis=-1);
    %1 = nn.softmax(%0, axis=-1);
    %2 = cast(%1, dtype="float16");
    let %x12 = 1.0f;
    %3 = add(%x12, %x12);
    let %x13 = %3;
    %4 = zeros(shape=[1], dtype="float32");
    %5 = add(%1, %4);
    %6 = add(%x13, %5);
    let %x14 = %6;
    %7 = add(%x14, 1.0f);
    %8 = nn.conv2d(%7, %x2, strides=[1, 1], padding=[1, 1, 1, 1], dilation=[1, 1], groups=1, channels=3, kernel_size=[3, 3], data_layout="NCHW", kernel_layout="OIHW", out_layout="", out_dtype="");
    %9 = add(1.0f, %8);
    %10 = add(%8, %9);
    %11 = nn.conv2d(%10, %x3, strides=[1, 1], padding=[0, 0, 0, 0], dilation=[1, 1], groups=1, channels=3, kernel_size=[1, 1], data_layout="NCHW", kernel_layout="OIHW", out_layout="", out_dtype="");
    %12 = nn.conv2d(%10, %x4, strides=[1, 1], padding=[1, 1, 1, 1], dilation=[1, 1], groups=1, channels=3, kernel_size=[3, 3], data_layout="NCHW", kernel_layout="OIHW", out_layout="", out_dtype="");
    %13 = add(%11, %12);
    %14 = qnn.dequantize(%x1, 0.2f, 0, axis=-1);
    %15 = multiply(%0, %14);
    %16 = qnn.quantize(%15, 20.0f, 0, out_dtype="int8", axis=-1);
    %17 = qnn.dequantize(%16, 0.5f, 0, axis=-1);
    %18 = qnn.dequantize(%x5, 1.5f, 0, axis=-1);
    %19 = qnn.dequantize(%x6, 2.5f, 0, axis=-1);
    %20 = qnn.dequantize(%x7, 3.5f, 0, axis=-1);
    %21 = (%17, %18, %19, %20);
    %22 = concatenate(%21, axis=-1);
    %23 = qnn.quantize(%22, 3.5f, 0, out_dtype="int8", axis=-1);
    %24 = layout_transform(%15, src_layout="NHWC", dst_layout="NCHW");
    %25 = layout_transform(%24, src_layout="NCHW", dst_layout="NCHW4c");
    %26 = nn.relu(%25);
    %27 = layout_transform(%26, src_layout="NCHW4c", dst_layout="NCHW");
    %28 = layout_transform(%27, src_layout="NCHW", dst_layout="NHWC");
    %29 = add(1.0f, 1.0f);
    %30 = add(%29, %x4);
    %31 = nn.batch_norm(%27, %x11, %x10, %x9, %x8, axis=1, epsilon=1e-05f, center=1, scale=1);
    %32 = %31.0;
    %33 = %31.0;
    %34 = add(%32, %33);
    %35 = qnn.dequantize(%16, 2.0f, 0, axis=-1);
    %36 = expand_dims(%35, axis=1, num_newaxis=1);
    %37 = qnn.quantize(%36, 2.0f, 0, out_dtype="int8", axis=-1);
    %38 = (%2, %13, %23, %28, %30, %34, %37);
    %38
}
