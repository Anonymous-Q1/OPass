#[version = "0.0.5"]
def @main(%x0: Tensor[(2, 32), float32], %x1: Tensor[(16, 32), float32], %x2: Tensor[(8, 32), float32], %x3: Tensor[(2, 11, 1), float32], %x4: Tensor[(2, 16, 1), float32], %x5: Tensor[(2, 16, 1), float32], %x6: Tensor[(5, 32), float32], %x7: float32, %x8: Tensor[(32, 32), float32], %x9: float32, %x10: Tensor[(72, 26), int32]) {
    %0 = nn.dense(%x0, %x1, units=None, out_dtype="");
    %1 = expand_dims(%0, axis=2, num_newaxis=1);
    %2 = nn.dense(%x0, %x2, units=None, out_dtype="");
    %3 = expand_dims(%2, axis=2, num_newaxis=1);
    %4 = (%1, %3);
    %5 = nn.softmax(%0, axis=-1);
    %6 = multiply(%x2, %x2);
    let %x11 = %6;
    %7 = zeros_like(%x2);
    %8 = ones_like(%x11);
    let %x12 = %8;
    %9 = multiply(%x12, %x2);
    %10 = collapse_sum_like(%9, %x2);
    %11 = add(%7, %10);
    %12 = multiply(%x12, %x2);
    %13 = collapse_sum_like(%12, %x2);
    %14 = add(%11, %13);
    %15 = (%14,);
    %16 = (%x11, %15);
    %17 = sqrt(%1);
    %18 = divide(2.0f, %17);
    %19 = nn.batch_matmul(%x3, %18, out_dtype="", transpose_a=0, transpose_b=1);
    %20 = nn.batch_matmul(%x3, %x4, out_dtype="", transpose_a=0, transpose_b=1);
    %21 = nn.batch_matmul(%x3, %x5, out_dtype="", transpose_a=0, transpose_b=1);
    %22 = (%19, %20, %21);
    %23 = add(%x1, 1.0f);
    %24 = nn.dense(%x6, %23, units=None, out_dtype="");
    %25 = add(%24, %x7);
    %26 = nn.dense(%x6, %x8, units=None, out_dtype="");
    %27 = add(%26, %x9);
    %28 = (%25, %27);
    %29 = nn.softmax(%2, axis=-1);
    %30 = cast_like(%8, %x10);
    %31 = exp(%23);
    %32 = squeeze(%31, axis=None);
    %33 = shape_of(%32, dtype="int32");
    %34 = dyn.ones(%33, shape=None, dtype="float32");
    %35 = (%4, %5, %16, %22, %28, %29, %30, %34);
    %35
}
