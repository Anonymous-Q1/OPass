#[version = "0.0.5"]
type List[A] {
  Cons(A, List[A]),
  Nil,
}

type Option[A] {
  Some(A),
  None,
}

type Tree[A] {
  Rose(A, List[Tree[A]]),
}

type tensor_float16_t {
  tensor_nil_float16,
  tensor0_float16(float16),
  tensor1_float16(Tensor[(?), float16]),
  tensor2_float16(Tensor[(?, ?), float16]),
  tensor3_float16(Tensor[(?, ?, ?), float16]),
  tensor4_float16(Tensor[(?, ?, ?, ?), float16]),
  tensor5_float16(Tensor[(?, ?, ?, ?, ?), float16]),
  tensor6_float16(Tensor[(?, ?, ?, ?, ?, ?), float16]),
}

type tensor_float32_t {
  tensor_nil_float32,
  tensor0_float32(float32),
  tensor1_float32(Tensor[(?), float32]),
  tensor2_float32(Tensor[(?, ?), float32]),
  tensor3_float32(Tensor[(?, ?, ?), float32]),
  tensor4_float32(Tensor[(?, ?, ?, ?), float32]),
  tensor5_float32(Tensor[(?, ?, ?, ?, ?), float32]),
  tensor6_float32(Tensor[(?, ?, ?, ?, ?, ?), float32]),
}

type tensor_float64_t {
  tensor_nil_float64,
  tensor0_float64(float64),
  tensor1_float64(Tensor[(?), float64]),
  tensor2_float64(Tensor[(?, ?), float64]),
  tensor3_float64(Tensor[(?, ?, ?), float64]),
  tensor4_float64(Tensor[(?, ?, ?, ?), float64]),
  tensor5_float64(Tensor[(?, ?, ?, ?, ?), float64]),
  tensor6_float64(Tensor[(?, ?, ?, ?, ?, ?), float64]),
}

type tensor_int16_t {
  tensor_nil_int16,
  tensor0_int16(int16),
  tensor1_int16(Tensor[(?), int16]),
  tensor2_int16(Tensor[(?, ?), int16]),
  tensor3_int16(Tensor[(?, ?, ?), int16]),
  tensor4_int16(Tensor[(?, ?, ?, ?), int16]),
  tensor5_int16(Tensor[(?, ?, ?, ?, ?), int16]),
  tensor6_int16(Tensor[(?, ?, ?, ?, ?, ?), int16]),
}

type tensor_int32_t {
  tensor_nil_int32,
  tensor0_int32(int32),
  tensor1_int32(Tensor[(?), int32]),
  tensor2_int32(Tensor[(?, ?), int32]),
  tensor3_int32(Tensor[(?, ?, ?), int32]),
  tensor4_int32(Tensor[(?, ?, ?, ?), int32]),
  tensor5_int32(Tensor[(?, ?, ?, ?, ?), int32]),
  tensor6_int32(Tensor[(?, ?, ?, ?, ?, ?), int32]),
}

type tensor_int64_t {
  tensor_nil_int64,
  tensor0_int64(int64),
  tensor1_int64(Tensor[(?), int64]),
  tensor2_int64(Tensor[(?, ?), int64]),
  tensor3_int64(Tensor[(?, ?, ?), int64]),
  tensor4_int64(Tensor[(?, ?, ?, ?), int64]),
  tensor5_int64(Tensor[(?, ?, ?, ?, ?), int64]),
  tensor6_int64(Tensor[(?, ?, ?, ?, ?, ?), int64]),
}

type tensor_int8_t {
  tensor_nil_int8,
  tensor0_int8(int8),
  tensor1_int8(Tensor[(?), int8]),
  tensor2_int8(Tensor[(?, ?), int8]),
  tensor3_int8(Tensor[(?, ?, ?), int8]),
  tensor4_int8(Tensor[(?, ?, ?, ?), int8]),
  tensor5_int8(Tensor[(?, ?, ?, ?, ?), int8]),
  tensor6_int8(Tensor[(?, ?, ?, ?, ?, ?), int8]),
}

type tensor_uint16_t {
  tensor_nil_uint16,
  tensor0_uint16(uint16),
  tensor1_uint16(Tensor[(?), uint16]),
  tensor2_uint16(Tensor[(?, ?), uint16]),
  tensor3_uint16(Tensor[(?, ?, ?), uint16]),
  tensor4_uint16(Tensor[(?, ?, ?, ?), uint16]),
  tensor5_uint16(Tensor[(?, ?, ?, ?, ?), uint16]),
  tensor6_uint16(Tensor[(?, ?, ?, ?, ?, ?), uint16]),
}

type tensor_uint8_t {
  tensor_nil_uint8,
  tensor0_uint8(uint8),
  tensor1_uint8(Tensor[(?), uint8]),
  tensor2_uint8(Tensor[(?, ?), uint8]),
  tensor3_uint8(Tensor[(?, ?, ?), uint8]),
  tensor4_uint8(Tensor[(?, ?, ?, ?), uint8]),
  tensor5_uint8(Tensor[(?, ?, ?, ?, ?), uint8]),
  tensor6_uint8(Tensor[(?, ?, ?, ?, ?, ?), uint8]),
}

def @compose[A, B, C](%f: fn (B) -> C /* ty=fn (B) -> C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:27:5 */, %g: fn (A) -> B /* ty=fn (A) -> B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:27:8 */) -> fn (A) -> C {
  fn (%x: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:27:11 */) -> C {
    %0 = %g(%x) /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:27:8 */;
    %f(%0) /* ty=C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:27:5 */
  } /* ty=fn (A) -> C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:26:3 */
}

def @concat[A](%xs: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:162:21 */, %ys: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:162:16 */) -> List[A] {
  @foldr(Cons, %ys, %xs) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:162:3 */
}

def @filter[A](%f1: fn (A) -> bool /* ty=fn (A) -> bool span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:174:17 */, %xs1: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:169:10 */) -> List[A] {
  match (%xs1) {
    Cons(%x1: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:172:14 */, %rest: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:174:21 */) => {
      %1 = %f1(%x1) /* ty=bool span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:171:11 */;
      if (%1) {
        %2 = @filter(%f1, %rest) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:172:18 */;
        Cons(%x1, %2) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:172:9 */
      } else {
        @filter(%f1, %rest) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:174:9 */
      }
    },
    Nil => {
      Nil /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:177:12 */
    },
  }
}

def @flip[A, B, C](%f2: fn (A, B) -> C /* ty=fn (A, B) -> C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:33:5 */) -> fn (B, A) -> C {
  fn (%b: B /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:33:12 */, %a: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:33:8 */) -> C {
    %f2(%a, %b) /* ty=C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:33:5 */
  } /* ty=fn (B, A) -> C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:32:3 */
}

def @foldl[A, B](%f3: fn (A, B) -> A /* ty=fn (A, B) -> A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:115:35 */, %acc: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:116:12 */, %xs2: List[B] /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:114:10 */) -> A {
  match (%xs2) {
    Cons(%x2: B /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:115:44 */, %rest1: List[B] /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:115:49 */) => {
      %3 = %f3(%acc, %x2) /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:115:35 */;
      @foldl(%f3, %3, %rest1) /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:115:24 */
    },
    Nil => {
      %acc
    },
  }
}

def @foldr[A, B](%f4: fn (A, B) -> B /* ty=fn (A, B) -> B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:128:38 */, %acc1: B /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:129:12 */, %xs3: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:127:10 */) -> B {
  match (%xs3) {
    Cons(%x3: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:128:27 */, %rest2: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:128:48 */) => {
      %4 = @foldr(%f4, %acc1, %rest2) /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:128:31 */;
      %f4(%x3, %4) /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:128:24 */
    },
    Nil => {
      %acc1
    },
  }
}

def @foldr1[A](%f5: fn (A, A) -> A /* ty=fn (A, A) -> A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:142:39 */, %xs4: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:140:11 */) -> A {
  match? (%xs4) {
    Cons(%x4: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:141:22 */, Nil) => {
      %x4
    },
    Cons(%x5: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:142:27 */, %rest3: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:142:43 */) => {
      %5 = @foldr1(%f5, %rest3) /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:142:31 */;
      %f5(%x5, %5) /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:142:24 */
    },
  }
}

def @hd[A](%xs5: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:50:11 */) -> A {
  match? (%xs5) {
    Cons(%x6: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:51:20 */, _) => {
      %x6
    },
  }
}

def @id[A](%x7: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:22:3 */) -> A {
  %x7
}

def @iterate[A](%f6: fn (A) -> A /* ty=fn (A) -> A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:304:28 */, %n: int32 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:304:32 */) -> fn (A) -> A {
  %6 = equal(%n, 0 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:301:15 */) /* ty=bool span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:301:7 */;
  if (%6) {
    @id
  } else {
    %7 = subtract(%n, 1 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:304:38 */) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:304:32 */;
    %8 = @iterate(%f6, %7) /* ty=fn (A) -> A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:304:18 */;
    @compose(%f6, %8) /* ty=fn [A](A) -> A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:304:5 */
  }
}

def @length[A](%xs6: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:79:10 */) -> int32 {
  match (%xs6) {
    Cons(_, %rest4: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:80:35 */) => {
      %9 = @length(%rest4) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:80:27 */;
      add(1 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:80:24 */, %9) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:80:24 */
    },
    Nil => {
      0 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:81:13 */
    },
  }
}

def @main() {
  %10 = Nil;
  %11 = Cons(4, %10);
  %12 = Cons(3, %11);
  %13 = Cons(2, %12);
  %14 = Cons(1, %13);
  %15 = Cons(0, %14);
  %16 = @tl(%15);
  %17 = @tl(%16);
  @hd(%17)
}

def @map[A, B](%f7: fn (A) -> B /* ty=fn (A) -> B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:102:43 */, %xs7: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:101:10 */) -> List[B] {
  match (%xs7) {
    Cons(%x8: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:102:32 */, %rest5: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:102:47 */) => {
      %18 = %f7(%x8) /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:102:29 */;
      %19 = @map(%f7, %rest5) /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:102:37 */;
      Cons(%18, %19) /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:102:24 */
    },
    Nil => {
      Nil /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:103:12 */
    },
  }
}

def @map_accuml[A, B, C](%f8: fn (A, B) -> (A, C) /* ty=fn (A, B) -> (A, C) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:222:18 */, %init: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:225:21 */, %xs8: List[B] /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:225:36 */) -> (A, List[C]) {
  let %updater: fn ((A, List[C]), B) -> (A, List[C]) /* ty=fn ((A, List[C]), B) -> (A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:225:10 */ = fn (%acc2: (A, List[C]) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:223:31 */, %x9: B /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:222:29 */) -> (A, List[C]) {
    %20 = %acc2.0 /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:222:21 */;
    let %f_out: (A, C) /* ty=(A, C) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:223:21 */ = %f8(%20, %x9) /* ty=(A, C) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:222:18 */;
    %21 = %f_out.1 /* ty=C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:223:21 */;
    %22 = %acc2.1 /* ty=List[C] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:223:31 */;
    %23 = %f_out.0 /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:223:6 */;
    %24 = Cons(%21, %22) /* ty=List[C] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:223:16 */;
    (%23, %24) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:223:5 */
  } /* ty=fn ((A, List[C]), B) -> (A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:221:3 */;
  %25 = Nil /* ty=List[C] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:225:30 */;
  %26 = (%init, %25) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:225:20 */;
  @foldl(%updater, %26, %xs8) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:225:3 */
}

def @map_accumr[A, B, C](%f9: fn (A, B) -> (A, C) /* ty=fn (A, B) -> (A, C) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:208:18 */, %init1: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:211:21 */, %xs9: List[B] /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:211:36 */) -> (A, List[C]) {
  let %updater1: fn (B, (A, List[C])) -> (A, List[C]) /* ty=fn (B, (A, List[C])) -> (A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:211:10 */ = fn (%x10: B /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:208:29 */, %acc3: (A, List[C]) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:209:31 */) -> (A, List[C]) {
    %27 = %acc3.0 /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:208:21 */;
    let %f_out1: (A, C) /* ty=(A, C) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:209:21 */ = %f9(%27, %x10) /* ty=(A, C) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:208:18 */;
    %28 = %f_out1.1 /* ty=C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:209:21 */;
    %29 = %acc3.1 /* ty=List[C] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:209:31 */;
    %30 = %f_out1.0 /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:209:6 */;
    %31 = Cons(%28, %29) /* ty=List[C] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:209:16 */;
    (%30, %31) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:209:5 */
  } /* ty=fn (B, (A, List[C])) -> (A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:207:3 */;
  %32 = Nil /* ty=List[C] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:211:30 */;
  %33 = (%init1, %32) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:211:20 */;
  @foldr(%updater1, %33, %xs9) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:211:3 */
}

def @nth[A](%xs10: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:71:14 */, %n1: int32 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:71:20 */) -> A {
  %34 = equal(%n1, 0 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:68:15 */) /* ty=bool span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:68:7 */;
  if (%34) {
    @hd(%xs10) /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:69:5 */
  } else {
    %35 = @tl(%xs10) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:71:10 */;
    %36 = subtract(%n1, 1 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:71:26 */) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:71:20 */;
    @nth(%35, %36) /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:71:5 */
  }
}

def @rev[A](%xs11: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:64 */) -> List[A] {
  %37 = fn (%h: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:47 */, %t: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:51 */) -> List[A] {
    Cons(%h, %t) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:42 */
  } /* ty=fn (A, List[A]) -> List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:16 */;
  %38 = @flip(%37) /* ty=fn (List[A], A) -> List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:10 */;
  %39 = Nil /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:59 */;
  @foldl(%38, %39, %xs11) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:3 */
}

def @size[A](%t1: Tree[A] /* ty=Tree[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:289:9 */) -> int32 {
  match (%t1) {
    Rose(_, %sub_trees: List[Tree[A]] /* ty=List[Tree[A]] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:291:29 */) => {
      %40 = @map(@size, %sub_trees) /* ty=List[int32] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:291:16 */;
      %41 = @sum(%40) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:291:11 */;
      add(1 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:291:8 */, %41) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:290:5 */
    },
  }
}

def @sum(%xs12: List[int32] /* ty=List[int32] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:154:21 */) -> int32 {
  let %add_f: fn (int32, int32) -> int32 /* ty=fn (int32, int32) -> int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:154:10 */ = fn (%x11: int32 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:152:5 */, %y: int32 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:152:10 */) -> int32 {
    add(%x11, %y) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:152:5 */
  } /* ty=fn (int32, int32) -> int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:151:3 */;
  @foldl(%add_f, 0 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:154:19 */, %xs12) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:154:3 */
}

def @ta_split_helper_float16(%tensor_array: List[tensor_float16_t[]], %value1: tensor_float16_t[], %offset1: int32, %current1: int32, %limit1: int32, %lengths: Tensor[(?), int32]) -> List[tensor_float16_t[]] {
  %42 = equal(%current1, %limit1);
  if (%42) {
    %tensor_array
  } else {
    %43 = take(%lengths, %current1);
    %44 = add(%offset1, %43);
    %45 = add(%current1, 1);
    %46 = take(%lengths, %current1);
    %47 = add(%46, %offset1);
    %48 = @ta_split_helper_float16(%tensor_array, %value1, %44, %45, %limit1, %lengths);
    %49 = @tensor_take_float16(%value1, %offset1, %47);
    @tensor_array_write_float16(%48, %current1, %49)
  }
}

def @ta_split_helper_float32(%tensor_array1: List[tensor_float32_t[]], %value11: tensor_float32_t[], %offset11: int32, %current11: int32, %limit11: int32, %lengths1: Tensor[(?), int32]) -> List[tensor_float32_t[]] {
  %50 = equal(%current11, %limit11);
  if (%50) {
    %tensor_array1
  } else {
    %51 = take(%lengths1, %current11);
    %52 = add(%offset11, %51);
    %53 = add(%current11, 1);
    %54 = take(%lengths1, %current11);
    %55 = add(%54, %offset11);
    %56 = @ta_split_helper_float32(%tensor_array1, %value11, %52, %53, %limit11, %lengths1);
    %57 = @tensor_take_float32(%value11, %offset11, %55);
    @tensor_array_write_float32(%56, %current11, %57)
  }
}

def @ta_split_helper_float64(%tensor_array2: List[tensor_float64_t[]], %value12: tensor_float64_t[], %offset12: int32, %current12: int32, %limit12: int32, %lengths2: Tensor[(?), int32]) -> List[tensor_float64_t[]] {
  %58 = equal(%current12, %limit12);
  if (%58) {
    %tensor_array2
  } else {
    %59 = take(%lengths2, %current12);
    %60 = add(%offset12, %59);
    %61 = add(%current12, 1);
    %62 = take(%lengths2, %current12);
    %63 = add(%62, %offset12);
    %64 = @ta_split_helper_float64(%tensor_array2, %value12, %60, %61, %limit12, %lengths2);
    %65 = @tensor_take_float64(%value12, %offset12, %63);
    @tensor_array_write_float64(%64, %current12, %65)
  }
}

def @ta_split_helper_int16(%tensor_array3: List[tensor_int16_t[]], %value13: tensor_int16_t[], %offset13: int32, %current13: int32, %limit13: int32, %lengths3: Tensor[(?), int32]) -> List[tensor_int16_t[]] {
  %66 = equal(%current13, %limit13);
  if (%66) {
    %tensor_array3
  } else {
    %67 = take(%lengths3, %current13);
    %68 = add(%offset13, %67);
    %69 = add(%current13, 1);
    %70 = take(%lengths3, %current13);
    %71 = add(%70, %offset13);
    %72 = @ta_split_helper_int16(%tensor_array3, %value13, %68, %69, %limit13, %lengths3);
    %73 = @tensor_take_int16(%value13, %offset13, %71);
    @tensor_array_write_int16(%72, %current13, %73)
  }
}

def @ta_split_helper_int32(%tensor_array4: List[tensor_int32_t[]], %value14: tensor_int32_t[], %offset14: int32, %current14: int32, %limit14: int32, %lengths4: Tensor[(?), int32]) -> List[tensor_int32_t[]] {
  %74 = equal(%current14, %limit14);
  if (%74) {
    %tensor_array4
  } else {
    %75 = take(%lengths4, %current14);
    %76 = add(%offset14, %75);
    %77 = add(%current14, 1);
    %78 = take(%lengths4, %current14);
    %79 = add(%78, %offset14);
    %80 = @ta_split_helper_int32(%tensor_array4, %value14, %76, %77, %limit14, %lengths4);
    %81 = @tensor_take_int32(%value14, %offset14, %79);
    @tensor_array_write_int32(%80, %current14, %81)
  }
}

def @ta_split_helper_int64(%tensor_array5: List[tensor_int64_t[]], %value15: tensor_int64_t[], %offset15: int32, %current15: int32, %limit15: int32, %lengths5: Tensor[(?), int32]) -> List[tensor_int64_t[]] {
  %82 = equal(%current15, %limit15);
  if (%82) {
    %tensor_array5
  } else {
    %83 = take(%lengths5, %current15);
    %84 = add(%offset15, %83);
    %85 = add(%current15, 1);
    %86 = take(%lengths5, %current15);
    %87 = add(%86, %offset15);
    %88 = @ta_split_helper_int64(%tensor_array5, %value15, %84, %85, %limit15, %lengths5);
    %89 = @tensor_take_int64(%value15, %offset15, %87);
    @tensor_array_write_int64(%88, %current15, %89)
  }
}

def @ta_split_helper_int8(%tensor_array6: List[tensor_int8_t[]], %value16: tensor_int8_t[], %offset16: int32, %current16: int32, %limit16: int32, %lengths6: Tensor[(?), int32]) -> List[tensor_int8_t[]] {
  %90 = equal(%current16, %limit16);
  if (%90) {
    %tensor_array6
  } else {
    %91 = take(%lengths6, %current16);
    %92 = add(%offset16, %91);
    %93 = add(%current16, 1);
    %94 = take(%lengths6, %current16);
    %95 = add(%94, %offset16);
    %96 = @ta_split_helper_int8(%tensor_array6, %value16, %92, %93, %limit16, %lengths6);
    %97 = @tensor_take_int8(%value16, %offset16, %95);
    @tensor_array_write_int8(%96, %current16, %97)
  }
}

def @ta_split_helper_uint16(%tensor_array7: List[tensor_uint16_t[]], %value17: tensor_uint16_t[], %offset17: int32, %current17: int32, %limit17: int32, %lengths7: Tensor[(?), int32]) -> List[tensor_uint16_t[]] {
  %98 = equal(%current17, %limit17);
  if (%98) {
    %tensor_array7
  } else {
    %99 = take(%lengths7, %current17);
    %100 = add(%offset17, %99);
    %101 = add(%current17, 1);
    %102 = take(%lengths7, %current17);
    %103 = add(%102, %offset17);
    %104 = @ta_split_helper_uint16(%tensor_array7, %value17, %100, %101, %limit17, %lengths7);
    %105 = @tensor_take_uint16(%value17, %offset17, %103);
    @tensor_array_write_uint16(%104, %current17, %105)
  }
}

def @ta_split_helper_uint8(%tensor_array8: List[tensor_uint8_t[]], %value18: tensor_uint8_t[], %offset18: int32, %current18: int32, %limit18: int32, %lengths8: Tensor[(?), int32]) -> List[tensor_uint8_t[]] {
  %106 = equal(%current18, %limit18);
  if (%106) {
    %tensor_array8
  } else {
    %107 = take(%lengths8, %current18);
    %108 = add(%offset18, %107);
    %109 = add(%current18, 1);
    %110 = take(%lengths8, %current18);
    %111 = add(%110, %offset18);
    %112 = @ta_split_helper_uint8(%tensor_array8, %value18, %108, %109, %limit18, %lengths8);
    %113 = @tensor_take_uint8(%value18, %offset18, %111);
    @tensor_array_write_uint8(%112, %current18, %113)
  }
}

def @tensor_array_concat_float16(%tensor_array9: List[tensor_float16_t[]]) -> tensor_float16_t[] {
  match? (%tensor_array9) {
    Nil => {
      tensor_nil_float16
    },
    Cons(%hd, %tl) => {
      match? (%tl) {
        Nil => {
          %hd
        },
        _ => {
          %114 = @tensor_array_concat_float16(%tl);
          @tensor_concatenate_float16(%hd, %114)
        },
      }
    },
  }
}

def @tensor_array_concat_float32(%tensor_array10: List[tensor_float32_t[]]) -> tensor_float32_t[] {
  match? (%tensor_array10) {
    Nil => {
      tensor_nil_float32
    },
    Cons(%hd1, %tl1) => {
      match? (%tl1) {
        Nil => {
          %hd1
        },
        _ => {
          %115 = @tensor_array_concat_float32(%tl1);
          @tensor_concatenate_float32(%hd1, %115)
        },
      }
    },
  }
}

def @tensor_array_concat_float64(%tensor_array11: List[tensor_float64_t[]]) -> tensor_float64_t[] {
  match? (%tensor_array11) {
    Nil => {
      tensor_nil_float64
    },
    Cons(%hd2, %tl2) => {
      match? (%tl2) {
        Nil => {
          %hd2
        },
        _ => {
          %116 = @tensor_array_concat_float64(%tl2);
          @tensor_concatenate_float64(%hd2, %116)
        },
      }
    },
  }
}

def @tensor_array_concat_int16(%tensor_array12: List[tensor_int16_t[]]) -> tensor_int16_t[] {
  match? (%tensor_array12) {
    Nil => {
      tensor_nil_int16
    },
    Cons(%hd3, %tl3) => {
      match? (%tl3) {
        Nil => {
          %hd3
        },
        _ => {
          %117 = @tensor_array_concat_int16(%tl3);
          @tensor_concatenate_int16(%hd3, %117)
        },
      }
    },
  }
}

def @tensor_array_concat_int32(%tensor_array13: List[tensor_int32_t[]]) -> tensor_int32_t[] {
  match? (%tensor_array13) {
    Nil => {
      tensor_nil_int32
    },
    Cons(%hd4, %tl4) => {
      match? (%tl4) {
        Nil => {
          %hd4
        },
        _ => {
          %118 = @tensor_array_concat_int32(%tl4);
          @tensor_concatenate_int32(%hd4, %118)
        },
      }
    },
  }
}

def @tensor_array_concat_int64(%tensor_array14: List[tensor_int64_t[]]) -> tensor_int64_t[] {
  match? (%tensor_array14) {
    Nil => {
      tensor_nil_int64
    },
    Cons(%hd5, %tl5) => {
      match? (%tl5) {
        Nil => {
          %hd5
        },
        _ => {
          %119 = @tensor_array_concat_int64(%tl5);
          @tensor_concatenate_int64(%hd5, %119)
        },
      }
    },
  }
}

def @tensor_array_concat_int8(%tensor_array15: List[tensor_int8_t[]]) -> tensor_int8_t[] {
  match? (%tensor_array15) {
    Nil => {
      tensor_nil_int8
    },
    Cons(%hd6, %tl6) => {
      match? (%tl6) {
        Nil => {
          %hd6
        },
        _ => {
          %120 = @tensor_array_concat_int8(%tl6);
          @tensor_concatenate_int8(%hd6, %120)
        },
      }
    },
  }
}

def @tensor_array_concat_uint16(%tensor_array16: List[tensor_uint16_t[]]) -> tensor_uint16_t[] {
  match? (%tensor_array16) {
    Nil => {
      tensor_nil_uint16
    },
    Cons(%hd7, %tl7) => {
      match? (%tl7) {
        Nil => {
          %hd7
        },
        _ => {
          %121 = @tensor_array_concat_uint16(%tl7);
          @tensor_concatenate_uint16(%hd7, %121)
        },
      }
    },
  }
}

def @tensor_array_concat_uint8(%tensor_array17: List[tensor_uint8_t[]]) -> tensor_uint8_t[] {
  match? (%tensor_array17) {
    Nil => {
      tensor_nil_uint8
    },
    Cons(%hd8, %tl8) => {
      match? (%tl8) {
        Nil => {
          %hd8
        },
        _ => {
          %122 = @tensor_array_concat_uint8(%tl8);
          @tensor_concatenate_uint8(%hd8, %122)
        },
      }
    },
  }
}

def @tensor_array_float16(%x12: int32) -> List[tensor_float16_t[]] {
  %123 = equal(%x12, 0);
  if (%123) {
    Nil
  } else {
    %124 = subtract(%x12, 1);
    %125 = tensor_nil_float16;
    %126 = @tensor_array_float16(%124);
    Cons(%125, %126)
  }
}

def @tensor_array_float32(%x13: int32) -> List[tensor_float32_t[]] {
  %127 = equal(%x13, 0);
  if (%127) {
    Nil
  } else {
    %128 = subtract(%x13, 1);
    %129 = tensor_nil_float32;
    %130 = @tensor_array_float32(%128);
    Cons(%129, %130)
  }
}

def @tensor_array_float64(%x14: int32) -> List[tensor_float64_t[]] {
  %131 = equal(%x14, 0);
  if (%131) {
    Nil
  } else {
    %132 = subtract(%x14, 1);
    %133 = tensor_nil_float64;
    %134 = @tensor_array_float64(%132);
    Cons(%133, %134)
  }
}

def @tensor_array_int16(%x15: int32) -> List[tensor_int16_t[]] {
  %135 = equal(%x15, 0);
  if (%135) {
    Nil
  } else {
    %136 = subtract(%x15, 1);
    %137 = tensor_nil_int16;
    %138 = @tensor_array_int16(%136);
    Cons(%137, %138)
  }
}

def @tensor_array_int32(%x16: int32) -> List[tensor_int32_t[]] {
  %139 = equal(%x16, 0);
  if (%139) {
    Nil
  } else {
    %140 = subtract(%x16, 1);
    %141 = tensor_nil_int32;
    %142 = @tensor_array_int32(%140);
    Cons(%141, %142)
  }
}

def @tensor_array_int64(%x17: int32) -> List[tensor_int64_t[]] {
  %143 = equal(%x17, 0);
  if (%143) {
    Nil
  } else {
    %144 = subtract(%x17, 1);
    %145 = tensor_nil_int64;
    %146 = @tensor_array_int64(%144);
    Cons(%145, %146)
  }
}

def @tensor_array_int8(%x18: int32) -> List[tensor_int8_t[]] {
  %147 = equal(%x18, 0);
  if (%147) {
    Nil
  } else {
    %148 = subtract(%x18, 1);
    %149 = tensor_nil_int8;
    %150 = @tensor_array_int8(%148);
    Cons(%149, %150)
  }
}

def @tensor_array_read_float16(%tensor_array18: List[tensor_float16_t[]], %x19: int32) -> tensor_float16_t[] {
  @nth(%tensor_array18, %x19)
}

def @tensor_array_read_float32(%tensor_array19: List[tensor_float32_t[]], %x20: int32) -> tensor_float32_t[] {
  @nth(%tensor_array19, %x20)
}

def @tensor_array_read_float64(%tensor_array20: List[tensor_float64_t[]], %x21: int32) -> tensor_float64_t[] {
  @nth(%tensor_array20, %x21)
}

def @tensor_array_read_int16(%tensor_array21: List[tensor_int16_t[]], %x22: int32) -> tensor_int16_t[] {
  @nth(%tensor_array21, %x22)
}

def @tensor_array_read_int32(%tensor_array22: List[tensor_int32_t[]], %x23: int32) -> tensor_int32_t[] {
  @nth(%tensor_array22, %x23)
}

def @tensor_array_read_int64(%tensor_array23: List[tensor_int64_t[]], %x24: int32) -> tensor_int64_t[] {
  @nth(%tensor_array23, %x24)
}

def @tensor_array_read_int8(%tensor_array24: List[tensor_int8_t[]], %x25: int32) -> tensor_int8_t[] {
  @nth(%tensor_array24, %x25)
}

def @tensor_array_read_uint16(%tensor_array25: List[tensor_uint16_t[]], %x26: int32) -> tensor_uint16_t[] {
  @nth(%tensor_array25, %x26)
}

def @tensor_array_read_uint8(%tensor_array26: List[tensor_uint8_t[]], %x27: int32) -> tensor_uint8_t[] {
  @nth(%tensor_array26, %x27)
}

def @tensor_array_scatter_float16(%tensor_array27: List[tensor_float16_t[]], %indices: Tensor[(?), int32], %values: List[tensor_float16_t[]]) -> List[tensor_float16_t[]] {
  %151 = shape_of(%indices, dtype="int32");
  %152 = take(%151, 0);
  @tensor_array_scatter_helper_float16(%tensor_array27, 0, %152, %indices, %values)
}

def @tensor_array_scatter_float32(%tensor_array28: List[tensor_float32_t[]], %indices1: Tensor[(?), int32], %values1: List[tensor_float32_t[]]) -> List[tensor_float32_t[]] {
  %153 = shape_of(%indices1, dtype="int32");
  %154 = take(%153, 0);
  @tensor_array_scatter_helper_float32(%tensor_array28, 0, %154, %indices1, %values1)
}

def @tensor_array_scatter_float64(%tensor_array29: List[tensor_float64_t[]], %indices2: Tensor[(?), int32], %values2: List[tensor_float64_t[]]) -> List[tensor_float64_t[]] {
  %155 = shape_of(%indices2, dtype="int32");
  %156 = take(%155, 0);
  @tensor_array_scatter_helper_float64(%tensor_array29, 0, %156, %indices2, %values2)
}

def @tensor_array_scatter_helper_float16(%ta: List[tensor_float16_t[]], %current: int32, %limit: int32, %indices_: Tensor[(?), int32], %values_: List[tensor_float16_t[]]) -> List[tensor_float16_t[]] {
  %157 = equal(%current, %limit);
  if (%157) {
    %ta
  } else {
    %158 = take(%indices_, %current);
    %159 = @tensor_array_read_float16(%values_, %current);
    %160 = @tensor_array_write_float16(%ta, %158, %159);
    %161 = add(%current, 1);
    @tensor_array_scatter_helper_float16(%160, %161, %limit, %indices_, %values_)
  }
}

def @tensor_array_scatter_helper_float32(%ta1: List[tensor_float32_t[]], %current2: int32, %limit2: int32, %indices_1: Tensor[(?), int32], %values_1: List[tensor_float32_t[]]) -> List[tensor_float32_t[]] {
  %162 = equal(%current2, %limit2);
  if (%162) {
    %ta1
  } else {
    %163 = take(%indices_1, %current2);
    %164 = @tensor_array_read_float32(%values_1, %current2);
    %165 = @tensor_array_write_float32(%ta1, %163, %164);
    %166 = add(%current2, 1);
    @tensor_array_scatter_helper_float32(%165, %166, %limit2, %indices_1, %values_1)
  }
}

def @tensor_array_scatter_helper_float64(%ta2: List[tensor_float64_t[]], %current3: int32, %limit3: int32, %indices_2: Tensor[(?), int32], %values_2: List[tensor_float64_t[]]) -> List[tensor_float64_t[]] {
  %167 = equal(%current3, %limit3);
  if (%167) {
    %ta2
  } else {
    %168 = take(%indices_2, %current3);
    %169 = @tensor_array_read_float64(%values_2, %current3);
    %170 = @tensor_array_write_float64(%ta2, %168, %169);
    %171 = add(%current3, 1);
    @tensor_array_scatter_helper_float64(%170, %171, %limit3, %indices_2, %values_2)
  }
}

def @tensor_array_scatter_helper_int16(%ta3: List[tensor_int16_t[]], %current4: int32, %limit4: int32, %indices_3: Tensor[(?), int32], %values_3: List[tensor_int16_t[]]) -> List[tensor_int16_t[]] {
  %172 = equal(%current4, %limit4);
  if (%172) {
    %ta3
  } else {
    %173 = take(%indices_3, %current4);
    %174 = @tensor_array_read_int16(%values_3, %current4);
    %175 = @tensor_array_write_int16(%ta3, %173, %174);
    %176 = add(%current4, 1);
    @tensor_array_scatter_helper_int16(%175, %176, %limit4, %indices_3, %values_3)
  }
}

def @tensor_array_scatter_helper_int32(%ta4: List[tensor_int32_t[]], %current5: int32, %limit5: int32, %indices_4: Tensor[(?), int32], %values_4: List[tensor_int32_t[]]) -> List[tensor_int32_t[]] {
  %177 = equal(%current5, %limit5);
  if (%177) {
    %ta4
  } else {
    %178 = take(%indices_4, %current5);
    %179 = @tensor_array_read_int32(%values_4, %current5);
    %180 = @tensor_array_write_int32(%ta4, %178, %179);
    %181 = add(%current5, 1);
    @tensor_array_scatter_helper_int32(%180, %181, %limit5, %indices_4, %values_4)
  }
}

def @tensor_array_scatter_helper_int64(%ta5: List[tensor_int64_t[]], %current6: int32, %limit6: int32, %indices_5: Tensor[(?), int32], %values_5: List[tensor_int64_t[]]) -> List[tensor_int64_t[]] {
  %182 = equal(%current6, %limit6);
  if (%182) {
    %ta5
  } else {
    %183 = take(%indices_5, %current6);
    %184 = @tensor_array_read_int64(%values_5, %current6);
    %185 = @tensor_array_write_int64(%ta5, %183, %184);
    %186 = add(%current6, 1);
    @tensor_array_scatter_helper_int64(%185, %186, %limit6, %indices_5, %values_5)
  }
}

def @tensor_array_scatter_helper_int8(%ta6: List[tensor_int8_t[]], %current7: int32, %limit7: int32, %indices_6: Tensor[(?), int32], %values_6: List[tensor_int8_t[]]) -> List[tensor_int8_t[]] {
  %187 = equal(%current7, %limit7);
  if (%187) {
    %ta6
  } else {
    %188 = take(%indices_6, %current7);
    %189 = @tensor_array_read_int8(%values_6, %current7);
    %190 = @tensor_array_write_int8(%ta6, %188, %189);
    %191 = add(%current7, 1);
    @tensor_array_scatter_helper_int8(%190, %191, %limit7, %indices_6, %values_6)
  }
}

def @tensor_array_scatter_helper_uint16(%ta7: List[tensor_uint16_t[]], %current8: int32, %limit8: int32, %indices_7: Tensor[(?), int32], %values_7: List[tensor_uint16_t[]]) -> List[tensor_uint16_t[]] {
  %192 = equal(%current8, %limit8);
  if (%192) {
    %ta7
  } else {
    %193 = take(%indices_7, %current8);
    %194 = @tensor_array_read_uint16(%values_7, %current8);
    %195 = @tensor_array_write_uint16(%ta7, %193, %194);
    %196 = add(%current8, 1);
    @tensor_array_scatter_helper_uint16(%195, %196, %limit8, %indices_7, %values_7)
  }
}

def @tensor_array_scatter_helper_uint8(%ta8: List[tensor_uint8_t[]], %current9: int32, %limit9: int32, %indices_8: Tensor[(?), int32], %values_8: List[tensor_uint8_t[]]) -> List[tensor_uint8_t[]] {
  %197 = equal(%current9, %limit9);
  if (%197) {
    %ta8
  } else {
    %198 = take(%indices_8, %current9);
    %199 = @tensor_array_read_uint8(%values_8, %current9);
    %200 = @tensor_array_write_uint8(%ta8, %198, %199);
    %201 = add(%current9, 1);
    @tensor_array_scatter_helper_uint8(%200, %201, %limit9, %indices_8, %values_8)
  }
}

def @tensor_array_scatter_int16(%tensor_array30: List[tensor_int16_t[]], %indices3: Tensor[(?), int32], %values3: List[tensor_int16_t[]]) -> List[tensor_int16_t[]] {
  %202 = shape_of(%indices3, dtype="int32");
  %203 = take(%202, 0);
  @tensor_array_scatter_helper_int16(%tensor_array30, 0, %203, %indices3, %values3)
}

def @tensor_array_scatter_int32(%tensor_array31: List[tensor_int32_t[]], %indices4: Tensor[(?), int32], %values4: List[tensor_int32_t[]]) -> List[tensor_int32_t[]] {
  %204 = shape_of(%indices4, dtype="int32");
  %205 = take(%204, 0);
  @tensor_array_scatter_helper_int32(%tensor_array31, 0, %205, %indices4, %values4)
}

def @tensor_array_scatter_int64(%tensor_array32: List[tensor_int64_t[]], %indices5: Tensor[(?), int32], %values5: List[tensor_int64_t[]]) -> List[tensor_int64_t[]] {
  %206 = shape_of(%indices5, dtype="int32");
  %207 = take(%206, 0);
  @tensor_array_scatter_helper_int64(%tensor_array32, 0, %207, %indices5, %values5)
}

def @tensor_array_scatter_int8(%tensor_array33: List[tensor_int8_t[]], %indices6: Tensor[(?), int32], %values6: List[tensor_int8_t[]]) -> List[tensor_int8_t[]] {
  %208 = shape_of(%indices6, dtype="int32");
  %209 = take(%208, 0);
  @tensor_array_scatter_helper_int8(%tensor_array33, 0, %209, %indices6, %values6)
}

def @tensor_array_scatter_uint16(%tensor_array34: List[tensor_uint16_t[]], %indices7: Tensor[(?), int32], %values7: List[tensor_uint16_t[]]) -> List[tensor_uint16_t[]] {
  %210 = shape_of(%indices7, dtype="int32");
  %211 = take(%210, 0);
  @tensor_array_scatter_helper_uint16(%tensor_array34, 0, %211, %indices7, %values7)
}

def @tensor_array_scatter_uint8(%tensor_array35: List[tensor_uint8_t[]], %indices8: Tensor[(?), int32], %values8: List[tensor_uint8_t[]]) -> List[tensor_uint8_t[]] {
  %212 = shape_of(%indices8, dtype="int32");
  %213 = take(%212, 0);
  @tensor_array_scatter_helper_uint8(%tensor_array35, 0, %213, %indices8, %values8)
}

def @tensor_array_split_float16(%tensor_array36: List[tensor_float16_t[]], %value: tensor_float16_t[], %lengths9: Tensor[(?), int32]) -> List[tensor_float16_t[]] {
  %214 = shape_of(%lengths9, dtype="int32");
  %215 = take(%214, 0);
  @ta_split_helper_float16(%tensor_array36, %value, 0, 0, %215, %lengths9)
}

def @tensor_array_split_float32(%tensor_array37: List[tensor_float32_t[]], %value2: tensor_float32_t[], %lengths10: Tensor[(?), int32]) -> List[tensor_float32_t[]] {
  %216 = shape_of(%lengths10, dtype="int32");
  %217 = take(%216, 0);
  @ta_split_helper_float32(%tensor_array37, %value2, 0, 0, %217, %lengths10)
}

def @tensor_array_split_float64(%tensor_array38: List[tensor_float64_t[]], %value3: tensor_float64_t[], %lengths11: Tensor[(?), int32]) -> List[tensor_float64_t[]] {
  %218 = shape_of(%lengths11, dtype="int32");
  %219 = take(%218, 0);
  @ta_split_helper_float64(%tensor_array38, %value3, 0, 0, %219, %lengths11)
}

def @tensor_array_split_int16(%tensor_array39: List[tensor_int16_t[]], %value4: tensor_int16_t[], %lengths12: Tensor[(?), int32]) -> List[tensor_int16_t[]] {
  %220 = shape_of(%lengths12, dtype="int32");
  %221 = take(%220, 0);
  @ta_split_helper_int16(%tensor_array39, %value4, 0, 0, %221, %lengths12)
}

def @tensor_array_split_int32(%tensor_array40: List[tensor_int32_t[]], %value5: tensor_int32_t[], %lengths13: Tensor[(?), int32]) -> List[tensor_int32_t[]] {
  %222 = shape_of(%lengths13, dtype="int32");
  %223 = take(%222, 0);
  @ta_split_helper_int32(%tensor_array40, %value5, 0, 0, %223, %lengths13)
}

def @tensor_array_split_int64(%tensor_array41: List[tensor_int64_t[]], %value6: tensor_int64_t[], %lengths14: Tensor[(?), int32]) -> List[tensor_int64_t[]] {
  %224 = shape_of(%lengths14, dtype="int32");
  %225 = take(%224, 0);
  @ta_split_helper_int64(%tensor_array41, %value6, 0, 0, %225, %lengths14)
}

def @tensor_array_split_int8(%tensor_array42: List[tensor_int8_t[]], %value7: tensor_int8_t[], %lengths15: Tensor[(?), int32]) -> List[tensor_int8_t[]] {
  %226 = shape_of(%lengths15, dtype="int32");
  %227 = take(%226, 0);
  @ta_split_helper_int8(%tensor_array42, %value7, 0, 0, %227, %lengths15)
}

def @tensor_array_split_uint16(%tensor_array43: List[tensor_uint16_t[]], %value8: tensor_uint16_t[], %lengths16: Tensor[(?), int32]) -> List[tensor_uint16_t[]] {
  %228 = shape_of(%lengths16, dtype="int32");
  %229 = take(%228, 0);
  @ta_split_helper_uint16(%tensor_array43, %value8, 0, 0, %229, %lengths16)
}

def @tensor_array_split_uint8(%tensor_array44: List[tensor_uint8_t[]], %value9: tensor_uint8_t[], %lengths17: Tensor[(?), int32]) -> List[tensor_uint8_t[]] {
  %230 = shape_of(%lengths17, dtype="int32");
  %231 = take(%230, 0);
  @ta_split_helper_uint8(%tensor_array44, %value9, 0, 0, %231, %lengths17)
}

def @tensor_array_stack_float16(%tensor_array45: List[tensor_float16_t[]]) -> tensor_float16_t[] {
  let %x_4 = @map(@tensor_expand_dims_float16, %tensor_array45);
  let %x_5 = @hd(%x_4);
  let %x_6 = @tl(%x_4);
  let %x_7 = @foldl(@tensor_concatenate_float16, %x_5, %x_6);
  %x_7
}

def @tensor_array_stack_float32(%tensor_array46: List[tensor_float32_t[]]) -> tensor_float32_t[] {
  let %x_0 = @map(@tensor_expand_dims_float32, %tensor_array46);
  let %x_1 = @hd(%x_0);
  let %x_2 = @tl(%x_0);
  let %x_3 = @foldl(@tensor_concatenate_float32, %x_1, %x_2);
  %x_3
}

def @tensor_array_stack_float64(%tensor_array47: List[tensor_float64_t[]]) -> tensor_float64_t[] {
  let %x_8 = @map(@tensor_expand_dims_float64, %tensor_array47);
  let %x_9 = @hd(%x_8);
  let %x_10 = @tl(%x_8);
  let %x_11 = @foldl(@tensor_concatenate_float64, %x_9, %x_10);
  %x_11
}

def @tensor_array_stack_int16(%tensor_array48: List[tensor_int16_t[]]) -> tensor_int16_t[] {
  let %x_24 = @map(@tensor_expand_dims_int16, %tensor_array48);
  let %x_25 = @hd(%x_24);
  let %x_26 = @tl(%x_24);
  let %x_27 = @foldl(@tensor_concatenate_int16, %x_25, %x_26);
  %x_27
}

def @tensor_array_stack_int32(%tensor_array49: List[tensor_int32_t[]]) -> tensor_int32_t[] {
  let %x_12 = @map(@tensor_expand_dims_int32, %tensor_array49);
  let %x_13 = @hd(%x_12);
  let %x_14 = @tl(%x_12);
  let %x_15 = @foldl(@tensor_concatenate_int32, %x_13, %x_14);
  %x_15
}

def @tensor_array_stack_int64(%tensor_array50: List[tensor_int64_t[]]) -> tensor_int64_t[] {
  let %x_32 = @map(@tensor_expand_dims_int64, %tensor_array50);
  let %x_33 = @hd(%x_32);
  let %x_34 = @tl(%x_32);
  let %x_35 = @foldl(@tensor_concatenate_int64, %x_33, %x_34);
  %x_35
}

def @tensor_array_stack_int8(%tensor_array51: List[tensor_int8_t[]]) -> tensor_int8_t[] {
  let %x_20 = @map(@tensor_expand_dims_int8, %tensor_array51);
  let %x_21 = @hd(%x_20);
  let %x_22 = @tl(%x_20);
  let %x_23 = @foldl(@tensor_concatenate_int8, %x_21, %x_22);
  %x_23
}

def @tensor_array_stack_uint16(%tensor_array52: List[tensor_uint16_t[]]) -> tensor_uint16_t[] {
  let %x_28 = @map(@tensor_expand_dims_uint16, %tensor_array52);
  let %x_29 = @hd(%x_28);
  let %x_30 = @tl(%x_28);
  let %x_31 = @foldl(@tensor_concatenate_uint16, %x_29, %x_30);
  %x_31
}

def @tensor_array_stack_uint8(%tensor_array53: List[tensor_uint8_t[]]) -> tensor_uint8_t[] {
  let %x_16 = @map(@tensor_expand_dims_uint8, %tensor_array53);
  let %x_17 = @hd(%x_16);
  let %x_18 = @tl(%x_16);
  let %x_19 = @foldl(@tensor_concatenate_uint8, %x_17, %x_18);
  %x_19
}

def @tensor_array_uint16(%x28: int32) -> List[tensor_uint16_t[]] {
  %232 = equal(%x28, 0);
  if (%232) {
    Nil
  } else {
    %233 = subtract(%x28, 1);
    %234 = tensor_nil_uint16;
    %235 = @tensor_array_uint16(%233);
    Cons(%234, %235)
  }
}

def @tensor_array_uint8(%x29: int32) -> List[tensor_uint8_t[]] {
  %236 = equal(%x29, 0);
  if (%236) {
    Nil
  } else {
    %237 = subtract(%x29, 1);
    %238 = tensor_nil_uint8;
    %239 = @tensor_array_uint8(%237);
    Cons(%238, %239)
  }
}

def @tensor_array_unstack_tensor1_float16(%tensor: Tensor[(?), float16]) -> List[tensor_float16_t[]] {
  %240 = shape_of(%tensor, dtype="int32");
  %241 = take(%240, 0);
  @tensor_array_unstack_tensor1_helper_float16(0, %241, %tensor)
}

def @tensor_array_unstack_tensor1_float32(%tensor1: Tensor[(?), float32]) -> List[tensor_float32_t[]] {
  %242 = shape_of(%tensor1, dtype="int32");
  %243 = take(%242, 0);
  @tensor_array_unstack_tensor1_helper_float32(0, %243, %tensor1)
}

def @tensor_array_unstack_tensor1_float64(%tensor2: Tensor[(?), float64]) -> List[tensor_float64_t[]] {
  %244 = shape_of(%tensor2, dtype="int32");
  %245 = take(%244, 0);
  @tensor_array_unstack_tensor1_helper_float64(0, %245, %tensor2)
}

def @tensor_array_unstack_tensor1_helper_float16(%i: int32, %up: int32, %t2: Tensor[(?), float16]) -> List[tensor_float16_t[]] {
  %246 = equal(%i, %up);
  if (%246) {
    Nil
  } else {
    %247 = take(%t2, %i);
    %248 = add(%i, 1);
    %249 = tensor0_float16(%247);
    %250 = @tensor_array_unstack_tensor1_helper_float16(%248, %up, %t2);
    Cons(%249, %250)
  }
}

def @tensor_array_unstack_tensor1_helper_float32(%i1: int32, %up1: int32, %t3: Tensor[(?), float32]) -> List[tensor_float32_t[]] {
  %251 = equal(%i1, %up1);
  if (%251) {
    Nil
  } else {
    %252 = take(%t3, %i1);
    %253 = add(%i1, 1);
    %254 = tensor0_float32(%252);
    %255 = @tensor_array_unstack_tensor1_helper_float32(%253, %up1, %t3);
    Cons(%254, %255)
  }
}

def @tensor_array_unstack_tensor1_helper_float64(%i2: int32, %up2: int32, %t4: Tensor[(?), float64]) -> List[tensor_float64_t[]] {
  %256 = equal(%i2, %up2);
  if (%256) {
    Nil
  } else {
    %257 = take(%t4, %i2);
    %258 = add(%i2, 1);
    %259 = tensor0_float64(%257);
    %260 = @tensor_array_unstack_tensor1_helper_float64(%258, %up2, %t4);
    Cons(%259, %260)
  }
}

def @tensor_array_unstack_tensor1_helper_int16(%i3: int32, %up3: int32, %t5: Tensor[(?), int16]) -> List[tensor_int16_t[]] {
  %261 = equal(%i3, %up3);
  if (%261) {
    Nil
  } else {
    %262 = take(%t5, %i3);
    %263 = add(%i3, 1);
    %264 = tensor0_int16(%262);
    %265 = @tensor_array_unstack_tensor1_helper_int16(%263, %up3, %t5);
    Cons(%264, %265)
  }
}

def @tensor_array_unstack_tensor1_helper_int32(%i4: int32, %up4: int32, %t6: Tensor[(?), int32]) -> List[tensor_int32_t[]] {
  %266 = equal(%i4, %up4);
  if (%266) {
    Nil
  } else {
    %267 = take(%t6, %i4);
    %268 = add(%i4, 1);
    %269 = tensor0_int32(%267);
    %270 = @tensor_array_unstack_tensor1_helper_int32(%268, %up4, %t6);
    Cons(%269, %270)
  }
}

def @tensor_array_unstack_tensor1_helper_int64(%i5: int32, %up5: int32, %t7: Tensor[(?), int64]) -> List[tensor_int64_t[]] {
  %271 = equal(%i5, %up5);
  if (%271) {
    Nil
  } else {
    %272 = take(%t7, %i5);
    %273 = add(%i5, 1);
    %274 = tensor0_int64(%272);
    %275 = @tensor_array_unstack_tensor1_helper_int64(%273, %up5, %t7);
    Cons(%274, %275)
  }
}

def @tensor_array_unstack_tensor1_helper_int8(%i6: int32, %up6: int32, %t8: Tensor[(?), int8]) -> List[tensor_int8_t[]] {
  %276 = equal(%i6, %up6);
  if (%276) {
    Nil
  } else {
    %277 = take(%t8, %i6);
    %278 = add(%i6, 1);
    %279 = tensor0_int8(%277);
    %280 = @tensor_array_unstack_tensor1_helper_int8(%278, %up6, %t8);
    Cons(%279, %280)
  }
}

def @tensor_array_unstack_tensor1_helper_uint16(%i7: int32, %up7: int32, %t9: Tensor[(?), uint16]) -> List[tensor_uint16_t[]] {
  %281 = equal(%i7, %up7);
  if (%281) {
    Nil
  } else {
    %282 = take(%t9, %i7);
    %283 = add(%i7, 1);
    %284 = tensor0_uint16(%282);
    %285 = @tensor_array_unstack_tensor1_helper_uint16(%283, %up7, %t9);
    Cons(%284, %285)
  }
}

def @tensor_array_unstack_tensor1_helper_uint8(%i8: int32, %up8: int32, %t10: Tensor[(?), uint8]) -> List[tensor_uint8_t[]] {
  %286 = equal(%i8, %up8);
  if (%286) {
    Nil
  } else {
    %287 = take(%t10, %i8);
    %288 = add(%i8, 1);
    %289 = tensor0_uint8(%287);
    %290 = @tensor_array_unstack_tensor1_helper_uint8(%288, %up8, %t10);
    Cons(%289, %290)
  }
}

def @tensor_array_unstack_tensor1_int16(%tensor3: Tensor[(?), int16]) -> List[tensor_int16_t[]] {
  %291 = shape_of(%tensor3, dtype="int32");
  %292 = take(%291, 0);
  @tensor_array_unstack_tensor1_helper_int16(0, %292, %tensor3)
}

def @tensor_array_unstack_tensor1_int32(%tensor4: Tensor[(?), int32]) -> List[tensor_int32_t[]] {
  %293 = shape_of(%tensor4, dtype="int32");
  %294 = take(%293, 0);
  @tensor_array_unstack_tensor1_helper_int32(0, %294, %tensor4)
}

def @tensor_array_unstack_tensor1_int64(%tensor5: Tensor[(?), int64]) -> List[tensor_int64_t[]] {
  %295 = shape_of(%tensor5, dtype="int32");
  %296 = take(%295, 0);
  @tensor_array_unstack_tensor1_helper_int64(0, %296, %tensor5)
}

def @tensor_array_unstack_tensor1_int8(%tensor6: Tensor[(?), int8]) -> List[tensor_int8_t[]] {
  %297 = shape_of(%tensor6, dtype="int32");
  %298 = take(%297, 0);
  @tensor_array_unstack_tensor1_helper_int8(0, %298, %tensor6)
}

def @tensor_array_unstack_tensor1_uint16(%tensor7: Tensor[(?), uint16]) -> List[tensor_uint16_t[]] {
  %299 = shape_of(%tensor7, dtype="int32");
  %300 = take(%299, 0);
  @tensor_array_unstack_tensor1_helper_uint16(0, %300, %tensor7)
}

def @tensor_array_unstack_tensor1_uint8(%tensor8: Tensor[(?), uint8]) -> List[tensor_uint8_t[]] {
  %301 = shape_of(%tensor8, dtype="int32");
  %302 = take(%301, 0);
  @tensor_array_unstack_tensor1_helper_uint8(0, %302, %tensor8)
}

def @tensor_array_unstack_tensor2_float16(%tensor9: Tensor[(?, ?), float16]) -> List[tensor_float16_t[]] {
  %303 = shape_of(%tensor9, dtype="int32");
  %304 = take(%303, 0);
  @tensor_array_unstack_tensor2_helper_float16(0, %304, %tensor9)
}

def @tensor_array_unstack_tensor2_float32(%tensor10: Tensor[(?, ?), float32]) -> List[tensor_float32_t[]] {
  %305 = shape_of(%tensor10, dtype="int32");
  %306 = take(%305, 0);
  @tensor_array_unstack_tensor2_helper_float32(0, %306, %tensor10)
}

def @tensor_array_unstack_tensor2_float64(%tensor11: Tensor[(?, ?), float64]) -> List[tensor_float64_t[]] {
  %307 = shape_of(%tensor11, dtype="int32");
  %308 = take(%307, 0);
  @tensor_array_unstack_tensor2_helper_float64(0, %308, %tensor11)
}

def @tensor_array_unstack_tensor2_helper_float16(%i9: int32, %up9: int32, %t11: Tensor[(?, ?), float16]) -> List[tensor_float16_t[]] {
  %309 = equal(%i9, %up9);
  if (%309) {
    Nil
  } else {
    %310 = take(%t11, %i9, axis=0);
    %311 = add(%i9, 1);
    %312 = tensor1_float16(%310);
    %313 = @tensor_array_unstack_tensor2_helper_float16(%311, %up9, %t11);
    Cons(%312, %313)
  }
}

def @tensor_array_unstack_tensor2_helper_float32(%i10: int32, %up10: int32, %t12: Tensor[(?, ?), float32]) -> List[tensor_float32_t[]] {
  %314 = equal(%i10, %up10);
  if (%314) {
    Nil
  } else {
    %315 = take(%t12, %i10, axis=0);
    %316 = add(%i10, 1);
    %317 = tensor1_float32(%315);
    %318 = @tensor_array_unstack_tensor2_helper_float32(%316, %up10, %t12);
    Cons(%317, %318)
  }
}

def @tensor_array_unstack_tensor2_helper_float64(%i11: int32, %up11: int32, %t13: Tensor[(?, ?), float64]) -> List[tensor_float64_t[]] {
  %319 = equal(%i11, %up11);
  if (%319) {
    Nil
  } else {
    %320 = take(%t13, %i11, axis=0);
    %321 = add(%i11, 1);
    %322 = tensor1_float64(%320);
    %323 = @tensor_array_unstack_tensor2_helper_float64(%321, %up11, %t13);
    Cons(%322, %323)
  }
}

def @tensor_array_unstack_tensor2_helper_int16(%i12: int32, %up12: int32, %t14: Tensor[(?, ?), int16]) -> List[tensor_int16_t[]] {
  %324 = equal(%i12, %up12);
  if (%324) {
    Nil
  } else {
    %325 = take(%t14, %i12, axis=0);
    %326 = add(%i12, 1);
    %327 = tensor1_int16(%325);
    %328 = @tensor_array_unstack_tensor2_helper_int16(%326, %up12, %t14);
    Cons(%327, %328)
  }
}

def @tensor_array_unstack_tensor2_helper_int32(%i13: int32, %up13: int32, %t15: Tensor[(?, ?), int32]) -> List[tensor_int32_t[]] {
  %329 = equal(%i13, %up13);
  if (%329) {
    Nil
  } else {
    %330 = take(%t15, %i13, axis=0);
    %331 = add(%i13, 1);
    %332 = tensor1_int32(%330);
    %333 = @tensor_array_unstack_tensor2_helper_int32(%331, %up13, %t15);
    Cons(%332, %333)
  }
}

def @tensor_array_unstack_tensor2_helper_int64(%i14: int32, %up14: int32, %t16: Tensor[(?, ?), int64]) -> List[tensor_int64_t[]] {
  %334 = equal(%i14, %up14);
  if (%334) {
    Nil
  } else {
    %335 = take(%t16, %i14, axis=0);
    %336 = add(%i14, 1);
    %337 = tensor1_int64(%335);
    %338 = @tensor_array_unstack_tensor2_helper_int64(%336, %up14, %t16);
    Cons(%337, %338)
  }
}

def @tensor_array_unstack_tensor2_helper_int8(%i15: int32, %up15: int32, %t17: Tensor[(?, ?), int8]) -> List[tensor_int8_t[]] {
  %339 = equal(%i15, %up15);
  if (%339) {
    Nil
  } else {
    %340 = take(%t17, %i15, axis=0);
    %341 = add(%i15, 1);
    %342 = tensor1_int8(%340);
    %343 = @tensor_array_unstack_tensor2_helper_int8(%341, %up15, %t17);
    Cons(%342, %343)
  }
}

def @tensor_array_unstack_tensor2_helper_uint16(%i16: int32, %up16: int32, %t18: Tensor[(?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %344 = equal(%i16, %up16);
  if (%344) {
    Nil
  } else {
    %345 = take(%t18, %i16, axis=0);
    %346 = add(%i16, 1);
    %347 = tensor1_uint16(%345);
    %348 = @tensor_array_unstack_tensor2_helper_uint16(%346, %up16, %t18);
    Cons(%347, %348)
  }
}

def @tensor_array_unstack_tensor2_helper_uint8(%i17: int32, %up17: int32, %t19: Tensor[(?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %349 = equal(%i17, %up17);
  if (%349) {
    Nil
  } else {
    %350 = take(%t19, %i17, axis=0);
    %351 = add(%i17, 1);
    %352 = tensor1_uint8(%350);
    %353 = @tensor_array_unstack_tensor2_helper_uint8(%351, %up17, %t19);
    Cons(%352, %353)
  }
}

def @tensor_array_unstack_tensor2_int16(%tensor12: Tensor[(?, ?), int16]) -> List[tensor_int16_t[]] {
  %354 = shape_of(%tensor12, dtype="int32");
  %355 = take(%354, 0);
  @tensor_array_unstack_tensor2_helper_int16(0, %355, %tensor12)
}

def @tensor_array_unstack_tensor2_int32(%tensor13: Tensor[(?, ?), int32]) -> List[tensor_int32_t[]] {
  %356 = shape_of(%tensor13, dtype="int32");
  %357 = take(%356, 0);
  @tensor_array_unstack_tensor2_helper_int32(0, %357, %tensor13)
}

def @tensor_array_unstack_tensor2_int64(%tensor14: Tensor[(?, ?), int64]) -> List[tensor_int64_t[]] {
  %358 = shape_of(%tensor14, dtype="int32");
  %359 = take(%358, 0);
  @tensor_array_unstack_tensor2_helper_int64(0, %359, %tensor14)
}

def @tensor_array_unstack_tensor2_int8(%tensor15: Tensor[(?, ?), int8]) -> List[tensor_int8_t[]] {
  %360 = shape_of(%tensor15, dtype="int32");
  %361 = take(%360, 0);
  @tensor_array_unstack_tensor2_helper_int8(0, %361, %tensor15)
}

def @tensor_array_unstack_tensor2_uint16(%tensor16: Tensor[(?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %362 = shape_of(%tensor16, dtype="int32");
  %363 = take(%362, 0);
  @tensor_array_unstack_tensor2_helper_uint16(0, %363, %tensor16)
}

def @tensor_array_unstack_tensor2_uint8(%tensor17: Tensor[(?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %364 = shape_of(%tensor17, dtype="int32");
  %365 = take(%364, 0);
  @tensor_array_unstack_tensor2_helper_uint8(0, %365, %tensor17)
}

def @tensor_array_unstack_tensor3_float16(%tensor18: Tensor[(?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %366 = shape_of(%tensor18, dtype="int32");
  %367 = take(%366, 0);
  @tensor_array_unstack_tensor3_helper_float16(0, %367, %tensor18)
}

def @tensor_array_unstack_tensor3_float32(%tensor19: Tensor[(?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %368 = shape_of(%tensor19, dtype="int32");
  %369 = take(%368, 0);
  @tensor_array_unstack_tensor3_helper_float32(0, %369, %tensor19)
}

def @tensor_array_unstack_tensor3_float64(%tensor20: Tensor[(?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %370 = shape_of(%tensor20, dtype="int32");
  %371 = take(%370, 0);
  @tensor_array_unstack_tensor3_helper_float64(0, %371, %tensor20)
}

def @tensor_array_unstack_tensor3_helper_float16(%i18: int32, %up18: int32, %t20: Tensor[(?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %372 = equal(%i18, %up18);
  if (%372) {
    Nil
  } else {
    %373 = take(%t20, %i18, axis=0);
    %374 = add(%i18, 1);
    %375 = tensor2_float16(%373);
    %376 = @tensor_array_unstack_tensor3_helper_float16(%374, %up18, %t20);
    Cons(%375, %376)
  }
}

def @tensor_array_unstack_tensor3_helper_float32(%i19: int32, %up19: int32, %t21: Tensor[(?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %377 = equal(%i19, %up19);
  if (%377) {
    Nil
  } else {
    %378 = take(%t21, %i19, axis=0);
    %379 = add(%i19, 1);
    %380 = tensor2_float32(%378);
    %381 = @tensor_array_unstack_tensor3_helper_float32(%379, %up19, %t21);
    Cons(%380, %381)
  }
}

def @tensor_array_unstack_tensor3_helper_float64(%i20: int32, %up20: int32, %t22: Tensor[(?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %382 = equal(%i20, %up20);
  if (%382) {
    Nil
  } else {
    %383 = take(%t22, %i20, axis=0);
    %384 = add(%i20, 1);
    %385 = tensor2_float64(%383);
    %386 = @tensor_array_unstack_tensor3_helper_float64(%384, %up20, %t22);
    Cons(%385, %386)
  }
}

def @tensor_array_unstack_tensor3_helper_int16(%i21: int32, %up21: int32, %t23: Tensor[(?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %387 = equal(%i21, %up21);
  if (%387) {
    Nil
  } else {
    %388 = take(%t23, %i21, axis=0);
    %389 = add(%i21, 1);
    %390 = tensor2_int16(%388);
    %391 = @tensor_array_unstack_tensor3_helper_int16(%389, %up21, %t23);
    Cons(%390, %391)
  }
}

def @tensor_array_unstack_tensor3_helper_int32(%i22: int32, %up22: int32, %t24: Tensor[(?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %392 = equal(%i22, %up22);
  if (%392) {
    Nil
  } else {
    %393 = take(%t24, %i22, axis=0);
    %394 = add(%i22, 1);
    %395 = tensor2_int32(%393);
    %396 = @tensor_array_unstack_tensor3_helper_int32(%394, %up22, %t24);
    Cons(%395, %396)
  }
}

def @tensor_array_unstack_tensor3_helper_int64(%i23: int32, %up23: int32, %t25: Tensor[(?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %397 = equal(%i23, %up23);
  if (%397) {
    Nil
  } else {
    %398 = take(%t25, %i23, axis=0);
    %399 = add(%i23, 1);
    %400 = tensor2_int64(%398);
    %401 = @tensor_array_unstack_tensor3_helper_int64(%399, %up23, %t25);
    Cons(%400, %401)
  }
}

def @tensor_array_unstack_tensor3_helper_int8(%i24: int32, %up24: int32, %t26: Tensor[(?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %402 = equal(%i24, %up24);
  if (%402) {
    Nil
  } else {
    %403 = take(%t26, %i24, axis=0);
    %404 = add(%i24, 1);
    %405 = tensor2_int8(%403);
    %406 = @tensor_array_unstack_tensor3_helper_int8(%404, %up24, %t26);
    Cons(%405, %406)
  }
}

def @tensor_array_unstack_tensor3_helper_uint16(%i25: int32, %up25: int32, %t27: Tensor[(?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %407 = equal(%i25, %up25);
  if (%407) {
    Nil
  } else {
    %408 = take(%t27, %i25, axis=0);
    %409 = add(%i25, 1);
    %410 = tensor2_uint16(%408);
    %411 = @tensor_array_unstack_tensor3_helper_uint16(%409, %up25, %t27);
    Cons(%410, %411)
  }
}

def @tensor_array_unstack_tensor3_helper_uint8(%i26: int32, %up26: int32, %t28: Tensor[(?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %412 = equal(%i26, %up26);
  if (%412) {
    Nil
  } else {
    %413 = take(%t28, %i26, axis=0);
    %414 = add(%i26, 1);
    %415 = tensor2_uint8(%413);
    %416 = @tensor_array_unstack_tensor3_helper_uint8(%414, %up26, %t28);
    Cons(%415, %416)
  }
}

def @tensor_array_unstack_tensor3_int16(%tensor21: Tensor[(?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %417 = shape_of(%tensor21, dtype="int32");
  %418 = take(%417, 0);
  @tensor_array_unstack_tensor3_helper_int16(0, %418, %tensor21)
}

def @tensor_array_unstack_tensor3_int32(%tensor22: Tensor[(?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %419 = shape_of(%tensor22, dtype="int32");
  %420 = take(%419, 0);
  @tensor_array_unstack_tensor3_helper_int32(0, %420, %tensor22)
}

def @tensor_array_unstack_tensor3_int64(%tensor23: Tensor[(?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %421 = shape_of(%tensor23, dtype="int32");
  %422 = take(%421, 0);
  @tensor_array_unstack_tensor3_helper_int64(0, %422, %tensor23)
}

def @tensor_array_unstack_tensor3_int8(%tensor24: Tensor[(?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %423 = shape_of(%tensor24, dtype="int32");
  %424 = take(%423, 0);
  @tensor_array_unstack_tensor3_helper_int8(0, %424, %tensor24)
}

def @tensor_array_unstack_tensor3_uint16(%tensor25: Tensor[(?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %425 = shape_of(%tensor25, dtype="int32");
  %426 = take(%425, 0);
  @tensor_array_unstack_tensor3_helper_uint16(0, %426, %tensor25)
}

def @tensor_array_unstack_tensor3_uint8(%tensor26: Tensor[(?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %427 = shape_of(%tensor26, dtype="int32");
  %428 = take(%427, 0);
  @tensor_array_unstack_tensor3_helper_uint8(0, %428, %tensor26)
}

def @tensor_array_unstack_tensor4_float16(%tensor27: Tensor[(?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %429 = shape_of(%tensor27, dtype="int32");
  %430 = take(%429, 0);
  @tensor_array_unstack_tensor4_helper_float16(0, %430, %tensor27)
}

def @tensor_array_unstack_tensor4_float32(%tensor28: Tensor[(?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %431 = shape_of(%tensor28, dtype="int32");
  %432 = take(%431, 0);
  @tensor_array_unstack_tensor4_helper_float32(0, %432, %tensor28)
}

def @tensor_array_unstack_tensor4_float64(%tensor29: Tensor[(?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %433 = shape_of(%tensor29, dtype="int32");
  %434 = take(%433, 0);
  @tensor_array_unstack_tensor4_helper_float64(0, %434, %tensor29)
}

def @tensor_array_unstack_tensor4_helper_float16(%i27: int32, %up27: int32, %t29: Tensor[(?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %435 = equal(%i27, %up27);
  if (%435) {
    Nil
  } else {
    %436 = take(%t29, %i27, axis=0);
    %437 = add(%i27, 1);
    %438 = tensor3_float16(%436);
    %439 = @tensor_array_unstack_tensor4_helper_float16(%437, %up27, %t29);
    Cons(%438, %439)
  }
}

def @tensor_array_unstack_tensor4_helper_float32(%i28: int32, %up28: int32, %t30: Tensor[(?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %440 = equal(%i28, %up28);
  if (%440) {
    Nil
  } else {
    %441 = take(%t30, %i28, axis=0);
    %442 = add(%i28, 1);
    %443 = tensor3_float32(%441);
    %444 = @tensor_array_unstack_tensor4_helper_float32(%442, %up28, %t30);
    Cons(%443, %444)
  }
}

def @tensor_array_unstack_tensor4_helper_float64(%i29: int32, %up29: int32, %t31: Tensor[(?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %445 = equal(%i29, %up29);
  if (%445) {
    Nil
  } else {
    %446 = take(%t31, %i29, axis=0);
    %447 = add(%i29, 1);
    %448 = tensor3_float64(%446);
    %449 = @tensor_array_unstack_tensor4_helper_float64(%447, %up29, %t31);
    Cons(%448, %449)
  }
}

def @tensor_array_unstack_tensor4_helper_int16(%i30: int32, %up30: int32, %t32: Tensor[(?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %450 = equal(%i30, %up30);
  if (%450) {
    Nil
  } else {
    %451 = take(%t32, %i30, axis=0);
    %452 = add(%i30, 1);
    %453 = tensor3_int16(%451);
    %454 = @tensor_array_unstack_tensor4_helper_int16(%452, %up30, %t32);
    Cons(%453, %454)
  }
}

def @tensor_array_unstack_tensor4_helper_int32(%i31: int32, %up31: int32, %t33: Tensor[(?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %455 = equal(%i31, %up31);
  if (%455) {
    Nil
  } else {
    %456 = take(%t33, %i31, axis=0);
    %457 = add(%i31, 1);
    %458 = tensor3_int32(%456);
    %459 = @tensor_array_unstack_tensor4_helper_int32(%457, %up31, %t33);
    Cons(%458, %459)
  }
}

def @tensor_array_unstack_tensor4_helper_int64(%i32: int32, %up32: int32, %t34: Tensor[(?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %460 = equal(%i32, %up32);
  if (%460) {
    Nil
  } else {
    %461 = take(%t34, %i32, axis=0);
    %462 = add(%i32, 1);
    %463 = tensor3_int64(%461);
    %464 = @tensor_array_unstack_tensor4_helper_int64(%462, %up32, %t34);
    Cons(%463, %464)
  }
}

def @tensor_array_unstack_tensor4_helper_int8(%i33: int32, %up33: int32, %t35: Tensor[(?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %465 = equal(%i33, %up33);
  if (%465) {
    Nil
  } else {
    %466 = take(%t35, %i33, axis=0);
    %467 = add(%i33, 1);
    %468 = tensor3_int8(%466);
    %469 = @tensor_array_unstack_tensor4_helper_int8(%467, %up33, %t35);
    Cons(%468, %469)
  }
}

def @tensor_array_unstack_tensor4_helper_uint16(%i34: int32, %up34: int32, %t36: Tensor[(?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %470 = equal(%i34, %up34);
  if (%470) {
    Nil
  } else {
    %471 = take(%t36, %i34, axis=0);
    %472 = add(%i34, 1);
    %473 = tensor3_uint16(%471);
    %474 = @tensor_array_unstack_tensor4_helper_uint16(%472, %up34, %t36);
    Cons(%473, %474)
  }
}

def @tensor_array_unstack_tensor4_helper_uint8(%i35: int32, %up35: int32, %t37: Tensor[(?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %475 = equal(%i35, %up35);
  if (%475) {
    Nil
  } else {
    %476 = take(%t37, %i35, axis=0);
    %477 = add(%i35, 1);
    %478 = tensor3_uint8(%476);
    %479 = @tensor_array_unstack_tensor4_helper_uint8(%477, %up35, %t37);
    Cons(%478, %479)
  }
}

def @tensor_array_unstack_tensor4_int16(%tensor30: Tensor[(?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %480 = shape_of(%tensor30, dtype="int32");
  %481 = take(%480, 0);
  @tensor_array_unstack_tensor4_helper_int16(0, %481, %tensor30)
}

def @tensor_array_unstack_tensor4_int32(%tensor31: Tensor[(?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %482 = shape_of(%tensor31, dtype="int32");
  %483 = take(%482, 0);
  @tensor_array_unstack_tensor4_helper_int32(0, %483, %tensor31)
}

def @tensor_array_unstack_tensor4_int64(%tensor32: Tensor[(?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %484 = shape_of(%tensor32, dtype="int32");
  %485 = take(%484, 0);
  @tensor_array_unstack_tensor4_helper_int64(0, %485, %tensor32)
}

def @tensor_array_unstack_tensor4_int8(%tensor33: Tensor[(?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %486 = shape_of(%tensor33, dtype="int32");
  %487 = take(%486, 0);
  @tensor_array_unstack_tensor4_helper_int8(0, %487, %tensor33)
}

def @tensor_array_unstack_tensor4_uint16(%tensor34: Tensor[(?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %488 = shape_of(%tensor34, dtype="int32");
  %489 = take(%488, 0);
  @tensor_array_unstack_tensor4_helper_uint16(0, %489, %tensor34)
}

def @tensor_array_unstack_tensor4_uint8(%tensor35: Tensor[(?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %490 = shape_of(%tensor35, dtype="int32");
  %491 = take(%490, 0);
  @tensor_array_unstack_tensor4_helper_uint8(0, %491, %tensor35)
}

def @tensor_array_unstack_tensor5_float16(%tensor36: Tensor[(?, ?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %492 = shape_of(%tensor36, dtype="int32");
  %493 = take(%492, 0);
  @tensor_array_unstack_tensor5_helper_float16(0, %493, %tensor36)
}

def @tensor_array_unstack_tensor5_float32(%tensor37: Tensor[(?, ?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %494 = shape_of(%tensor37, dtype="int32");
  %495 = take(%494, 0);
  @tensor_array_unstack_tensor5_helper_float32(0, %495, %tensor37)
}

def @tensor_array_unstack_tensor5_float64(%tensor38: Tensor[(?, ?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %496 = shape_of(%tensor38, dtype="int32");
  %497 = take(%496, 0);
  @tensor_array_unstack_tensor5_helper_float64(0, %497, %tensor38)
}

def @tensor_array_unstack_tensor5_helper_float16(%i36: int32, %up36: int32, %t38: Tensor[(?, ?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %498 = equal(%i36, %up36);
  if (%498) {
    Nil
  } else {
    %499 = take(%t38, %i36, axis=0);
    %500 = add(%i36, 1);
    %501 = tensor4_float16(%499);
    %502 = @tensor_array_unstack_tensor5_helper_float16(%500, %up36, %t38);
    Cons(%501, %502)
  }
}

def @tensor_array_unstack_tensor5_helper_float32(%i37: int32, %up37: int32, %t39: Tensor[(?, ?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %503 = equal(%i37, %up37);
  if (%503) {
    Nil
  } else {
    %504 = take(%t39, %i37, axis=0);
    %505 = add(%i37, 1);
    %506 = tensor4_float32(%504);
    %507 = @tensor_array_unstack_tensor5_helper_float32(%505, %up37, %t39);
    Cons(%506, %507)
  }
}

def @tensor_array_unstack_tensor5_helper_float64(%i38: int32, %up38: int32, %t40: Tensor[(?, ?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %508 = equal(%i38, %up38);
  if (%508) {
    Nil
  } else {
    %509 = take(%t40, %i38, axis=0);
    %510 = add(%i38, 1);
    %511 = tensor4_float64(%509);
    %512 = @tensor_array_unstack_tensor5_helper_float64(%510, %up38, %t40);
    Cons(%511, %512)
  }
}

def @tensor_array_unstack_tensor5_helper_int16(%i39: int32, %up39: int32, %t41: Tensor[(?, ?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %513 = equal(%i39, %up39);
  if (%513) {
    Nil
  } else {
    %514 = take(%t41, %i39, axis=0);
    %515 = add(%i39, 1);
    %516 = tensor4_int16(%514);
    %517 = @tensor_array_unstack_tensor5_helper_int16(%515, %up39, %t41);
    Cons(%516, %517)
  }
}

def @tensor_array_unstack_tensor5_helper_int32(%i40: int32, %up40: int32, %t42: Tensor[(?, ?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %518 = equal(%i40, %up40);
  if (%518) {
    Nil
  } else {
    %519 = take(%t42, %i40, axis=0);
    %520 = add(%i40, 1);
    %521 = tensor4_int32(%519);
    %522 = @tensor_array_unstack_tensor5_helper_int32(%520, %up40, %t42);
    Cons(%521, %522)
  }
}

def @tensor_array_unstack_tensor5_helper_int64(%i41: int32, %up41: int32, %t43: Tensor[(?, ?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %523 = equal(%i41, %up41);
  if (%523) {
    Nil
  } else {
    %524 = take(%t43, %i41, axis=0);
    %525 = add(%i41, 1);
    %526 = tensor4_int64(%524);
    %527 = @tensor_array_unstack_tensor5_helper_int64(%525, %up41, %t43);
    Cons(%526, %527)
  }
}

def @tensor_array_unstack_tensor5_helper_int8(%i42: int32, %up42: int32, %t44: Tensor[(?, ?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %528 = equal(%i42, %up42);
  if (%528) {
    Nil
  } else {
    %529 = take(%t44, %i42, axis=0);
    %530 = add(%i42, 1);
    %531 = tensor4_int8(%529);
    %532 = @tensor_array_unstack_tensor5_helper_int8(%530, %up42, %t44);
    Cons(%531, %532)
  }
}

def @tensor_array_unstack_tensor5_helper_uint16(%i43: int32, %up43: int32, %t45: Tensor[(?, ?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %533 = equal(%i43, %up43);
  if (%533) {
    Nil
  } else {
    %534 = take(%t45, %i43, axis=0);
    %535 = add(%i43, 1);
    %536 = tensor4_uint16(%534);
    %537 = @tensor_array_unstack_tensor5_helper_uint16(%535, %up43, %t45);
    Cons(%536, %537)
  }
}

def @tensor_array_unstack_tensor5_helper_uint8(%i44: int32, %up44: int32, %t46: Tensor[(?, ?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %538 = equal(%i44, %up44);
  if (%538) {
    Nil
  } else {
    %539 = take(%t46, %i44, axis=0);
    %540 = add(%i44, 1);
    %541 = tensor4_uint8(%539);
    %542 = @tensor_array_unstack_tensor5_helper_uint8(%540, %up44, %t46);
    Cons(%541, %542)
  }
}

def @tensor_array_unstack_tensor5_int16(%tensor39: Tensor[(?, ?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %543 = shape_of(%tensor39, dtype="int32");
  %544 = take(%543, 0);
  @tensor_array_unstack_tensor5_helper_int16(0, %544, %tensor39)
}

def @tensor_array_unstack_tensor5_int32(%tensor40: Tensor[(?, ?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %545 = shape_of(%tensor40, dtype="int32");
  %546 = take(%545, 0);
  @tensor_array_unstack_tensor5_helper_int32(0, %546, %tensor40)
}

def @tensor_array_unstack_tensor5_int64(%tensor41: Tensor[(?, ?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %547 = shape_of(%tensor41, dtype="int32");
  %548 = take(%547, 0);
  @tensor_array_unstack_tensor5_helper_int64(0, %548, %tensor41)
}

def @tensor_array_unstack_tensor5_int8(%tensor42: Tensor[(?, ?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %549 = shape_of(%tensor42, dtype="int32");
  %550 = take(%549, 0);
  @tensor_array_unstack_tensor5_helper_int8(0, %550, %tensor42)
}

def @tensor_array_unstack_tensor5_uint16(%tensor43: Tensor[(?, ?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %551 = shape_of(%tensor43, dtype="int32");
  %552 = take(%551, 0);
  @tensor_array_unstack_tensor5_helper_uint16(0, %552, %tensor43)
}

def @tensor_array_unstack_tensor5_uint8(%tensor44: Tensor[(?, ?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %553 = shape_of(%tensor44, dtype="int32");
  %554 = take(%553, 0);
  @tensor_array_unstack_tensor5_helper_uint8(0, %554, %tensor44)
}

def @tensor_array_unstack_tensor6_float16(%tensor45: Tensor[(?, ?, ?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %555 = shape_of(%tensor45, dtype="int32");
  %556 = take(%555, 0);
  @tensor_array_unstack_tensor6_helper_float16(0, %556, %tensor45)
}

def @tensor_array_unstack_tensor6_float32(%tensor46: Tensor[(?, ?, ?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %557 = shape_of(%tensor46, dtype="int32");
  %558 = take(%557, 0);
  @tensor_array_unstack_tensor6_helper_float32(0, %558, %tensor46)
}

def @tensor_array_unstack_tensor6_float64(%tensor47: Tensor[(?, ?, ?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %559 = shape_of(%tensor47, dtype="int32");
  %560 = take(%559, 0);
  @tensor_array_unstack_tensor6_helper_float64(0, %560, %tensor47)
}

def @tensor_array_unstack_tensor6_helper_float16(%i45: int32, %up45: int32, %t47: Tensor[(?, ?, ?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %561 = equal(%i45, %up45);
  if (%561) {
    Nil
  } else {
    %562 = take(%t47, %i45, axis=0);
    %563 = add(%i45, 1);
    %564 = tensor5_float16(%562);
    %565 = @tensor_array_unstack_tensor6_helper_float16(%563, %up45, %t47);
    Cons(%564, %565)
  }
}

def @tensor_array_unstack_tensor6_helper_float32(%i46: int32, %up46: int32, %t48: Tensor[(?, ?, ?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %566 = equal(%i46, %up46);
  if (%566) {
    Nil
  } else {
    %567 = take(%t48, %i46, axis=0);
    %568 = add(%i46, 1);
    %569 = tensor5_float32(%567);
    %570 = @tensor_array_unstack_tensor6_helper_float32(%568, %up46, %t48);
    Cons(%569, %570)
  }
}

def @tensor_array_unstack_tensor6_helper_float64(%i47: int32, %up47: int32, %t49: Tensor[(?, ?, ?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %571 = equal(%i47, %up47);
  if (%571) {
    Nil
  } else {
    %572 = take(%t49, %i47, axis=0);
    %573 = add(%i47, 1);
    %574 = tensor5_float64(%572);
    %575 = @tensor_array_unstack_tensor6_helper_float64(%573, %up47, %t49);
    Cons(%574, %575)
  }
}

def @tensor_array_unstack_tensor6_helper_int16(%i48: int32, %up48: int32, %t50: Tensor[(?, ?, ?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %576 = equal(%i48, %up48);
  if (%576) {
    Nil
  } else {
    %577 = take(%t50, %i48, axis=0);
    %578 = add(%i48, 1);
    %579 = tensor5_int16(%577);
    %580 = @tensor_array_unstack_tensor6_helper_int16(%578, %up48, %t50);
    Cons(%579, %580)
  }
}

def @tensor_array_unstack_tensor6_helper_int32(%i49: int32, %up49: int32, %t51: Tensor[(?, ?, ?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %581 = equal(%i49, %up49);
  if (%581) {
    Nil
  } else {
    %582 = take(%t51, %i49, axis=0);
    %583 = add(%i49, 1);
    %584 = tensor5_int32(%582);
    %585 = @tensor_array_unstack_tensor6_helper_int32(%583, %up49, %t51);
    Cons(%584, %585)
  }
}

def @tensor_array_unstack_tensor6_helper_int64(%i50: int32, %up50: int32, %t52: Tensor[(?, ?, ?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %586 = equal(%i50, %up50);
  if (%586) {
    Nil
  } else {
    %587 = take(%t52, %i50, axis=0);
    %588 = add(%i50, 1);
    %589 = tensor5_int64(%587);
    %590 = @tensor_array_unstack_tensor6_helper_int64(%588, %up50, %t52);
    Cons(%589, %590)
  }
}

def @tensor_array_unstack_tensor6_helper_int8(%i51: int32, %up51: int32, %t53: Tensor[(?, ?, ?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %591 = equal(%i51, %up51);
  if (%591) {
    Nil
  } else {
    %592 = take(%t53, %i51, axis=0);
    %593 = add(%i51, 1);
    %594 = tensor5_int8(%592);
    %595 = @tensor_array_unstack_tensor6_helper_int8(%593, %up51, %t53);
    Cons(%594, %595)
  }
}

def @tensor_array_unstack_tensor6_helper_uint16(%i52: int32, %up52: int32, %t54: Tensor[(?, ?, ?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %596 = equal(%i52, %up52);
  if (%596) {
    Nil
  } else {
    %597 = take(%t54, %i52, axis=0);
    %598 = add(%i52, 1);
    %599 = tensor5_uint16(%597);
    %600 = @tensor_array_unstack_tensor6_helper_uint16(%598, %up52, %t54);
    Cons(%599, %600)
  }
}

def @tensor_array_unstack_tensor6_helper_uint8(%i53: int32, %up53: int32, %t55: Tensor[(?, ?, ?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %601 = equal(%i53, %up53);
  if (%601) {
    Nil
  } else {
    %602 = take(%t55, %i53, axis=0);
    %603 = add(%i53, 1);
    %604 = tensor5_uint8(%602);
    %605 = @tensor_array_unstack_tensor6_helper_uint8(%603, %up53, %t55);
    Cons(%604, %605)
  }
}

def @tensor_array_unstack_tensor6_int16(%tensor48: Tensor[(?, ?, ?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %606 = shape_of(%tensor48, dtype="int32");
  %607 = take(%606, 0);
  @tensor_array_unstack_tensor6_helper_int16(0, %607, %tensor48)
}

def @tensor_array_unstack_tensor6_int32(%tensor49: Tensor[(?, ?, ?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %608 = shape_of(%tensor49, dtype="int32");
  %609 = take(%608, 0);
  @tensor_array_unstack_tensor6_helper_int32(0, %609, %tensor49)
}

def @tensor_array_unstack_tensor6_int64(%tensor50: Tensor[(?, ?, ?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %610 = shape_of(%tensor50, dtype="int32");
  %611 = take(%610, 0);
  @tensor_array_unstack_tensor6_helper_int64(0, %611, %tensor50)
}

def @tensor_array_unstack_tensor6_int8(%tensor51: Tensor[(?, ?, ?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %612 = shape_of(%tensor51, dtype="int32");
  %613 = take(%612, 0);
  @tensor_array_unstack_tensor6_helper_int8(0, %613, %tensor51)
}

def @tensor_array_unstack_tensor6_uint16(%tensor52: Tensor[(?, ?, ?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %614 = shape_of(%tensor52, dtype="int32");
  %615 = take(%614, 0);
  @tensor_array_unstack_tensor6_helper_uint16(0, %615, %tensor52)
}

def @tensor_array_unstack_tensor6_uint8(%tensor53: Tensor[(?, ?, ?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %616 = shape_of(%tensor53, dtype="int32");
  %617 = take(%616, 0);
  @tensor_array_unstack_tensor6_helper_uint8(0, %617, %tensor53)
}

def @tensor_array_write_float16(%tensor_array54: List[tensor_float16_t[]], %x30: int32, %v: tensor_float16_t[]) -> List[tensor_float16_t[]] {
  @update(%tensor_array54, %x30, %v)
}

def @tensor_array_write_float32(%tensor_array55: List[tensor_float32_t[]], %x31: int32, %v1: tensor_float32_t[]) -> List[tensor_float32_t[]] {
  @update(%tensor_array55, %x31, %v1)
}

def @tensor_array_write_float64(%tensor_array56: List[tensor_float64_t[]], %x32: int32, %v2: tensor_float64_t[]) -> List[tensor_float64_t[]] {
  @update(%tensor_array56, %x32, %v2)
}

def @tensor_array_write_int16(%tensor_array57: List[tensor_int16_t[]], %x33: int32, %v3: tensor_int16_t[]) -> List[tensor_int16_t[]] {
  @update(%tensor_array57, %x33, %v3)
}

def @tensor_array_write_int32(%tensor_array58: List[tensor_int32_t[]], %x34: int32, %v4: tensor_int32_t[]) -> List[tensor_int32_t[]] {
  @update(%tensor_array58, %x34, %v4)
}

def @tensor_array_write_int64(%tensor_array59: List[tensor_int64_t[]], %x35: int32, %v5: tensor_int64_t[]) -> List[tensor_int64_t[]] {
  @update(%tensor_array59, %x35, %v5)
}

def @tensor_array_write_int8(%tensor_array60: List[tensor_int8_t[]], %x36: int32, %v6: tensor_int8_t[]) -> List[tensor_int8_t[]] {
  @update(%tensor_array60, %x36, %v6)
}

def @tensor_array_write_uint16(%tensor_array61: List[tensor_uint16_t[]], %x37: int32, %v7: tensor_uint16_t[]) -> List[tensor_uint16_t[]] {
  @update(%tensor_array61, %x37, %v7)
}

def @tensor_array_write_uint8(%tensor_array62: List[tensor_uint8_t[]], %x38: int32, %v8: tensor_uint8_t[]) -> List[tensor_uint8_t[]] {
  @update(%tensor_array62, %x38, %v8)
}

def @tensor_concatenate_float16(%x39: tensor_float16_t[], %y1: tensor_float16_t[]) -> tensor_float16_t[] {
  match? (%x39) {
    tensor1_float16(%t111) => {
      match? (%y1) {
        tensor1_float16(%t121) => {
          %618 = (%t111, %t121);
          %619 = concatenate(%618);
          tensor1_float16(%619)
        },
      }
    },
    tensor2_float16(%t211) => {
      match? (%y1) {
        tensor2_float16(%t221) => {
          %620 = (%t211, %t221);
          %621 = concatenate(%620);
          tensor2_float16(%621)
        },
      }
    },
    tensor3_float16(%t311) => {
      match? (%y1) {
        tensor3_float16(%t321) => {
          %622 = (%t311, %t321);
          %623 = concatenate(%622);
          tensor3_float16(%623)
        },
      }
    },
    tensor4_float16(%t411) => {
      match? (%y1) {
        tensor4_float16(%t421) => {
          %624 = (%t411, %t421);
          %625 = concatenate(%624);
          tensor4_float16(%625)
        },
      }
    },
  }
}

def @tensor_concatenate_float32(%x40: tensor_float32_t[], %y2: tensor_float32_t[]) -> tensor_float32_t[] {
  match? (%x40) {
    tensor1_float32(%t112) => {
      match? (%y2) {
        tensor1_float32(%t122) => {
          %626 = (%t112, %t122);
          %627 = concatenate(%626);
          tensor1_float32(%627)
        },
      }
    },
    tensor2_float32(%t212) => {
      match? (%y2) {
        tensor2_float32(%t222) => {
          %628 = (%t212, %t222);
          %629 = concatenate(%628);
          tensor2_float32(%629)
        },
      }
    },
    tensor3_float32(%t312) => {
      match? (%y2) {
        tensor3_float32(%t322) => {
          %630 = (%t312, %t322);
          %631 = concatenate(%630);
          tensor3_float32(%631)
        },
      }
    },
    tensor4_float32(%t412) => {
      match? (%y2) {
        tensor4_float32(%t422) => {
          %632 = (%t412, %t422);
          %633 = concatenate(%632);
          tensor4_float32(%633)
        },
      }
    },
  }
}

def @tensor_concatenate_float64(%x41: tensor_float64_t[], %y3: tensor_float64_t[]) -> tensor_float64_t[] {
  match? (%x41) {
    tensor1_float64(%t113) => {
      match? (%y3) {
        tensor1_float64(%t123) => {
          %634 = (%t113, %t123);
          %635 = concatenate(%634);
          tensor1_float64(%635)
        },
      }
    },
    tensor2_float64(%t213) => {
      match? (%y3) {
        tensor2_float64(%t223) => {
          %636 = (%t213, %t223);
          %637 = concatenate(%636);
          tensor2_float64(%637)
        },
      }
    },
    tensor3_float64(%t313) => {
      match? (%y3) {
        tensor3_float64(%t323) => {
          %638 = (%t313, %t323);
          %639 = concatenate(%638);
          tensor3_float64(%639)
        },
      }
    },
    tensor4_float64(%t413) => {
      match? (%y3) {
        tensor4_float64(%t423) => {
          %640 = (%t413, %t423);
          %641 = concatenate(%640);
          tensor4_float64(%641)
        },
      }
    },
  }
}

def @tensor_concatenate_int16(%x42: tensor_int16_t[], %y4: tensor_int16_t[]) -> tensor_int16_t[] {
  match? (%x42) {
    tensor1_int16(%t114) => {
      match? (%y4) {
        tensor1_int16(%t124) => {
          %642 = (%t114, %t124);
          %643 = concatenate(%642);
          tensor1_int16(%643)
        },
      }
    },
    tensor2_int16(%t214) => {
      match? (%y4) {
        tensor2_int16(%t224) => {
          %644 = (%t214, %t224);
          %645 = concatenate(%644);
          tensor2_int16(%645)
        },
      }
    },
    tensor3_int16(%t314) => {
      match? (%y4) {
        tensor3_int16(%t324) => {
          %646 = (%t314, %t324);
          %647 = concatenate(%646);
          tensor3_int16(%647)
        },
      }
    },
    tensor4_int16(%t414) => {
      match? (%y4) {
        tensor4_int16(%t424) => {
          %648 = (%t414, %t424);
          %649 = concatenate(%648);
          tensor4_int16(%649)
        },
      }
    },
  }
}

def @tensor_concatenate_int32(%x43: tensor_int32_t[], %y5: tensor_int32_t[]) -> tensor_int32_t[] {
  match? (%x43) {
    tensor1_int32(%t115) => {
      match? (%y5) {
        tensor1_int32(%t125) => {
          %650 = (%t115, %t125);
          %651 = concatenate(%650);
          tensor1_int32(%651)
        },
      }
    },
    tensor2_int32(%t215) => {
      match? (%y5) {
        tensor2_int32(%t225) => {
          %652 = (%t215, %t225);
          %653 = concatenate(%652);
          tensor2_int32(%653)
        },
      }
    },
    tensor3_int32(%t315) => {
      match? (%y5) {
        tensor3_int32(%t325) => {
          %654 = (%t315, %t325);
          %655 = concatenate(%654);
          tensor3_int32(%655)
        },
      }
    },
    tensor4_int32(%t415) => {
      match? (%y5) {
        tensor4_int32(%t425) => {
          %656 = (%t415, %t425);
          %657 = concatenate(%656);
          tensor4_int32(%657)
        },
      }
    },
  }
}

def @tensor_concatenate_int64(%x44: tensor_int64_t[], %y6: tensor_int64_t[]) -> tensor_int64_t[] {
  match? (%x44) {
    tensor1_int64(%t116) => {
      match? (%y6) {
        tensor1_int64(%t126) => {
          %658 = (%t116, %t126);
          %659 = concatenate(%658);
          tensor1_int64(%659)
        },
      }
    },
    tensor2_int64(%t216) => {
      match? (%y6) {
        tensor2_int64(%t226) => {
          %660 = (%t216, %t226);
          %661 = concatenate(%660);
          tensor2_int64(%661)
        },
      }
    },
    tensor3_int64(%t316) => {
      match? (%y6) {
        tensor3_int64(%t326) => {
          %662 = (%t316, %t326);
          %663 = concatenate(%662);
          tensor3_int64(%663)
        },
      }
    },
    tensor4_int64(%t416) => {
      match? (%y6) {
        tensor4_int64(%t426) => {
          %664 = (%t416, %t426);
          %665 = concatenate(%664);
          tensor4_int64(%665)
        },
      }
    },
  }
}

def @tensor_concatenate_int8(%x45: tensor_int8_t[], %y7: tensor_int8_t[]) -> tensor_int8_t[] {
  match? (%x45) {
    tensor1_int8(%t117) => {
      match? (%y7) {
        tensor1_int8(%t127) => {
          %666 = (%t117, %t127);
          %667 = concatenate(%666);
          tensor1_int8(%667)
        },
      }
    },
    tensor2_int8(%t217) => {
      match? (%y7) {
        tensor2_int8(%t227) => {
          %668 = (%t217, %t227);
          %669 = concatenate(%668);
          tensor2_int8(%669)
        },
      }
    },
    tensor3_int8(%t317) => {
      match? (%y7) {
        tensor3_int8(%t327) => {
          %670 = (%t317, %t327);
          %671 = concatenate(%670);
          tensor3_int8(%671)
        },
      }
    },
    tensor4_int8(%t417) => {
      match? (%y7) {
        tensor4_int8(%t427) => {
          %672 = (%t417, %t427);
          %673 = concatenate(%672);
          tensor4_int8(%673)
        },
      }
    },
  }
}

def @tensor_concatenate_uint16(%x46: tensor_uint16_t[], %y8: tensor_uint16_t[]) -> tensor_uint16_t[] {
  match? (%x46) {
    tensor1_uint16(%t118) => {
      match? (%y8) {
        tensor1_uint16(%t128) => {
          %674 = (%t118, %t128);
          %675 = concatenate(%674);
          tensor1_uint16(%675)
        },
      }
    },
    tensor2_uint16(%t218) => {
      match? (%y8) {
        tensor2_uint16(%t228) => {
          %676 = (%t218, %t228);
          %677 = concatenate(%676);
          tensor2_uint16(%677)
        },
      }
    },
    tensor3_uint16(%t318) => {
      match? (%y8) {
        tensor3_uint16(%t328) => {
          %678 = (%t318, %t328);
          %679 = concatenate(%678);
          tensor3_uint16(%679)
        },
      }
    },
    tensor4_uint16(%t418) => {
      match? (%y8) {
        tensor4_uint16(%t428) => {
          %680 = (%t418, %t428);
          %681 = concatenate(%680);
          tensor4_uint16(%681)
        },
      }
    },
  }
}

def @tensor_concatenate_uint8(%x47: tensor_uint8_t[], %y9: tensor_uint8_t[]) -> tensor_uint8_t[] {
  match? (%x47) {
    tensor1_uint8(%t119) => {
      match? (%y9) {
        tensor1_uint8(%t129) => {
          %682 = (%t119, %t129);
          %683 = concatenate(%682);
          tensor1_uint8(%683)
        },
      }
    },
    tensor2_uint8(%t219) => {
      match? (%y9) {
        tensor2_uint8(%t229) => {
          %684 = (%t219, %t229);
          %685 = concatenate(%684);
          tensor2_uint8(%685)
        },
      }
    },
    tensor3_uint8(%t319) => {
      match? (%y9) {
        tensor3_uint8(%t329) => {
          %686 = (%t319, %t329);
          %687 = concatenate(%686);
          tensor3_uint8(%687)
        },
      }
    },
    tensor4_uint8(%t419) => {
      match? (%y9) {
        tensor4_uint8(%t429) => {
          %688 = (%t419, %t429);
          %689 = concatenate(%688);
          tensor4_uint8(%689)
        },
      }
    },
  }
}

def @tensor_expand_dims_float16(%x48: tensor_float16_t[]) -> tensor_float16_t[] {
  match? (%x48) {
    tensor0_float16(%t0) => {
      %690 = expand_dims(%t0, axis=0);
      tensor1_float16(%690)
    },
    tensor1_float16(%t110) => {
      %691 = expand_dims(%t110, axis=0);
      tensor2_float16(%691)
    },
    tensor2_float16(%t210) => {
      %692 = expand_dims(%t210, axis=0);
      tensor3_float16(%692)
    },
    tensor3_float16(%t310) => {
      %693 = expand_dims(%t310, axis=0);
      tensor4_float16(%693)
    },
    tensor4_float16(%t410) => {
      %694 = expand_dims(%t410, axis=0);
      tensor5_float16(%694)
    },
    tensor5_float16(%t56) => {
      %695 = expand_dims(%t56, axis=0);
      tensor6_float16(%695)
    },
  }
}

def @tensor_expand_dims_float32(%x49: tensor_float32_t[]) -> tensor_float32_t[] {
  match? (%x49) {
    tensor0_float32(%t01) => {
      %696 = expand_dims(%t01, axis=0);
      tensor1_float32(%696)
    },
    tensor1_float32(%t120) => {
      %697 = expand_dims(%t120, axis=0);
      tensor2_float32(%697)
    },
    tensor2_float32(%t220) => {
      %698 = expand_dims(%t220, axis=0);
      tensor3_float32(%698)
    },
    tensor3_float32(%t320) => {
      %699 = expand_dims(%t320, axis=0);
      tensor4_float32(%699)
    },
    tensor4_float32(%t420) => {
      %700 = expand_dims(%t420, axis=0);
      tensor5_float32(%700)
    },
    tensor5_float32(%t57) => {
      %701 = expand_dims(%t57, axis=0);
      tensor6_float32(%701)
    },
  }
}

def @tensor_expand_dims_float64(%x50: tensor_float64_t[]) -> tensor_float64_t[] {
  match? (%x50) {
    tensor0_float64(%t02) => {
      %702 = expand_dims(%t02, axis=0);
      tensor1_float64(%702)
    },
    tensor1_float64(%t130) => {
      %703 = expand_dims(%t130, axis=0);
      tensor2_float64(%703)
    },
    tensor2_float64(%t230) => {
      %704 = expand_dims(%t230, axis=0);
      tensor3_float64(%704)
    },
    tensor3_float64(%t330) => {
      %705 = expand_dims(%t330, axis=0);
      tensor4_float64(%705)
    },
    tensor4_float64(%t430) => {
      %706 = expand_dims(%t430, axis=0);
      tensor5_float64(%706)
    },
    tensor5_float64(%t58) => {
      %707 = expand_dims(%t58, axis=0);
      tensor6_float64(%707)
    },
  }
}

def @tensor_expand_dims_int16(%x51: tensor_int16_t[]) -> tensor_int16_t[] {
  match? (%x51) {
    tensor0_int16(%t03) => {
      %708 = expand_dims(%t03, axis=0);
      tensor1_int16(%708)
    },
    tensor1_int16(%t131) => {
      %709 = expand_dims(%t131, axis=0);
      tensor2_int16(%709)
    },
    tensor2_int16(%t231) => {
      %710 = expand_dims(%t231, axis=0);
      tensor3_int16(%710)
    },
    tensor3_int16(%t331) => {
      %711 = expand_dims(%t331, axis=0);
      tensor4_int16(%711)
    },
    tensor4_int16(%t431) => {
      %712 = expand_dims(%t431, axis=0);
      tensor5_int16(%712)
    },
    tensor5_int16(%t59) => {
      %713 = expand_dims(%t59, axis=0);
      tensor6_int16(%713)
    },
  }
}

def @tensor_expand_dims_int32(%x52: tensor_int32_t[]) -> tensor_int32_t[] {
  match? (%x52) {
    tensor0_int32(%t04) => {
      %714 = expand_dims(%t04, axis=0);
      tensor1_int32(%714)
    },
    tensor1_int32(%t132) => {
      %715 = expand_dims(%t132, axis=0);
      tensor2_int32(%715)
    },
    tensor2_int32(%t232) => {
      %716 = expand_dims(%t232, axis=0);
      tensor3_int32(%716)
    },
    tensor3_int32(%t332) => {
      %717 = expand_dims(%t332, axis=0);
      tensor4_int32(%717)
    },
    tensor4_int32(%t432) => {
      %718 = expand_dims(%t432, axis=0);
      tensor5_int32(%718)
    },
    tensor5_int32(%t510) => {
      %719 = expand_dims(%t510, axis=0);
      tensor6_int32(%719)
    },
  }
}

def @tensor_expand_dims_int64(%x53: tensor_int64_t[]) -> tensor_int64_t[] {
  match? (%x53) {
    tensor0_int64(%t05) => {
      %720 = expand_dims(%t05, axis=0);
      tensor1_int64(%720)
    },
    tensor1_int64(%t133) => {
      %721 = expand_dims(%t133, axis=0);
      tensor2_int64(%721)
    },
    tensor2_int64(%t233) => {
      %722 = expand_dims(%t233, axis=0);
      tensor3_int64(%722)
    },
    tensor3_int64(%t333) => {
      %723 = expand_dims(%t333, axis=0);
      tensor4_int64(%723)
    },
    tensor4_int64(%t433) => {
      %724 = expand_dims(%t433, axis=0);
      tensor5_int64(%724)
    },
    tensor5_int64(%t511) => {
      %725 = expand_dims(%t511, axis=0);
      tensor6_int64(%725)
    },
  }
}

def @tensor_expand_dims_int8(%x54: tensor_int8_t[]) -> tensor_int8_t[] {
  match? (%x54) {
    tensor0_int8(%t06) => {
      %726 = expand_dims(%t06, axis=0);
      tensor1_int8(%726)
    },
    tensor1_int8(%t134) => {
      %727 = expand_dims(%t134, axis=0);
      tensor2_int8(%727)
    },
    tensor2_int8(%t234) => {
      %728 = expand_dims(%t234, axis=0);
      tensor3_int8(%728)
    },
    tensor3_int8(%t334) => {
      %729 = expand_dims(%t334, axis=0);
      tensor4_int8(%729)
    },
    tensor4_int8(%t434) => {
      %730 = expand_dims(%t434, axis=0);
      tensor5_int8(%730)
    },
    tensor5_int8(%t512) => {
      %731 = expand_dims(%t512, axis=0);
      tensor6_int8(%731)
    },
  }
}

def @tensor_expand_dims_uint16(%x55: tensor_uint16_t[]) -> tensor_uint16_t[] {
  match? (%x55) {
    tensor0_uint16(%t07) => {
      %732 = expand_dims(%t07, axis=0);
      tensor1_uint16(%732)
    },
    tensor1_uint16(%t135) => {
      %733 = expand_dims(%t135, axis=0);
      tensor2_uint16(%733)
    },
    tensor2_uint16(%t235) => {
      %734 = expand_dims(%t235, axis=0);
      tensor3_uint16(%734)
    },
    tensor3_uint16(%t335) => {
      %735 = expand_dims(%t335, axis=0);
      tensor4_uint16(%735)
    },
    tensor4_uint16(%t435) => {
      %736 = expand_dims(%t435, axis=0);
      tensor5_uint16(%736)
    },
    tensor5_uint16(%t513) => {
      %737 = expand_dims(%t513, axis=0);
      tensor6_uint16(%737)
    },
  }
}

def @tensor_expand_dims_uint8(%x56: tensor_uint8_t[]) -> tensor_uint8_t[] {
  match? (%x56) {
    tensor0_uint8(%t08) => {
      %738 = expand_dims(%t08, axis=0);
      tensor1_uint8(%738)
    },
    tensor1_uint8(%t136) => {
      %739 = expand_dims(%t136, axis=0);
      tensor2_uint8(%739)
    },
    tensor2_uint8(%t236) => {
      %740 = expand_dims(%t236, axis=0);
      tensor3_uint8(%740)
    },
    tensor3_uint8(%t336) => {
      %741 = expand_dims(%t336, axis=0);
      tensor4_uint8(%741)
    },
    tensor4_uint8(%t436) => {
      %742 = expand_dims(%t436, axis=0);
      tensor5_uint8(%742)
    },
    tensor5_uint8(%t514) => {
      %743 = expand_dims(%t514, axis=0);
      tensor6_uint8(%743)
    },
  }
}

def @tensor_take_float16(%tensor54: tensor_float16_t[], %lower: int32, %upper: int32) -> tensor_float16_t[] {
  match? (%tensor54) {
    tensor1_float16(%t137) => {
      %744 = arange(%lower, %upper, 1, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][0], dtype="int32");
      %745 = take(%t137, %744);
      tensor1_float16(%745)
    },
    tensor2_float16(%t237) => {
      %746 = arange(%lower, %upper, 1, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][1], dtype="int32");
      %747 = take(%t237, %746, axis=0);
      tensor2_float16(%747)
    },
    tensor3_float16(%t337) => {
      %748 = arange(%lower, %upper, 1, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][2], dtype="int32");
      %749 = take(%t337, %748, axis=0);
      tensor3_float16(%749)
    },
    tensor4_float16(%t437) => {
      %750 = arange(%lower, %upper, 1, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][3], dtype="int32");
      %751 = take(%t437, %750, axis=0);
      tensor4_float16(%751)
    },
    tensor5_float16(%t515) => {
      %752 = arange(%lower, %upper, 1, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][4], dtype="int32");
      %753 = take(%t515, %752, axis=0);
      tensor5_float16(%753)
    },
    tensor6_float16(%t61) => {
      %754 = arange(%lower, %upper, 1, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][5], dtype="int32");
      %755 = take(%t61, %754, axis=0);
      tensor6_float16(%755)
    },
  }
}

def @tensor_take_float32(%tensor55: tensor_float32_t[], %lower1: int32, %upper1: int32) -> tensor_float32_t[] {
  match? (%tensor55) {
    tensor1_float32(%t138) => {
      %756 = arange(%lower1, %upper1, 1, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][6], dtype="int32");
      %757 = take(%t138, %756);
      tensor1_float32(%757)
    },
    tensor2_float32(%t238) => {
      %758 = arange(%lower1, %upper1, 1, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][7], dtype="int32");
      %759 = take(%t238, %758, axis=0);
      tensor2_float32(%759)
    },
    tensor3_float32(%t338) => {
      %760 = arange(%lower1, %upper1, 1, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][8], dtype="int32");
      %761 = take(%t338, %760, axis=0);
      tensor3_float32(%761)
    },
    tensor4_float32(%t438) => {
      %762 = arange(%lower1, %upper1, 1, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][9], dtype="int32");
      %763 = take(%t438, %762, axis=0);
      tensor4_float32(%763)
    },
    tensor5_float32(%t516) => {
      %764 = arange(%lower1, %upper1, 1, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][10], dtype="int32");
      %765 = take(%t516, %764, axis=0);
      tensor5_float32(%765)
    },
    tensor6_float32(%t62) => {
      %766 = arange(%lower1, %upper1, 1, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][11], dtype="int32");
      %767 = take(%t62, %766, axis=0);
      tensor6_float32(%767)
    },
  }
}

def @tensor_take_float64(%tensor56: tensor_float64_t[], %lower2: int32, %upper2: int32) -> tensor_float64_t[] {
  match? (%tensor56) {
    tensor1_float64(%t139) => {
      %768 = arange(%lower2, %upper2, 1, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][12], dtype="int32");
      %769 = take(%t139, %768);
      tensor1_float64(%769)
    },
    tensor2_float64(%t239) => {
      %770 = arange(%lower2, %upper2, 1, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][13], dtype="int32");
      %771 = take(%t239, %770, axis=0);
      tensor2_float64(%771)
    },
    tensor3_float64(%t339) => {
      %772 = arange(%lower2, %upper2, 1, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][14], dtype="int32");
      %773 = take(%t339, %772, axis=0);
      tensor3_float64(%773)
    },
    tensor4_float64(%t439) => {
      %774 = arange(%lower2, %upper2, 1, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][15], dtype="int32");
      %775 = take(%t439, %774, axis=0);
      tensor4_float64(%775)
    },
    tensor5_float64(%t517) => {
      %776 = arange(%lower2, %upper2, 1, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][16], dtype="int32");
      %777 = take(%t517, %776, axis=0);
      tensor5_float64(%777)
    },
    tensor6_float64(%t63) => {
      %778 = arange(%lower2, %upper2, 1, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][17], dtype="int32");
      %779 = take(%t63, %778, axis=0);
      tensor6_float64(%779)
    },
  }
}

def @tensor_take_int16(%tensor57: tensor_int16_t[], %lower3: int32, %upper3: int32) -> tensor_int16_t[] {
  match? (%tensor57) {
    tensor1_int16(%t140) => {
      %780 = arange(%lower3, %upper3, 1, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][18], dtype="int32");
      %781 = take(%t140, %780);
      tensor1_int16(%781)
    },
    tensor2_int16(%t240) => {
      %782 = arange(%lower3, %upper3, 1, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][19], dtype="int32");
      %783 = take(%t240, %782, axis=0);
      tensor2_int16(%783)
    },
    tensor3_int16(%t340) => {
      %784 = arange(%lower3, %upper3, 1, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][20], dtype="int32");
      %785 = take(%t340, %784, axis=0);
      tensor3_int16(%785)
    },
    tensor4_int16(%t440) => {
      %786 = arange(%lower3, %upper3, 1, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][21], dtype="int32");
      %787 = take(%t440, %786, axis=0);
      tensor4_int16(%787)
    },
    tensor5_int16(%t518) => {
      %788 = arange(%lower3, %upper3, 1, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][22], dtype="int32");
      %789 = take(%t518, %788, axis=0);
      tensor5_int16(%789)
    },
    tensor6_int16(%t64) => {
      %790 = arange(%lower3, %upper3, 1, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][23], dtype="int32");
      %791 = take(%t64, %790, axis=0);
      tensor6_int16(%791)
    },
  }
}

def @tensor_take_int32(%tensor58: tensor_int32_t[], %lower4: int32, %upper4: int32) -> tensor_int32_t[] {
  match? (%tensor58) {
    tensor1_int32(%t141) => {
      %792 = arange(%lower4, %upper4, 1, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][24], dtype="int32");
      %793 = take(%t141, %792);
      tensor1_int32(%793)
    },
    tensor2_int32(%t241) => {
      %794 = arange(%lower4, %upper4, 1, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][25], dtype="int32");
      %795 = take(%t241, %794, axis=0);
      tensor2_int32(%795)
    },
    tensor3_int32(%t341) => {
      %796 = arange(%lower4, %upper4, 1, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][26], dtype="int32");
      %797 = take(%t341, %796, axis=0);
      tensor3_int32(%797)
    },
    tensor4_int32(%t441) => {
      %798 = arange(%lower4, %upper4, 1, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][27], dtype="int32");
      %799 = take(%t441, %798, axis=0);
      tensor4_int32(%799)
    },
    tensor5_int32(%t519) => {
      %800 = arange(%lower4, %upper4, 1, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][28], dtype="int32");
      %801 = take(%t519, %800, axis=0);
      tensor5_int32(%801)
    },
    tensor6_int32(%t65) => {
      %802 = arange(%lower4, %upper4, 1, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][29], dtype="int32");
      %803 = take(%t65, %802, axis=0);
      tensor6_int32(%803)
    },
  }
}

def @tensor_take_int64(%tensor59: tensor_int64_t[], %lower5: int32, %upper5: int32) -> tensor_int64_t[] {
  match? (%tensor59) {
    tensor1_int64(%t142) => {
      %804 = arange(%lower5, %upper5, 1, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][30], dtype="int32");
      %805 = take(%t142, %804);
      tensor1_int64(%805)
    },
    tensor2_int64(%t242) => {
      %806 = arange(%lower5, %upper5, 1, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][31], dtype="int32");
      %807 = take(%t242, %806, axis=0);
      tensor2_int64(%807)
    },
    tensor3_int64(%t342) => {
      %808 = arange(%lower5, %upper5, 1, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][32], dtype="int32");
      %809 = take(%t342, %808, axis=0);
      tensor3_int64(%809)
    },
    tensor4_int64(%t442) => {
      %810 = arange(%lower5, %upper5, 1, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][33], dtype="int32");
      %811 = take(%t442, %810, axis=0);
      tensor4_int64(%811)
    },
    tensor5_int64(%t520) => {
      %812 = arange(%lower5, %upper5, 1, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][34], dtype="int32");
      %813 = take(%t520, %812, axis=0);
      tensor5_int64(%813)
    },
    tensor6_int64(%t66) => {
      %814 = arange(%lower5, %upper5, 1, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][35], dtype="int32");
      %815 = take(%t66, %814, axis=0);
      tensor6_int64(%815)
    },
  }
}

def @tensor_take_int8(%tensor60: tensor_int8_t[], %lower6: int32, %upper6: int32) -> tensor_int8_t[] {
  match? (%tensor60) {
    tensor1_int8(%t143) => {
      %816 = arange(%lower6, %upper6, 1, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][36], dtype="int32");
      %817 = take(%t143, %816);
      tensor1_int8(%817)
    },
    tensor2_int8(%t243) => {
      %818 = arange(%lower6, %upper6, 1, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][37], dtype="int32");
      %819 = take(%t243, %818, axis=0);
      tensor2_int8(%819)
    },
    tensor3_int8(%t343) => {
      %820 = arange(%lower6, %upper6, 1, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][38], dtype="int32");
      %821 = take(%t343, %820, axis=0);
      tensor3_int8(%821)
    },
    tensor4_int8(%t443) => {
      %822 = arange(%lower6, %upper6, 1, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][39], dtype="int32");
      %823 = take(%t443, %822, axis=0);
      tensor4_int8(%823)
    },
    tensor5_int8(%t521) => {
      %824 = arange(%lower6, %upper6, 1, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][40], dtype="int32");
      %825 = take(%t521, %824, axis=0);
      tensor5_int8(%825)
    },
    tensor6_int8(%t67) => {
      %826 = arange(%lower6, %upper6, 1, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][41], dtype="int32");
      %827 = take(%t67, %826, axis=0);
      tensor6_int8(%827)
    },
  }
}

def @tensor_take_uint16(%tensor61: tensor_uint16_t[], %lower7: int32, %upper7: int32) -> tensor_uint16_t[] {
  match? (%tensor61) {
    tensor1_uint16(%t144) => {
      %828 = arange(%lower7, %upper7, 1, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][42], dtype="int32");
      %829 = take(%t144, %828);
      tensor1_uint16(%829)
    },
    tensor2_uint16(%t244) => {
      %830 = arange(%lower7, %upper7, 1, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][43], dtype="int32");
      %831 = take(%t244, %830, axis=0);
      tensor2_uint16(%831)
    },
    tensor3_uint16(%t344) => {
      %832 = arange(%lower7, %upper7, 1, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][44], dtype="int32");
      %833 = take(%t344, %832, axis=0);
      tensor3_uint16(%833)
    },
    tensor4_uint16(%t444) => {
      %834 = arange(%lower7, %upper7, 1, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][45], dtype="int32");
      %835 = take(%t444, %834, axis=0);
      tensor4_uint16(%835)
    },
    tensor5_uint16(%t522) => {
      %836 = arange(%lower7, %upper7, 1, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][46], dtype="int32");
      %837 = take(%t522, %836, axis=0);
      tensor5_uint16(%837)
    },
    tensor6_uint16(%t68) => {
      %838 = arange(%lower7, %upper7, 1, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][47], dtype="int32");
      %839 = take(%t68, %838, axis=0);
      tensor6_uint16(%839)
    },
  }
}

def @tensor_take_uint8(%tensor62: tensor_uint8_t[], %lower8: int32, %upper8: int32) -> tensor_uint8_t[] {
  match? (%tensor62) {
    tensor1_uint8(%t145) => {
      %840 = arange(%lower8, %upper8, 1, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][48], dtype="int32");
      %841 = take(%t145, %840);
      tensor1_uint8(%841)
    },
    tensor2_uint8(%t245) => {
      %842 = arange(%lower8, %upper8, 1, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][49], dtype="int32");
      %843 = take(%t245, %842, axis=0);
      tensor2_uint8(%843)
    },
    tensor3_uint8(%t345) => {
      %844 = arange(%lower8, %upper8, 1, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][50], dtype="int32");
      %845 = take(%t345, %844, axis=0);
      tensor3_uint8(%845)
    },
    tensor4_uint8(%t445) => {
      %846 = arange(%lower8, %upper8, 1, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][51], dtype="int32");
      %847 = take(%t445, %846, axis=0);
      tensor4_uint8(%847)
    },
    tensor5_uint8(%t523) => {
      %848 = arange(%lower8, %upper8, 1, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][52], dtype="int32");
      %849 = take(%t523, %848, axis=0);
      tensor5_uint8(%849)
    },
    tensor6_uint8(%t69) => {
      %850 = arange(%lower8, %upper8, 1, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][53], dtype="int32");
      %851 = take(%t69, %850, axis=0);
      tensor6_uint8(%851)
    },
  }
}

def @tl[A](%xs13: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:59:11 */) -> List[A] {
  match? (%xs13) {
    Cons(_, %rest6: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:60:23 */) => {
      %rest6
    },
  }
}

def @tmap[A, B](%f10: fn (A) -> B /* ty=fn (A) -> B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:280:12 */, %t60: Tree[A] /* ty=Tree[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:275:9 */) -> Tree[B] {
  match (%t60) {
    Rose(%v9: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:280:15 */, %sub_trees1: List[Tree[A]] /* ty=List[Tree[A]] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:280:35 */) => {
      let %list_f: fn (Tree[A]) -> Tree[B] /* ty=fn (Tree[A]) -> Tree[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:280:26 */ = fn (%tt: Tree[A] /* ty=Tree[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:278:19 */) -> Tree[B] {
        @tmap(%f10, %tt) /* ty=Tree[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:278:9 */
      } /* ty=fn (Tree[A]) -> Tree[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:277:7 */;
      %852 = %f10(%v9) /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:280:12 */;
      %853 = @map(%list_f, %sub_trees1) /* ty=List[Tree[B]] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:280:20 */;
      Rose(%852, %853) /* ty=Tree[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:280:7 */
    },
  }
}

def @unfoldl[A, B](%f11: fn (A) -> Option[(A, B)] /* ty=fn (A) -> Option[(A, B)] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:258:17 */, %seed: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:258:21 */) -> List[B] {
  %854 = @unfoldr(%f11, %seed) /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:258:8 */;
  @rev(%854) /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:258:3 */
}

def @unfoldr[A, B](%f12: fn (A) -> Option[(A, B)] /* ty=fn (A) -> Option[(A, B)] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:245:41 */, %seed1: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:244:14 */) -> List[B] {
  %855 = %f12(%seed1) /* ty=Option[(A, B)] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:244:10 */;
  match (%855) {
    Some(%val: (A, B) /* ty=(A, B) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:245:45 */) => {
      %856 = %val.0 /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:245:45 */;
      %857 = %val.1 /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:245:24 */;
      %858 = @unfoldr(%f12, %856) /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:245:32 */;
      Cons(%857, %858) /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:245:19 */
    },
    None => {
      Nil /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:246:13 */
    },
  }
}

def @update[A](%xs14: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:32 */, %n2: int32 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:38 */, %v10: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:46 */) -> List[A] {
  %859 = equal(%n2, 0 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:89:15 */) /* ty=bool span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:89:7 */;
  if (%859) {
    %860 = @tl(%xs14) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:90:14 */;
    Cons(%v10, %860) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:90:5 */
  } else {
    %861 = @tl(%xs14) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:28 */;
    %862 = subtract(%n2, 1 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:44 */) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:38 */;
    %863 = @hd(%xs14) /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:10 */;
    %864 = @update(%861, %862, %v10) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:20 */;
    Cons(%863, %864) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:5 */
  }
}

def @zip[A, B](%xs15: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:187:11 */, %ys1: List[B] /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:187:16 */) -> List[(A, B)] {
  %865 = (%xs15, %ys1) /* ty=(List[A], List[B]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:187:10 */;
  match (%865) {
    (Cons(%x57: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:188:53 */, %x_rest: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:188:67 */), Cons(%y10: B /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:188:57 */, %y_rest: List[B] /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:188:76 */)) => {
      %866 = (%x57, %y10) /* ty=(A, B) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:188:52 */;
      %867 = @zip(%x_rest, %y_rest) /* ty=List[(A, B)] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:188:62 */;
      Cons(%866, %867) /* ty=List[(A, B)] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:188:47 */
    },
    _ => {
      Nil /* ty=List[(A, B)] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:189:10 */
    },
  }
}

#[metadata]
{
  "root": 1, 
  "nodes": [
    {
      "type_key": ""
    }, 
    {
      "type_key": "Map", 
      "keys": [
        "relay.Constant", 
        "relay.Var"
      ], 
      "data": [2, 59]
    }, 
    {
      "type_key": "Array", 
      "data": [
        3, 
        6, 
        7, 
        8, 
        9, 
        10, 
        11, 
        12, 
        13, 
        14, 
        15, 
        16, 
        17, 
        18, 
        19, 
        20, 
        21, 
        22, 
        23, 
        24, 
        25, 
        26, 
        27, 
        28, 
        29, 
        30, 
        31, 
        32, 
        33, 
        34, 
        35, 
        36, 
        37, 
        38, 
        39, 
        40, 
        41, 
        42, 
        43, 
        44, 
        45, 
        46, 
        47, 
        48, 
        49, 
        50, 
        51, 
        52, 
        53, 
        54, 
        55, 
        56, 
        57, 
        58
      ]
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "0", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "VirtualDevice", 
      "attrs": {
        "device_type_int": "-1", 
        "memory_scope": "5", 
        "target": "0", 
        "virtual_device_id": "-1"
      }
    }, 
    {
      "type_key": "runtime.String"
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "1", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "2", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "3", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "4", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "5", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "6", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "7", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "8", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "9", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "10", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "11", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "12", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "13", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "14", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "15", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "16", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "17", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "18", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "19", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "20", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "21", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "22", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "23", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "24", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "25", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "26", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "27", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "28", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "29", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "30", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "31", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "32", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "33", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "34", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "35", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "36", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "37", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "38", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "39", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "40", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "41", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "42", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "43", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "44", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "45", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "46", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "47", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "48", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "49", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "50", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "51", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "52", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "53", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [
        60, 
        65, 
        70, 
        75, 
        80, 
        85, 
        90, 
        95, 
        100, 
        105, 
        110, 
        115, 
        120, 
        125, 
        130, 
        135, 
        140, 
        145
      ]
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "63", 
        "vid": "61", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "62"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "64", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "68", 
        "vid": "66", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "67"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "69", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "73", 
        "vid": "71", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "72"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "74", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "78", 
        "vid": "76", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "77"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "79", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "83", 
        "vid": "81", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "82"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "84", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "88", 
        "vid": "86", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "87"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "89", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "93", 
        "vid": "91", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "92"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "94", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "98", 
        "vid": "96", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "97"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "99", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "103", 
        "vid": "101", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "102"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "104", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "108", 
        "vid": "106", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "107"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "109", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "113", 
        "vid": "111", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "112"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "114", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "118", 
        "vid": "116", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "117"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "119", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "123", 
        "vid": "121", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "122"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "124", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "128", 
        "vid": "126", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "127"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "129", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "133", 
        "vid": "131", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "132"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "134", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "138", 
        "vid": "136", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "137"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "139", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "143", 
        "vid": "141", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "142"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "144", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "148", 
        "vid": "146", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "147"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "149", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }
  ], 
  "b64ndarrays": [
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA="
  ], 
  "attrs": {"tvm_version": "0.13.dev0"}
}