#[version = "0.0.5"]
type List[A] {
  Cons(A, List[A]),
  Nil,
}

type Option[A] {
  Some(A),
  None,
}

type Tree[A] {
  Rose(A, List[Tree[A]]),
}

type tensor_float16_t {
  tensor_nil_float16,
  tensor0_float16(float16),
  tensor1_float16(Tensor[(?), float16]),
  tensor2_float16(Tensor[(?, ?), float16]),
  tensor3_float16(Tensor[(?, ?, ?), float16]),
  tensor4_float16(Tensor[(?, ?, ?, ?), float16]),
  tensor5_float16(Tensor[(?, ?, ?, ?, ?), float16]),
  tensor6_float16(Tensor[(?, ?, ?, ?, ?, ?), float16]),
}

type tensor_float32_t {
  tensor_nil_float32,
  tensor0_float32(float32),
  tensor1_float32(Tensor[(?), float32]),
  tensor2_float32(Tensor[(?, ?), float32]),
  tensor3_float32(Tensor[(?, ?, ?), float32]),
  tensor4_float32(Tensor[(?, ?, ?, ?), float32]),
  tensor5_float32(Tensor[(?, ?, ?, ?, ?), float32]),
  tensor6_float32(Tensor[(?, ?, ?, ?, ?, ?), float32]),
}

type tensor_float64_t {
  tensor_nil_float64,
  tensor0_float64(float64),
  tensor1_float64(Tensor[(?), float64]),
  tensor2_float64(Tensor[(?, ?), float64]),
  tensor3_float64(Tensor[(?, ?, ?), float64]),
  tensor4_float64(Tensor[(?, ?, ?, ?), float64]),
  tensor5_float64(Tensor[(?, ?, ?, ?, ?), float64]),
  tensor6_float64(Tensor[(?, ?, ?, ?, ?, ?), float64]),
}

type tensor_int16_t {
  tensor_nil_int16,
  tensor0_int16(int16),
  tensor1_int16(Tensor[(?), int16]),
  tensor2_int16(Tensor[(?, ?), int16]),
  tensor3_int16(Tensor[(?, ?, ?), int16]),
  tensor4_int16(Tensor[(?, ?, ?, ?), int16]),
  tensor5_int16(Tensor[(?, ?, ?, ?, ?), int16]),
  tensor6_int16(Tensor[(?, ?, ?, ?, ?, ?), int16]),
}

type tensor_int32_t {
  tensor_nil_int32,
  tensor0_int32(int32),
  tensor1_int32(Tensor[(?), int32]),
  tensor2_int32(Tensor[(?, ?), int32]),
  tensor3_int32(Tensor[(?, ?, ?), int32]),
  tensor4_int32(Tensor[(?, ?, ?, ?), int32]),
  tensor5_int32(Tensor[(?, ?, ?, ?, ?), int32]),
  tensor6_int32(Tensor[(?, ?, ?, ?, ?, ?), int32]),
}

type tensor_int64_t {
  tensor_nil_int64,
  tensor0_int64(int64),
  tensor1_int64(Tensor[(?), int64]),
  tensor2_int64(Tensor[(?, ?), int64]),
  tensor3_int64(Tensor[(?, ?, ?), int64]),
  tensor4_int64(Tensor[(?, ?, ?, ?), int64]),
  tensor5_int64(Tensor[(?, ?, ?, ?, ?), int64]),
  tensor6_int64(Tensor[(?, ?, ?, ?, ?, ?), int64]),
}

type tensor_int8_t {
  tensor_nil_int8,
  tensor0_int8(int8),
  tensor1_int8(Tensor[(?), int8]),
  tensor2_int8(Tensor[(?, ?), int8]),
  tensor3_int8(Tensor[(?, ?, ?), int8]),
  tensor4_int8(Tensor[(?, ?, ?, ?), int8]),
  tensor5_int8(Tensor[(?, ?, ?, ?, ?), int8]),
  tensor6_int8(Tensor[(?, ?, ?, ?, ?, ?), int8]),
}

type tensor_uint16_t {
  tensor_nil_uint16,
  tensor0_uint16(uint16),
  tensor1_uint16(Tensor[(?), uint16]),
  tensor2_uint16(Tensor[(?, ?), uint16]),
  tensor3_uint16(Tensor[(?, ?, ?), uint16]),
  tensor4_uint16(Tensor[(?, ?, ?, ?), uint16]),
  tensor5_uint16(Tensor[(?, ?, ?, ?, ?), uint16]),
  tensor6_uint16(Tensor[(?, ?, ?, ?, ?, ?), uint16]),
}

type tensor_uint8_t {
  tensor_nil_uint8,
  tensor0_uint8(uint8),
  tensor1_uint8(Tensor[(?), uint8]),
  tensor2_uint8(Tensor[(?, ?), uint8]),
  tensor3_uint8(Tensor[(?, ?, ?), uint8]),
  tensor4_uint8(Tensor[(?, ?, ?, ?), uint8]),
  tensor5_uint8(Tensor[(?, ?, ?, ?, ?), uint8]),
  tensor6_uint8(Tensor[(?, ?, ?, ?, ?, ?), uint8]),
}

def @compose[A, B, C](%f: fn (B) -> C /* ty=fn (B) -> C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:27:5 */, %g: fn (A) -> B /* ty=fn (A) -> B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:27:8 */) -> fn (A) -> C {
  fn (%x: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:27:11 */) -> C {
    %0 = %g(%x) /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:27:8 */;
    %f(%0) /* ty=C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:27:5 */
  } /* ty=fn (A) -> C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:26:3 */
}

def @concat[A](%xs: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:162:21 */, %ys: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:162:16 */) -> List[A] {
  @foldr(Cons, %ys, %xs) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:162:3 */
}

def @filter[A](%f1: fn (A) -> bool /* ty=fn (A) -> bool span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:174:17 */, %xs1: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:169:10 */) -> List[A] {
  match (%xs1) {
    Cons(%x1: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:172:14 */, %rest: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:174:21 */) => {
      %1 = %f1(%x1) /* ty=bool span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:171:11 */;
      if (%1) {
        %2 = @filter(%f1, %rest) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:172:18 */;
        Cons(%x1, %2) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:172:9 */
      } else {
        @filter(%f1, %rest) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:174:9 */
      }
    },
    Nil => {
      Nil /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:177:12 */
    },
  }
}

def @flip[A, B, C](%f2: fn (A, B) -> C /* ty=fn (A, B) -> C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:33:5 */) -> fn (B, A) -> C {
  fn (%b: B /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:33:12 */, %a: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:33:8 */) -> C {
    %f2(%a, %b) /* ty=C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:33:5 */
  } /* ty=fn (B, A) -> C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:32:3 */
}

def @foldl[A, B](%f3: fn (A, B) -> A /* ty=fn (A, B) -> A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:115:35 */, %acc: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:116:12 */, %xs2: List[B] /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:114:10 */) -> A {
  match (%xs2) {
    Cons(%x2: B /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:115:44 */, %rest1: List[B] /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:115:49 */) => {
      %3 = %f3(%acc, %x2) /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:115:35 */;
      @foldl(%f3, %3, %rest1) /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:115:24 */
    },
    Nil => {
      %acc
    },
  }
}

def @foldr[A, B](%f4: fn (A, B) -> B /* ty=fn (A, B) -> B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:128:38 */, %acc1: B /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:129:12 */, %xs3: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:127:10 */) -> B {
  match (%xs3) {
    Cons(%x3: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:128:27 */, %rest2: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:128:48 */) => {
      %4 = @foldr(%f4, %acc1, %rest2) /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:128:31 */;
      %f4(%x3, %4) /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:128:24 */
    },
    Nil => {
      %acc1
    },
  }
}

def @foldr1[A](%f5: fn (A, A) -> A /* ty=fn (A, A) -> A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:142:39 */, %xs4: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:140:11 */) -> A {
  match? (%xs4) {
    Cons(%x4: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:141:22 */, Nil) => {
      %x4
    },
    Cons(%x5: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:142:27 */, %rest3: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:142:43 */) => {
      %5 = @foldr1(%f5, %rest3) /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:142:31 */;
      %f5(%x5, %5) /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:142:24 */
    },
  }
}

def @hd[A](%xs5: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:50:11 */) -> A {
  match? (%xs5) {
    Cons(%x6: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:51:20 */, _) => {
      %x6
    },
  }
}

def @id[A](%x7: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:22:3 */) -> A {
  %x7
}

def @iterate[A](%f6: fn (A) -> A /* ty=fn (A) -> A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:304:28 */, %n: int32 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:304:32 */) -> fn (A) -> A {
  %6 = equal(%n, 0 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:301:15 */) /* ty=bool span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:301:7 */;
  if (%6) {
    @id
  } else {
    %7 = subtract(%n, 1 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:304:38 */) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:304:32 */;
    %8 = @iterate(%f6, %7) /* ty=fn (A) -> A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:304:18 */;
    @compose(%f6, %8) /* ty=fn [A](A) -> A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:304:5 */
  }
}

def @length[A](%xs6: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:79:10 */) -> int32 {
  match (%xs6) {
    Cons(_, %rest4: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:80:35 */) => {
      %9 = @length(%rest4) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:80:27 */;
      add(1 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:80:24 */, %9) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:80:24 */
    },
    Nil => {
      0 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:81:13 */
    },
  }
}

def @main(%x8: Tensor[(1, 16), float32]) {
  %x8
}

def @map[A, B](%f7: fn (A) -> B /* ty=fn (A) -> B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:102:43 */, %xs7: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:101:10 */) -> List[B] {
  match (%xs7) {
    Cons(%x9: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:102:32 */, %rest5: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:102:47 */) => {
      %10 = %f7(%x9) /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:102:29 */;
      %11 = @map(%f7, %rest5) /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:102:37 */;
      Cons(%10, %11) /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:102:24 */
    },
    Nil => {
      Nil /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:103:12 */
    },
  }
}

def @map_accuml[A, B, C](%f8: fn (A, B) -> (A, C) /* ty=fn (A, B) -> (A, C) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:222:18 */, %init: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:225:21 */, %xs8: List[B] /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:225:36 */) -> (A, List[C]) {
  let %updater: fn ((A, List[C]), B) -> (A, List[C]) /* ty=fn ((A, List[C]), B) -> (A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:225:10 */ = fn (%acc2: (A, List[C]) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:223:31 */, %x10: B /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:222:29 */) -> (A, List[C]) {
    %12 = %acc2.0 /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:222:21 */;
    let %f_out: (A, C) /* ty=(A, C) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:223:21 */ = %f8(%12, %x10) /* ty=(A, C) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:222:18 */;
    %13 = %f_out.1 /* ty=C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:223:21 */;
    %14 = %acc2.1 /* ty=List[C] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:223:31 */;
    %15 = %f_out.0 /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:223:6 */;
    %16 = Cons(%13, %14) /* ty=List[C] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:223:16 */;
    (%15, %16) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:223:5 */
  } /* ty=fn ((A, List[C]), B) -> (A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:221:3 */;
  %17 = Nil /* ty=List[C] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:225:30 */;
  %18 = (%init, %17) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:225:20 */;
  @foldl(%updater, %18, %xs8) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:225:3 */
}

def @map_accumr[A, B, C](%f9: fn (A, B) -> (A, C) /* ty=fn (A, B) -> (A, C) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:208:18 */, %init1: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:211:21 */, %xs9: List[B] /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:211:36 */) -> (A, List[C]) {
  let %updater1: fn (B, (A, List[C])) -> (A, List[C]) /* ty=fn (B, (A, List[C])) -> (A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:211:10 */ = fn (%x11: B /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:208:29 */, %acc3: (A, List[C]) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:209:31 */) -> (A, List[C]) {
    %19 = %acc3.0 /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:208:21 */;
    let %f_out1: (A, C) /* ty=(A, C) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:209:21 */ = %f9(%19, %x11) /* ty=(A, C) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:208:18 */;
    %20 = %f_out1.1 /* ty=C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:209:21 */;
    %21 = %acc3.1 /* ty=List[C] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:209:31 */;
    %22 = %f_out1.0 /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:209:6 */;
    %23 = Cons(%20, %21) /* ty=List[C] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:209:16 */;
    (%22, %23) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:209:5 */
  } /* ty=fn (B, (A, List[C])) -> (A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:207:3 */;
  %24 = Nil /* ty=List[C] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:211:30 */;
  %25 = (%init1, %24) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:211:20 */;
  @foldr(%updater1, %25, %xs9) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:211:3 */
}

def @nth[A](%xs10: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:71:14 */, %n1: int32 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:71:20 */) -> A {
  %26 = equal(%n1, 0 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:68:15 */) /* ty=bool span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:68:7 */;
  if (%26) {
    @hd(%xs10) /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:69:5 */
  } else {
    %27 = @tl(%xs10) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:71:10 */;
    %28 = subtract(%n1, 1 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:71:26 */) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:71:20 */;
    @nth(%27, %28) /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:71:5 */
  }
}

def @rev[A](%xs11: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:64 */) -> List[A] {
  %29 = fn (%h: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:47 */, %t: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:51 */) -> List[A] {
    Cons(%h, %t) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:42 */
  } /* ty=fn (A, List[A]) -> List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:16 */;
  %30 = @flip(%29) /* ty=fn (List[A], A) -> List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:10 */;
  %31 = Nil /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:59 */;
  @foldl(%30, %31, %xs11) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:3 */
}

def @size[A](%t1: Tree[A] /* ty=Tree[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:289:9 */) -> int32 {
  match (%t1) {
    Rose(_, %sub_trees: List[Tree[A]] /* ty=List[Tree[A]] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:291:29 */) => {
      %32 = @map(@size, %sub_trees) /* ty=List[int32] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:291:16 */;
      %33 = @sum(%32) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:291:11 */;
      add(1 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:291:8 */, %33) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:290:5 */
    },
  }
}

def @sum(%xs12: List[int32] /* ty=List[int32] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:154:21 */) -> int32 {
  let %add_f: fn (int32, int32) -> int32 /* ty=fn (int32, int32) -> int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:154:10 */ = fn (%x12: int32 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:152:5 */, %y: int32 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:152:10 */) -> int32 {
    add(%x12, %y) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:152:5 */
  } /* ty=fn (int32, int32) -> int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:151:3 */;
  @foldl(%add_f, 0 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:154:19 */, %xs12) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:154:3 */
}

def @ta_split_helper_float16(%tensor_array: List[tensor_float16_t[]], %value1: tensor_float16_t[], %offset1: int32, %current1: int32, %limit1: int32, %lengths: Tensor[(?), int32]) -> List[tensor_float16_t[]] {
  %34 = equal(%current1, %limit1);
  if (%34) {
    %tensor_array
  } else {
    %35 = take(%lengths, %current1);
    %36 = add(%offset1, %35);
    %37 = add(%current1, 1);
    %38 = take(%lengths, %current1);
    %39 = add(%38, %offset1);
    %40 = @ta_split_helper_float16(%tensor_array, %value1, %36, %37, %limit1, %lengths);
    %41 = @tensor_take_float16(%value1, %offset1, %39);
    @tensor_array_write_float16(%40, %current1, %41)
  }
}

def @ta_split_helper_float32(%tensor_array1: List[tensor_float32_t[]], %value11: tensor_float32_t[], %offset11: int32, %current11: int32, %limit11: int32, %lengths1: Tensor[(?), int32]) -> List[tensor_float32_t[]] {
  %42 = equal(%current11, %limit11);
  if (%42) {
    %tensor_array1
  } else {
    %43 = take(%lengths1, %current11);
    %44 = add(%offset11, %43);
    %45 = add(%current11, 1);
    %46 = take(%lengths1, %current11);
    %47 = add(%46, %offset11);
    %48 = @ta_split_helper_float32(%tensor_array1, %value11, %44, %45, %limit11, %lengths1);
    %49 = @tensor_take_float32(%value11, %offset11, %47);
    @tensor_array_write_float32(%48, %current11, %49)
  }
}

def @ta_split_helper_float64(%tensor_array2: List[tensor_float64_t[]], %value12: tensor_float64_t[], %offset12: int32, %current12: int32, %limit12: int32, %lengths2: Tensor[(?), int32]) -> List[tensor_float64_t[]] {
  %50 = equal(%current12, %limit12);
  if (%50) {
    %tensor_array2
  } else {
    %51 = take(%lengths2, %current12);
    %52 = add(%offset12, %51);
    %53 = add(%current12, 1);
    %54 = take(%lengths2, %current12);
    %55 = add(%54, %offset12);
    %56 = @ta_split_helper_float64(%tensor_array2, %value12, %52, %53, %limit12, %lengths2);
    %57 = @tensor_take_float64(%value12, %offset12, %55);
    @tensor_array_write_float64(%56, %current12, %57)
  }
}

def @ta_split_helper_int16(%tensor_array3: List[tensor_int16_t[]], %value13: tensor_int16_t[], %offset13: int32, %current13: int32, %limit13: int32, %lengths3: Tensor[(?), int32]) -> List[tensor_int16_t[]] {
  %58 = equal(%current13, %limit13);
  if (%58) {
    %tensor_array3
  } else {
    %59 = take(%lengths3, %current13);
    %60 = add(%offset13, %59);
    %61 = add(%current13, 1);
    %62 = take(%lengths3, %current13);
    %63 = add(%62, %offset13);
    %64 = @ta_split_helper_int16(%tensor_array3, %value13, %60, %61, %limit13, %lengths3);
    %65 = @tensor_take_int16(%value13, %offset13, %63);
    @tensor_array_write_int16(%64, %current13, %65)
  }
}

def @ta_split_helper_int32(%tensor_array4: List[tensor_int32_t[]], %value14: tensor_int32_t[], %offset14: int32, %current14: int32, %limit14: int32, %lengths4: Tensor[(?), int32]) -> List[tensor_int32_t[]] {
  %66 = equal(%current14, %limit14);
  if (%66) {
    %tensor_array4
  } else {
    %67 = take(%lengths4, %current14);
    %68 = add(%offset14, %67);
    %69 = add(%current14, 1);
    %70 = take(%lengths4, %current14);
    %71 = add(%70, %offset14);
    %72 = @ta_split_helper_int32(%tensor_array4, %value14, %68, %69, %limit14, %lengths4);
    %73 = @tensor_take_int32(%value14, %offset14, %71);
    @tensor_array_write_int32(%72, %current14, %73)
  }
}

def @ta_split_helper_int64(%tensor_array5: List[tensor_int64_t[]], %value15: tensor_int64_t[], %offset15: int32, %current15: int32, %limit15: int32, %lengths5: Tensor[(?), int32]) -> List[tensor_int64_t[]] {
  %74 = equal(%current15, %limit15);
  if (%74) {
    %tensor_array5
  } else {
    %75 = take(%lengths5, %current15);
    %76 = add(%offset15, %75);
    %77 = add(%current15, 1);
    %78 = take(%lengths5, %current15);
    %79 = add(%78, %offset15);
    %80 = @ta_split_helper_int64(%tensor_array5, %value15, %76, %77, %limit15, %lengths5);
    %81 = @tensor_take_int64(%value15, %offset15, %79);
    @tensor_array_write_int64(%80, %current15, %81)
  }
}

def @ta_split_helper_int8(%tensor_array6: List[tensor_int8_t[]], %value16: tensor_int8_t[], %offset16: int32, %current16: int32, %limit16: int32, %lengths6: Tensor[(?), int32]) -> List[tensor_int8_t[]] {
  %82 = equal(%current16, %limit16);
  if (%82) {
    %tensor_array6
  } else {
    %83 = take(%lengths6, %current16);
    %84 = add(%offset16, %83);
    %85 = add(%current16, 1);
    %86 = take(%lengths6, %current16);
    %87 = add(%86, %offset16);
    %88 = @ta_split_helper_int8(%tensor_array6, %value16, %84, %85, %limit16, %lengths6);
    %89 = @tensor_take_int8(%value16, %offset16, %87);
    @tensor_array_write_int8(%88, %current16, %89)
  }
}

def @ta_split_helper_uint16(%tensor_array7: List[tensor_uint16_t[]], %value17: tensor_uint16_t[], %offset17: int32, %current17: int32, %limit17: int32, %lengths7: Tensor[(?), int32]) -> List[tensor_uint16_t[]] {
  %90 = equal(%current17, %limit17);
  if (%90) {
    %tensor_array7
  } else {
    %91 = take(%lengths7, %current17);
    %92 = add(%offset17, %91);
    %93 = add(%current17, 1);
    %94 = take(%lengths7, %current17);
    %95 = add(%94, %offset17);
    %96 = @ta_split_helper_uint16(%tensor_array7, %value17, %92, %93, %limit17, %lengths7);
    %97 = @tensor_take_uint16(%value17, %offset17, %95);
    @tensor_array_write_uint16(%96, %current17, %97)
  }
}

def @ta_split_helper_uint8(%tensor_array8: List[tensor_uint8_t[]], %value18: tensor_uint8_t[], %offset18: int32, %current18: int32, %limit18: int32, %lengths8: Tensor[(?), int32]) -> List[tensor_uint8_t[]] {
  %98 = equal(%current18, %limit18);
  if (%98) {
    %tensor_array8
  } else {
    %99 = take(%lengths8, %current18);
    %100 = add(%offset18, %99);
    %101 = add(%current18, 1);
    %102 = take(%lengths8, %current18);
    %103 = add(%102, %offset18);
    %104 = @ta_split_helper_uint8(%tensor_array8, %value18, %100, %101, %limit18, %lengths8);
    %105 = @tensor_take_uint8(%value18, %offset18, %103);
    @tensor_array_write_uint8(%104, %current18, %105)
  }
}

def @tensor_array_concat_float16(%tensor_array9: List[tensor_float16_t[]]) -> tensor_float16_t[] {
  match? (%tensor_array9) {
    Nil => {
      tensor_nil_float16
    },
    Cons(%hd, %tl) => {
      match? (%tl) {
        Nil => {
          %hd
        },
        _ => {
          %106 = @tensor_array_concat_float16(%tl);
          @tensor_concatenate_float16(%hd, %106)
        },
      }
    },
  }
}

def @tensor_array_concat_float32(%tensor_array10: List[tensor_float32_t[]]) -> tensor_float32_t[] {
  match? (%tensor_array10) {
    Nil => {
      tensor_nil_float32
    },
    Cons(%hd1, %tl1) => {
      match? (%tl1) {
        Nil => {
          %hd1
        },
        _ => {
          %107 = @tensor_array_concat_float32(%tl1);
          @tensor_concatenate_float32(%hd1, %107)
        },
      }
    },
  }
}

def @tensor_array_concat_float64(%tensor_array11: List[tensor_float64_t[]]) -> tensor_float64_t[] {
  match? (%tensor_array11) {
    Nil => {
      tensor_nil_float64
    },
    Cons(%hd2, %tl2) => {
      match? (%tl2) {
        Nil => {
          %hd2
        },
        _ => {
          %108 = @tensor_array_concat_float64(%tl2);
          @tensor_concatenate_float64(%hd2, %108)
        },
      }
    },
  }
}

def @tensor_array_concat_int16(%tensor_array12: List[tensor_int16_t[]]) -> tensor_int16_t[] {
  match? (%tensor_array12) {
    Nil => {
      tensor_nil_int16
    },
    Cons(%hd3, %tl3) => {
      match? (%tl3) {
        Nil => {
          %hd3
        },
        _ => {
          %109 = @tensor_array_concat_int16(%tl3);
          @tensor_concatenate_int16(%hd3, %109)
        },
      }
    },
  }
}

def @tensor_array_concat_int32(%tensor_array13: List[tensor_int32_t[]]) -> tensor_int32_t[] {
  match? (%tensor_array13) {
    Nil => {
      tensor_nil_int32
    },
    Cons(%hd4, %tl4) => {
      match? (%tl4) {
        Nil => {
          %hd4
        },
        _ => {
          %110 = @tensor_array_concat_int32(%tl4);
          @tensor_concatenate_int32(%hd4, %110)
        },
      }
    },
  }
}

def @tensor_array_concat_int64(%tensor_array14: List[tensor_int64_t[]]) -> tensor_int64_t[] {
  match? (%tensor_array14) {
    Nil => {
      tensor_nil_int64
    },
    Cons(%hd5, %tl5) => {
      match? (%tl5) {
        Nil => {
          %hd5
        },
        _ => {
          %111 = @tensor_array_concat_int64(%tl5);
          @tensor_concatenate_int64(%hd5, %111)
        },
      }
    },
  }
}

def @tensor_array_concat_int8(%tensor_array15: List[tensor_int8_t[]]) -> tensor_int8_t[] {
  match? (%tensor_array15) {
    Nil => {
      tensor_nil_int8
    },
    Cons(%hd6, %tl6) => {
      match? (%tl6) {
        Nil => {
          %hd6
        },
        _ => {
          %112 = @tensor_array_concat_int8(%tl6);
          @tensor_concatenate_int8(%hd6, %112)
        },
      }
    },
  }
}

def @tensor_array_concat_uint16(%tensor_array16: List[tensor_uint16_t[]]) -> tensor_uint16_t[] {
  match? (%tensor_array16) {
    Nil => {
      tensor_nil_uint16
    },
    Cons(%hd7, %tl7) => {
      match? (%tl7) {
        Nil => {
          %hd7
        },
        _ => {
          %113 = @tensor_array_concat_uint16(%tl7);
          @tensor_concatenate_uint16(%hd7, %113)
        },
      }
    },
  }
}

def @tensor_array_concat_uint8(%tensor_array17: List[tensor_uint8_t[]]) -> tensor_uint8_t[] {
  match? (%tensor_array17) {
    Nil => {
      tensor_nil_uint8
    },
    Cons(%hd8, %tl8) => {
      match? (%tl8) {
        Nil => {
          %hd8
        },
        _ => {
          %114 = @tensor_array_concat_uint8(%tl8);
          @tensor_concatenate_uint8(%hd8, %114)
        },
      }
    },
  }
}

def @tensor_array_float16(%x13: int32) -> List[tensor_float16_t[]] {
  %115 = equal(%x13, 0);
  if (%115) {
    Nil
  } else {
    %116 = subtract(%x13, 1);
    %117 = tensor_nil_float16;
    %118 = @tensor_array_float16(%116);
    Cons(%117, %118)
  }
}

def @tensor_array_float32(%x14: int32) -> List[tensor_float32_t[]] {
  %119 = equal(%x14, 0);
  if (%119) {
    Nil
  } else {
    %120 = subtract(%x14, 1);
    %121 = tensor_nil_float32;
    %122 = @tensor_array_float32(%120);
    Cons(%121, %122)
  }
}

def @tensor_array_float64(%x15: int32) -> List[tensor_float64_t[]] {
  %123 = equal(%x15, 0);
  if (%123) {
    Nil
  } else {
    %124 = subtract(%x15, 1);
    %125 = tensor_nil_float64;
    %126 = @tensor_array_float64(%124);
    Cons(%125, %126)
  }
}

def @tensor_array_int16(%x16: int32) -> List[tensor_int16_t[]] {
  %127 = equal(%x16, 0);
  if (%127) {
    Nil
  } else {
    %128 = subtract(%x16, 1);
    %129 = tensor_nil_int16;
    %130 = @tensor_array_int16(%128);
    Cons(%129, %130)
  }
}

def @tensor_array_int32(%x17: int32) -> List[tensor_int32_t[]] {
  %131 = equal(%x17, 0);
  if (%131) {
    Nil
  } else {
    %132 = subtract(%x17, 1);
    %133 = tensor_nil_int32;
    %134 = @tensor_array_int32(%132);
    Cons(%133, %134)
  }
}

def @tensor_array_int64(%x18: int32) -> List[tensor_int64_t[]] {
  %135 = equal(%x18, 0);
  if (%135) {
    Nil
  } else {
    %136 = subtract(%x18, 1);
    %137 = tensor_nil_int64;
    %138 = @tensor_array_int64(%136);
    Cons(%137, %138)
  }
}

def @tensor_array_int8(%x19: int32) -> List[tensor_int8_t[]] {
  %139 = equal(%x19, 0);
  if (%139) {
    Nil
  } else {
    %140 = subtract(%x19, 1);
    %141 = tensor_nil_int8;
    %142 = @tensor_array_int8(%140);
    Cons(%141, %142)
  }
}

def @tensor_array_read_float16(%tensor_array18: List[tensor_float16_t[]], %x20: int32) -> tensor_float16_t[] {
  @nth(%tensor_array18, %x20)
}

def @tensor_array_read_float32(%tensor_array19: List[tensor_float32_t[]], %x21: int32) -> tensor_float32_t[] {
  @nth(%tensor_array19, %x21)
}

def @tensor_array_read_float64(%tensor_array20: List[tensor_float64_t[]], %x22: int32) -> tensor_float64_t[] {
  @nth(%tensor_array20, %x22)
}

def @tensor_array_read_int16(%tensor_array21: List[tensor_int16_t[]], %x23: int32) -> tensor_int16_t[] {
  @nth(%tensor_array21, %x23)
}

def @tensor_array_read_int32(%tensor_array22: List[tensor_int32_t[]], %x24: int32) -> tensor_int32_t[] {
  @nth(%tensor_array22, %x24)
}

def @tensor_array_read_int64(%tensor_array23: List[tensor_int64_t[]], %x25: int32) -> tensor_int64_t[] {
  @nth(%tensor_array23, %x25)
}

def @tensor_array_read_int8(%tensor_array24: List[tensor_int8_t[]], %x26: int32) -> tensor_int8_t[] {
  @nth(%tensor_array24, %x26)
}

def @tensor_array_read_uint16(%tensor_array25: List[tensor_uint16_t[]], %x27: int32) -> tensor_uint16_t[] {
  @nth(%tensor_array25, %x27)
}

def @tensor_array_read_uint8(%tensor_array26: List[tensor_uint8_t[]], %x28: int32) -> tensor_uint8_t[] {
  @nth(%tensor_array26, %x28)
}

def @tensor_array_scatter_float16(%tensor_array27: List[tensor_float16_t[]], %indices: Tensor[(?), int32], %values: List[tensor_float16_t[]]) -> List[tensor_float16_t[]] {
  %143 = shape_of(%indices, dtype="int32");
  %144 = take(%143, 0);
  @tensor_array_scatter_helper_float16(%tensor_array27, 0, %144, %indices, %values)
}

def @tensor_array_scatter_float32(%tensor_array28: List[tensor_float32_t[]], %indices1: Tensor[(?), int32], %values1: List[tensor_float32_t[]]) -> List[tensor_float32_t[]] {
  %145 = shape_of(%indices1, dtype="int32");
  %146 = take(%145, 0);
  @tensor_array_scatter_helper_float32(%tensor_array28, 0, %146, %indices1, %values1)
}

def @tensor_array_scatter_float64(%tensor_array29: List[tensor_float64_t[]], %indices2: Tensor[(?), int32], %values2: List[tensor_float64_t[]]) -> List[tensor_float64_t[]] {
  %147 = shape_of(%indices2, dtype="int32");
  %148 = take(%147, 0);
  @tensor_array_scatter_helper_float64(%tensor_array29, 0, %148, %indices2, %values2)
}

def @tensor_array_scatter_helper_float16(%ta: List[tensor_float16_t[]], %current: int32, %limit: int32, %indices_: Tensor[(?), int32], %values_: List[tensor_float16_t[]]) -> List[tensor_float16_t[]] {
  %149 = equal(%current, %limit);
  if (%149) {
    %ta
  } else {
    %150 = take(%indices_, %current);
    %151 = @tensor_array_read_float16(%values_, %current);
    %152 = @tensor_array_write_float16(%ta, %150, %151);
    %153 = add(%current, 1);
    @tensor_array_scatter_helper_float16(%152, %153, %limit, %indices_, %values_)
  }
}

def @tensor_array_scatter_helper_float32(%ta1: List[tensor_float32_t[]], %current2: int32, %limit2: int32, %indices_1: Tensor[(?), int32], %values_1: List[tensor_float32_t[]]) -> List[tensor_float32_t[]] {
  %154 = equal(%current2, %limit2);
  if (%154) {
    %ta1
  } else {
    %155 = take(%indices_1, %current2);
    %156 = @tensor_array_read_float32(%values_1, %current2);
    %157 = @tensor_array_write_float32(%ta1, %155, %156);
    %158 = add(%current2, 1);
    @tensor_array_scatter_helper_float32(%157, %158, %limit2, %indices_1, %values_1)
  }
}

def @tensor_array_scatter_helper_float64(%ta2: List[tensor_float64_t[]], %current3: int32, %limit3: int32, %indices_2: Tensor[(?), int32], %values_2: List[tensor_float64_t[]]) -> List[tensor_float64_t[]] {
  %159 = equal(%current3, %limit3);
  if (%159) {
    %ta2
  } else {
    %160 = take(%indices_2, %current3);
    %161 = @tensor_array_read_float64(%values_2, %current3);
    %162 = @tensor_array_write_float64(%ta2, %160, %161);
    %163 = add(%current3, 1);
    @tensor_array_scatter_helper_float64(%162, %163, %limit3, %indices_2, %values_2)
  }
}

def @tensor_array_scatter_helper_int16(%ta3: List[tensor_int16_t[]], %current4: int32, %limit4: int32, %indices_3: Tensor[(?), int32], %values_3: List[tensor_int16_t[]]) -> List[tensor_int16_t[]] {
  %164 = equal(%current4, %limit4);
  if (%164) {
    %ta3
  } else {
    %165 = take(%indices_3, %current4);
    %166 = @tensor_array_read_int16(%values_3, %current4);
    %167 = @tensor_array_write_int16(%ta3, %165, %166);
    %168 = add(%current4, 1);
    @tensor_array_scatter_helper_int16(%167, %168, %limit4, %indices_3, %values_3)
  }
}

def @tensor_array_scatter_helper_int32(%ta4: List[tensor_int32_t[]], %current5: int32, %limit5: int32, %indices_4: Tensor[(?), int32], %values_4: List[tensor_int32_t[]]) -> List[tensor_int32_t[]] {
  %169 = equal(%current5, %limit5);
  if (%169) {
    %ta4
  } else {
    %170 = take(%indices_4, %current5);
    %171 = @tensor_array_read_int32(%values_4, %current5);
    %172 = @tensor_array_write_int32(%ta4, %170, %171);
    %173 = add(%current5, 1);
    @tensor_array_scatter_helper_int32(%172, %173, %limit5, %indices_4, %values_4)
  }
}

def @tensor_array_scatter_helper_int64(%ta5: List[tensor_int64_t[]], %current6: int32, %limit6: int32, %indices_5: Tensor[(?), int32], %values_5: List[tensor_int64_t[]]) -> List[tensor_int64_t[]] {
  %174 = equal(%current6, %limit6);
  if (%174) {
    %ta5
  } else {
    %175 = take(%indices_5, %current6);
    %176 = @tensor_array_read_int64(%values_5, %current6);
    %177 = @tensor_array_write_int64(%ta5, %175, %176);
    %178 = add(%current6, 1);
    @tensor_array_scatter_helper_int64(%177, %178, %limit6, %indices_5, %values_5)
  }
}

def @tensor_array_scatter_helper_int8(%ta6: List[tensor_int8_t[]], %current7: int32, %limit7: int32, %indices_6: Tensor[(?), int32], %values_6: List[tensor_int8_t[]]) -> List[tensor_int8_t[]] {
  %179 = equal(%current7, %limit7);
  if (%179) {
    %ta6
  } else {
    %180 = take(%indices_6, %current7);
    %181 = @tensor_array_read_int8(%values_6, %current7);
    %182 = @tensor_array_write_int8(%ta6, %180, %181);
    %183 = add(%current7, 1);
    @tensor_array_scatter_helper_int8(%182, %183, %limit7, %indices_6, %values_6)
  }
}

def @tensor_array_scatter_helper_uint16(%ta7: List[tensor_uint16_t[]], %current8: int32, %limit8: int32, %indices_7: Tensor[(?), int32], %values_7: List[tensor_uint16_t[]]) -> List[tensor_uint16_t[]] {
  %184 = equal(%current8, %limit8);
  if (%184) {
    %ta7
  } else {
    %185 = take(%indices_7, %current8);
    %186 = @tensor_array_read_uint16(%values_7, %current8);
    %187 = @tensor_array_write_uint16(%ta7, %185, %186);
    %188 = add(%current8, 1);
    @tensor_array_scatter_helper_uint16(%187, %188, %limit8, %indices_7, %values_7)
  }
}

def @tensor_array_scatter_helper_uint8(%ta8: List[tensor_uint8_t[]], %current9: int32, %limit9: int32, %indices_8: Tensor[(?), int32], %values_8: List[tensor_uint8_t[]]) -> List[tensor_uint8_t[]] {
  %189 = equal(%current9, %limit9);
  if (%189) {
    %ta8
  } else {
    %190 = take(%indices_8, %current9);
    %191 = @tensor_array_read_uint8(%values_8, %current9);
    %192 = @tensor_array_write_uint8(%ta8, %190, %191);
    %193 = add(%current9, 1);
    @tensor_array_scatter_helper_uint8(%192, %193, %limit9, %indices_8, %values_8)
  }
}

def @tensor_array_scatter_int16(%tensor_array30: List[tensor_int16_t[]], %indices3: Tensor[(?), int32], %values3: List[tensor_int16_t[]]) -> List[tensor_int16_t[]] {
  %194 = shape_of(%indices3, dtype="int32");
  %195 = take(%194, 0);
  @tensor_array_scatter_helper_int16(%tensor_array30, 0, %195, %indices3, %values3)
}

def @tensor_array_scatter_int32(%tensor_array31: List[tensor_int32_t[]], %indices4: Tensor[(?), int32], %values4: List[tensor_int32_t[]]) -> List[tensor_int32_t[]] {
  %196 = shape_of(%indices4, dtype="int32");
  %197 = take(%196, 0);
  @tensor_array_scatter_helper_int32(%tensor_array31, 0, %197, %indices4, %values4)
}

def @tensor_array_scatter_int64(%tensor_array32: List[tensor_int64_t[]], %indices5: Tensor[(?), int32], %values5: List[tensor_int64_t[]]) -> List[tensor_int64_t[]] {
  %198 = shape_of(%indices5, dtype="int32");
  %199 = take(%198, 0);
  @tensor_array_scatter_helper_int64(%tensor_array32, 0, %199, %indices5, %values5)
}

def @tensor_array_scatter_int8(%tensor_array33: List[tensor_int8_t[]], %indices6: Tensor[(?), int32], %values6: List[tensor_int8_t[]]) -> List[tensor_int8_t[]] {
  %200 = shape_of(%indices6, dtype="int32");
  %201 = take(%200, 0);
  @tensor_array_scatter_helper_int8(%tensor_array33, 0, %201, %indices6, %values6)
}

def @tensor_array_scatter_uint16(%tensor_array34: List[tensor_uint16_t[]], %indices7: Tensor[(?), int32], %values7: List[tensor_uint16_t[]]) -> List[tensor_uint16_t[]] {
  %202 = shape_of(%indices7, dtype="int32");
  %203 = take(%202, 0);
  @tensor_array_scatter_helper_uint16(%tensor_array34, 0, %203, %indices7, %values7)
}

def @tensor_array_scatter_uint8(%tensor_array35: List[tensor_uint8_t[]], %indices8: Tensor[(?), int32], %values8: List[tensor_uint8_t[]]) -> List[tensor_uint8_t[]] {
  %204 = shape_of(%indices8, dtype="int32");
  %205 = take(%204, 0);
  @tensor_array_scatter_helper_uint8(%tensor_array35, 0, %205, %indices8, %values8)
}

def @tensor_array_split_float16(%tensor_array36: List[tensor_float16_t[]], %value: tensor_float16_t[], %lengths9: Tensor[(?), int32]) -> List[tensor_float16_t[]] {
  %206 = shape_of(%lengths9, dtype="int32");
  %207 = take(%206, 0);
  @ta_split_helper_float16(%tensor_array36, %value, 0, 0, %207, %lengths9)
}

def @tensor_array_split_float32(%tensor_array37: List[tensor_float32_t[]], %value2: tensor_float32_t[], %lengths10: Tensor[(?), int32]) -> List[tensor_float32_t[]] {
  %208 = shape_of(%lengths10, dtype="int32");
  %209 = take(%208, 0);
  @ta_split_helper_float32(%tensor_array37, %value2, 0, 0, %209, %lengths10)
}

def @tensor_array_split_float64(%tensor_array38: List[tensor_float64_t[]], %value3: tensor_float64_t[], %lengths11: Tensor[(?), int32]) -> List[tensor_float64_t[]] {
  %210 = shape_of(%lengths11, dtype="int32");
  %211 = take(%210, 0);
  @ta_split_helper_float64(%tensor_array38, %value3, 0, 0, %211, %lengths11)
}

def @tensor_array_split_int16(%tensor_array39: List[tensor_int16_t[]], %value4: tensor_int16_t[], %lengths12: Tensor[(?), int32]) -> List[tensor_int16_t[]] {
  %212 = shape_of(%lengths12, dtype="int32");
  %213 = take(%212, 0);
  @ta_split_helper_int16(%tensor_array39, %value4, 0, 0, %213, %lengths12)
}

def @tensor_array_split_int32(%tensor_array40: List[tensor_int32_t[]], %value5: tensor_int32_t[], %lengths13: Tensor[(?), int32]) -> List[tensor_int32_t[]] {
  %214 = shape_of(%lengths13, dtype="int32");
  %215 = take(%214, 0);
  @ta_split_helper_int32(%tensor_array40, %value5, 0, 0, %215, %lengths13)
}

def @tensor_array_split_int64(%tensor_array41: List[tensor_int64_t[]], %value6: tensor_int64_t[], %lengths14: Tensor[(?), int32]) -> List[tensor_int64_t[]] {
  %216 = shape_of(%lengths14, dtype="int32");
  %217 = take(%216, 0);
  @ta_split_helper_int64(%tensor_array41, %value6, 0, 0, %217, %lengths14)
}

def @tensor_array_split_int8(%tensor_array42: List[tensor_int8_t[]], %value7: tensor_int8_t[], %lengths15: Tensor[(?), int32]) -> List[tensor_int8_t[]] {
  %218 = shape_of(%lengths15, dtype="int32");
  %219 = take(%218, 0);
  @ta_split_helper_int8(%tensor_array42, %value7, 0, 0, %219, %lengths15)
}

def @tensor_array_split_uint16(%tensor_array43: List[tensor_uint16_t[]], %value8: tensor_uint16_t[], %lengths16: Tensor[(?), int32]) -> List[tensor_uint16_t[]] {
  %220 = shape_of(%lengths16, dtype="int32");
  %221 = take(%220, 0);
  @ta_split_helper_uint16(%tensor_array43, %value8, 0, 0, %221, %lengths16)
}

def @tensor_array_split_uint8(%tensor_array44: List[tensor_uint8_t[]], %value9: tensor_uint8_t[], %lengths17: Tensor[(?), int32]) -> List[tensor_uint8_t[]] {
  %222 = shape_of(%lengths17, dtype="int32");
  %223 = take(%222, 0);
  @ta_split_helper_uint8(%tensor_array44, %value9, 0, 0, %223, %lengths17)
}

def @tensor_array_stack_float16(%tensor_array45: List[tensor_float16_t[]]) -> tensor_float16_t[] {
  let %x_4 = @map(@tensor_expand_dims_float16, %tensor_array45);
  let %x_5 = @hd(%x_4);
  let %x_6 = @tl(%x_4);
  let %x_7 = @foldl(@tensor_concatenate_float16, %x_5, %x_6);
  %x_7
}

def @tensor_array_stack_float32(%tensor_array46: List[tensor_float32_t[]]) -> tensor_float32_t[] {
  let %x_0 = @map(@tensor_expand_dims_float32, %tensor_array46);
  let %x_1 = @hd(%x_0);
  let %x_2 = @tl(%x_0);
  let %x_3 = @foldl(@tensor_concatenate_float32, %x_1, %x_2);
  %x_3
}

def @tensor_array_stack_float64(%tensor_array47: List[tensor_float64_t[]]) -> tensor_float64_t[] {
  let %x_8 = @map(@tensor_expand_dims_float64, %tensor_array47);
  let %x_9 = @hd(%x_8);
  let %x_10 = @tl(%x_8);
  let %x_11 = @foldl(@tensor_concatenate_float64, %x_9, %x_10);
  %x_11
}

def @tensor_array_stack_int16(%tensor_array48: List[tensor_int16_t[]]) -> tensor_int16_t[] {
  let %x_24 = @map(@tensor_expand_dims_int16, %tensor_array48);
  let %x_25 = @hd(%x_24);
  let %x_26 = @tl(%x_24);
  let %x_27 = @foldl(@tensor_concatenate_int16, %x_25, %x_26);
  %x_27
}

def @tensor_array_stack_int32(%tensor_array49: List[tensor_int32_t[]]) -> tensor_int32_t[] {
  let %x_12 = @map(@tensor_expand_dims_int32, %tensor_array49);
  let %x_13 = @hd(%x_12);
  let %x_14 = @tl(%x_12);
  let %x_15 = @foldl(@tensor_concatenate_int32, %x_13, %x_14);
  %x_15
}

def @tensor_array_stack_int64(%tensor_array50: List[tensor_int64_t[]]) -> tensor_int64_t[] {
  let %x_32 = @map(@tensor_expand_dims_int64, %tensor_array50);
  let %x_33 = @hd(%x_32);
  let %x_34 = @tl(%x_32);
  let %x_35 = @foldl(@tensor_concatenate_int64, %x_33, %x_34);
  %x_35
}

def @tensor_array_stack_int8(%tensor_array51: List[tensor_int8_t[]]) -> tensor_int8_t[] {
  let %x_20 = @map(@tensor_expand_dims_int8, %tensor_array51);
  let %x_21 = @hd(%x_20);
  let %x_22 = @tl(%x_20);
  let %x_23 = @foldl(@tensor_concatenate_int8, %x_21, %x_22);
  %x_23
}

def @tensor_array_stack_uint16(%tensor_array52: List[tensor_uint16_t[]]) -> tensor_uint16_t[] {
  let %x_28 = @map(@tensor_expand_dims_uint16, %tensor_array52);
  let %x_29 = @hd(%x_28);
  let %x_30 = @tl(%x_28);
  let %x_31 = @foldl(@tensor_concatenate_uint16, %x_29, %x_30);
  %x_31
}

def @tensor_array_stack_uint8(%tensor_array53: List[tensor_uint8_t[]]) -> tensor_uint8_t[] {
  let %x_16 = @map(@tensor_expand_dims_uint8, %tensor_array53);
  let %x_17 = @hd(%x_16);
  let %x_18 = @tl(%x_16);
  let %x_19 = @foldl(@tensor_concatenate_uint8, %x_17, %x_18);
  %x_19
}

def @tensor_array_uint16(%x29: int32) -> List[tensor_uint16_t[]] {
  %224 = equal(%x29, 0);
  if (%224) {
    Nil
  } else {
    %225 = subtract(%x29, 1);
    %226 = tensor_nil_uint16;
    %227 = @tensor_array_uint16(%225);
    Cons(%226, %227)
  }
}

def @tensor_array_uint8(%x30: int32) -> List[tensor_uint8_t[]] {
  %228 = equal(%x30, 0);
  if (%228) {
    Nil
  } else {
    %229 = subtract(%x30, 1);
    %230 = tensor_nil_uint8;
    %231 = @tensor_array_uint8(%229);
    Cons(%230, %231)
  }
}

def @tensor_array_unstack_tensor1_float16(%tensor: Tensor[(?), float16]) -> List[tensor_float16_t[]] {
  %232 = shape_of(%tensor, dtype="int32");
  %233 = take(%232, 0);
  @tensor_array_unstack_tensor1_helper_float16(0, %233, %tensor)
}

def @tensor_array_unstack_tensor1_float32(%tensor1: Tensor[(?), float32]) -> List[tensor_float32_t[]] {
  %234 = shape_of(%tensor1, dtype="int32");
  %235 = take(%234, 0);
  @tensor_array_unstack_tensor1_helper_float32(0, %235, %tensor1)
}

def @tensor_array_unstack_tensor1_float64(%tensor2: Tensor[(?), float64]) -> List[tensor_float64_t[]] {
  %236 = shape_of(%tensor2, dtype="int32");
  %237 = take(%236, 0);
  @tensor_array_unstack_tensor1_helper_float64(0, %237, %tensor2)
}

def @tensor_array_unstack_tensor1_helper_float16(%i: int32, %up: int32, %t2: Tensor[(?), float16]) -> List[tensor_float16_t[]] {
  %238 = equal(%i, %up);
  if (%238) {
    Nil
  } else {
    %239 = take(%t2, %i);
    %240 = add(%i, 1);
    %241 = tensor0_float16(%239);
    %242 = @tensor_array_unstack_tensor1_helper_float16(%240, %up, %t2);
    Cons(%241, %242)
  }
}

def @tensor_array_unstack_tensor1_helper_float32(%i1: int32, %up1: int32, %t3: Tensor[(?), float32]) -> List[tensor_float32_t[]] {
  %243 = equal(%i1, %up1);
  if (%243) {
    Nil
  } else {
    %244 = take(%t3, %i1);
    %245 = add(%i1, 1);
    %246 = tensor0_float32(%244);
    %247 = @tensor_array_unstack_tensor1_helper_float32(%245, %up1, %t3);
    Cons(%246, %247)
  }
}

def @tensor_array_unstack_tensor1_helper_float64(%i2: int32, %up2: int32, %t4: Tensor[(?), float64]) -> List[tensor_float64_t[]] {
  %248 = equal(%i2, %up2);
  if (%248) {
    Nil
  } else {
    %249 = take(%t4, %i2);
    %250 = add(%i2, 1);
    %251 = tensor0_float64(%249);
    %252 = @tensor_array_unstack_tensor1_helper_float64(%250, %up2, %t4);
    Cons(%251, %252)
  }
}

def @tensor_array_unstack_tensor1_helper_int16(%i3: int32, %up3: int32, %t5: Tensor[(?), int16]) -> List[tensor_int16_t[]] {
  %253 = equal(%i3, %up3);
  if (%253) {
    Nil
  } else {
    %254 = take(%t5, %i3);
    %255 = add(%i3, 1);
    %256 = tensor0_int16(%254);
    %257 = @tensor_array_unstack_tensor1_helper_int16(%255, %up3, %t5);
    Cons(%256, %257)
  }
}

def @tensor_array_unstack_tensor1_helper_int32(%i4: int32, %up4: int32, %t6: Tensor[(?), int32]) -> List[tensor_int32_t[]] {
  %258 = equal(%i4, %up4);
  if (%258) {
    Nil
  } else {
    %259 = take(%t6, %i4);
    %260 = add(%i4, 1);
    %261 = tensor0_int32(%259);
    %262 = @tensor_array_unstack_tensor1_helper_int32(%260, %up4, %t6);
    Cons(%261, %262)
  }
}

def @tensor_array_unstack_tensor1_helper_int64(%i5: int32, %up5: int32, %t7: Tensor[(?), int64]) -> List[tensor_int64_t[]] {
  %263 = equal(%i5, %up5);
  if (%263) {
    Nil
  } else {
    %264 = take(%t7, %i5);
    %265 = add(%i5, 1);
    %266 = tensor0_int64(%264);
    %267 = @tensor_array_unstack_tensor1_helper_int64(%265, %up5, %t7);
    Cons(%266, %267)
  }
}

def @tensor_array_unstack_tensor1_helper_int8(%i6: int32, %up6: int32, %t8: Tensor[(?), int8]) -> List[tensor_int8_t[]] {
  %268 = equal(%i6, %up6);
  if (%268) {
    Nil
  } else {
    %269 = take(%t8, %i6);
    %270 = add(%i6, 1);
    %271 = tensor0_int8(%269);
    %272 = @tensor_array_unstack_tensor1_helper_int8(%270, %up6, %t8);
    Cons(%271, %272)
  }
}

def @tensor_array_unstack_tensor1_helper_uint16(%i7: int32, %up7: int32, %t9: Tensor[(?), uint16]) -> List[tensor_uint16_t[]] {
  %273 = equal(%i7, %up7);
  if (%273) {
    Nil
  } else {
    %274 = take(%t9, %i7);
    %275 = add(%i7, 1);
    %276 = tensor0_uint16(%274);
    %277 = @tensor_array_unstack_tensor1_helper_uint16(%275, %up7, %t9);
    Cons(%276, %277)
  }
}

def @tensor_array_unstack_tensor1_helper_uint8(%i8: int32, %up8: int32, %t10: Tensor[(?), uint8]) -> List[tensor_uint8_t[]] {
  %278 = equal(%i8, %up8);
  if (%278) {
    Nil
  } else {
    %279 = take(%t10, %i8);
    %280 = add(%i8, 1);
    %281 = tensor0_uint8(%279);
    %282 = @tensor_array_unstack_tensor1_helper_uint8(%280, %up8, %t10);
    Cons(%281, %282)
  }
}

def @tensor_array_unstack_tensor1_int16(%tensor3: Tensor[(?), int16]) -> List[tensor_int16_t[]] {
  %283 = shape_of(%tensor3, dtype="int32");
  %284 = take(%283, 0);
  @tensor_array_unstack_tensor1_helper_int16(0, %284, %tensor3)
}

def @tensor_array_unstack_tensor1_int32(%tensor4: Tensor[(?), int32]) -> List[tensor_int32_t[]] {
  %285 = shape_of(%tensor4, dtype="int32");
  %286 = take(%285, 0);
  @tensor_array_unstack_tensor1_helper_int32(0, %286, %tensor4)
}

def @tensor_array_unstack_tensor1_int64(%tensor5: Tensor[(?), int64]) -> List[tensor_int64_t[]] {
  %287 = shape_of(%tensor5, dtype="int32");
  %288 = take(%287, 0);
  @tensor_array_unstack_tensor1_helper_int64(0, %288, %tensor5)
}

def @tensor_array_unstack_tensor1_int8(%tensor6: Tensor[(?), int8]) -> List[tensor_int8_t[]] {
  %289 = shape_of(%tensor6, dtype="int32");
  %290 = take(%289, 0);
  @tensor_array_unstack_tensor1_helper_int8(0, %290, %tensor6)
}

def @tensor_array_unstack_tensor1_uint16(%tensor7: Tensor[(?), uint16]) -> List[tensor_uint16_t[]] {
  %291 = shape_of(%tensor7, dtype="int32");
  %292 = take(%291, 0);
  @tensor_array_unstack_tensor1_helper_uint16(0, %292, %tensor7)
}

def @tensor_array_unstack_tensor1_uint8(%tensor8: Tensor[(?), uint8]) -> List[tensor_uint8_t[]] {
  %293 = shape_of(%tensor8, dtype="int32");
  %294 = take(%293, 0);
  @tensor_array_unstack_tensor1_helper_uint8(0, %294, %tensor8)
}

def @tensor_array_unstack_tensor2_float16(%tensor9: Tensor[(?, ?), float16]) -> List[tensor_float16_t[]] {
  %295 = shape_of(%tensor9, dtype="int32");
  %296 = take(%295, 0);
  @tensor_array_unstack_tensor2_helper_float16(0, %296, %tensor9)
}

def @tensor_array_unstack_tensor2_float32(%tensor10: Tensor[(?, ?), float32]) -> List[tensor_float32_t[]] {
  %297 = shape_of(%tensor10, dtype="int32");
  %298 = take(%297, 0);
  @tensor_array_unstack_tensor2_helper_float32(0, %298, %tensor10)
}

def @tensor_array_unstack_tensor2_float64(%tensor11: Tensor[(?, ?), float64]) -> List[tensor_float64_t[]] {
  %299 = shape_of(%tensor11, dtype="int32");
  %300 = take(%299, 0);
  @tensor_array_unstack_tensor2_helper_float64(0, %300, %tensor11)
}

def @tensor_array_unstack_tensor2_helper_float16(%i9: int32, %up9: int32, %t11: Tensor[(?, ?), float16]) -> List[tensor_float16_t[]] {
  %301 = equal(%i9, %up9);
  if (%301) {
    Nil
  } else {
    %302 = take(%t11, %i9, axis=0);
    %303 = add(%i9, 1);
    %304 = tensor1_float16(%302);
    %305 = @tensor_array_unstack_tensor2_helper_float16(%303, %up9, %t11);
    Cons(%304, %305)
  }
}

def @tensor_array_unstack_tensor2_helper_float32(%i10: int32, %up10: int32, %t12: Tensor[(?, ?), float32]) -> List[tensor_float32_t[]] {
  %306 = equal(%i10, %up10);
  if (%306) {
    Nil
  } else {
    %307 = take(%t12, %i10, axis=0);
    %308 = add(%i10, 1);
    %309 = tensor1_float32(%307);
    %310 = @tensor_array_unstack_tensor2_helper_float32(%308, %up10, %t12);
    Cons(%309, %310)
  }
}

def @tensor_array_unstack_tensor2_helper_float64(%i11: int32, %up11: int32, %t13: Tensor[(?, ?), float64]) -> List[tensor_float64_t[]] {
  %311 = equal(%i11, %up11);
  if (%311) {
    Nil
  } else {
    %312 = take(%t13, %i11, axis=0);
    %313 = add(%i11, 1);
    %314 = tensor1_float64(%312);
    %315 = @tensor_array_unstack_tensor2_helper_float64(%313, %up11, %t13);
    Cons(%314, %315)
  }
}

def @tensor_array_unstack_tensor2_helper_int16(%i12: int32, %up12: int32, %t14: Tensor[(?, ?), int16]) -> List[tensor_int16_t[]] {
  %316 = equal(%i12, %up12);
  if (%316) {
    Nil
  } else {
    %317 = take(%t14, %i12, axis=0);
    %318 = add(%i12, 1);
    %319 = tensor1_int16(%317);
    %320 = @tensor_array_unstack_tensor2_helper_int16(%318, %up12, %t14);
    Cons(%319, %320)
  }
}

def @tensor_array_unstack_tensor2_helper_int32(%i13: int32, %up13: int32, %t15: Tensor[(?, ?), int32]) -> List[tensor_int32_t[]] {
  %321 = equal(%i13, %up13);
  if (%321) {
    Nil
  } else {
    %322 = take(%t15, %i13, axis=0);
    %323 = add(%i13, 1);
    %324 = tensor1_int32(%322);
    %325 = @tensor_array_unstack_tensor2_helper_int32(%323, %up13, %t15);
    Cons(%324, %325)
  }
}

def @tensor_array_unstack_tensor2_helper_int64(%i14: int32, %up14: int32, %t16: Tensor[(?, ?), int64]) -> List[tensor_int64_t[]] {
  %326 = equal(%i14, %up14);
  if (%326) {
    Nil
  } else {
    %327 = take(%t16, %i14, axis=0);
    %328 = add(%i14, 1);
    %329 = tensor1_int64(%327);
    %330 = @tensor_array_unstack_tensor2_helper_int64(%328, %up14, %t16);
    Cons(%329, %330)
  }
}

def @tensor_array_unstack_tensor2_helper_int8(%i15: int32, %up15: int32, %t17: Tensor[(?, ?), int8]) -> List[tensor_int8_t[]] {
  %331 = equal(%i15, %up15);
  if (%331) {
    Nil
  } else {
    %332 = take(%t17, %i15, axis=0);
    %333 = add(%i15, 1);
    %334 = tensor1_int8(%332);
    %335 = @tensor_array_unstack_tensor2_helper_int8(%333, %up15, %t17);
    Cons(%334, %335)
  }
}

def @tensor_array_unstack_tensor2_helper_uint16(%i16: int32, %up16: int32, %t18: Tensor[(?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %336 = equal(%i16, %up16);
  if (%336) {
    Nil
  } else {
    %337 = take(%t18, %i16, axis=0);
    %338 = add(%i16, 1);
    %339 = tensor1_uint16(%337);
    %340 = @tensor_array_unstack_tensor2_helper_uint16(%338, %up16, %t18);
    Cons(%339, %340)
  }
}

def @tensor_array_unstack_tensor2_helper_uint8(%i17: int32, %up17: int32, %t19: Tensor[(?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %341 = equal(%i17, %up17);
  if (%341) {
    Nil
  } else {
    %342 = take(%t19, %i17, axis=0);
    %343 = add(%i17, 1);
    %344 = tensor1_uint8(%342);
    %345 = @tensor_array_unstack_tensor2_helper_uint8(%343, %up17, %t19);
    Cons(%344, %345)
  }
}

def @tensor_array_unstack_tensor2_int16(%tensor12: Tensor[(?, ?), int16]) -> List[tensor_int16_t[]] {
  %346 = shape_of(%tensor12, dtype="int32");
  %347 = take(%346, 0);
  @tensor_array_unstack_tensor2_helper_int16(0, %347, %tensor12)
}

def @tensor_array_unstack_tensor2_int32(%tensor13: Tensor[(?, ?), int32]) -> List[tensor_int32_t[]] {
  %348 = shape_of(%tensor13, dtype="int32");
  %349 = take(%348, 0);
  @tensor_array_unstack_tensor2_helper_int32(0, %349, %tensor13)
}

def @tensor_array_unstack_tensor2_int64(%tensor14: Tensor[(?, ?), int64]) -> List[tensor_int64_t[]] {
  %350 = shape_of(%tensor14, dtype="int32");
  %351 = take(%350, 0);
  @tensor_array_unstack_tensor2_helper_int64(0, %351, %tensor14)
}

def @tensor_array_unstack_tensor2_int8(%tensor15: Tensor[(?, ?), int8]) -> List[tensor_int8_t[]] {
  %352 = shape_of(%tensor15, dtype="int32");
  %353 = take(%352, 0);
  @tensor_array_unstack_tensor2_helper_int8(0, %353, %tensor15)
}

def @tensor_array_unstack_tensor2_uint16(%tensor16: Tensor[(?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %354 = shape_of(%tensor16, dtype="int32");
  %355 = take(%354, 0);
  @tensor_array_unstack_tensor2_helper_uint16(0, %355, %tensor16)
}

def @tensor_array_unstack_tensor2_uint8(%tensor17: Tensor[(?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %356 = shape_of(%tensor17, dtype="int32");
  %357 = take(%356, 0);
  @tensor_array_unstack_tensor2_helper_uint8(0, %357, %tensor17)
}

def @tensor_array_unstack_tensor3_float16(%tensor18: Tensor[(?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %358 = shape_of(%tensor18, dtype="int32");
  %359 = take(%358, 0);
  @tensor_array_unstack_tensor3_helper_float16(0, %359, %tensor18)
}

def @tensor_array_unstack_tensor3_float32(%tensor19: Tensor[(?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %360 = shape_of(%tensor19, dtype="int32");
  %361 = take(%360, 0);
  @tensor_array_unstack_tensor3_helper_float32(0, %361, %tensor19)
}

def @tensor_array_unstack_tensor3_float64(%tensor20: Tensor[(?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %362 = shape_of(%tensor20, dtype="int32");
  %363 = take(%362, 0);
  @tensor_array_unstack_tensor3_helper_float64(0, %363, %tensor20)
}

def @tensor_array_unstack_tensor3_helper_float16(%i18: int32, %up18: int32, %t20: Tensor[(?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %364 = equal(%i18, %up18);
  if (%364) {
    Nil
  } else {
    %365 = take(%t20, %i18, axis=0);
    %366 = add(%i18, 1);
    %367 = tensor2_float16(%365);
    %368 = @tensor_array_unstack_tensor3_helper_float16(%366, %up18, %t20);
    Cons(%367, %368)
  }
}

def @tensor_array_unstack_tensor3_helper_float32(%i19: int32, %up19: int32, %t21: Tensor[(?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %369 = equal(%i19, %up19);
  if (%369) {
    Nil
  } else {
    %370 = take(%t21, %i19, axis=0);
    %371 = add(%i19, 1);
    %372 = tensor2_float32(%370);
    %373 = @tensor_array_unstack_tensor3_helper_float32(%371, %up19, %t21);
    Cons(%372, %373)
  }
}

def @tensor_array_unstack_tensor3_helper_float64(%i20: int32, %up20: int32, %t22: Tensor[(?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %374 = equal(%i20, %up20);
  if (%374) {
    Nil
  } else {
    %375 = take(%t22, %i20, axis=0);
    %376 = add(%i20, 1);
    %377 = tensor2_float64(%375);
    %378 = @tensor_array_unstack_tensor3_helper_float64(%376, %up20, %t22);
    Cons(%377, %378)
  }
}

def @tensor_array_unstack_tensor3_helper_int16(%i21: int32, %up21: int32, %t23: Tensor[(?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %379 = equal(%i21, %up21);
  if (%379) {
    Nil
  } else {
    %380 = take(%t23, %i21, axis=0);
    %381 = add(%i21, 1);
    %382 = tensor2_int16(%380);
    %383 = @tensor_array_unstack_tensor3_helper_int16(%381, %up21, %t23);
    Cons(%382, %383)
  }
}

def @tensor_array_unstack_tensor3_helper_int32(%i22: int32, %up22: int32, %t24: Tensor[(?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %384 = equal(%i22, %up22);
  if (%384) {
    Nil
  } else {
    %385 = take(%t24, %i22, axis=0);
    %386 = add(%i22, 1);
    %387 = tensor2_int32(%385);
    %388 = @tensor_array_unstack_tensor3_helper_int32(%386, %up22, %t24);
    Cons(%387, %388)
  }
}

def @tensor_array_unstack_tensor3_helper_int64(%i23: int32, %up23: int32, %t25: Tensor[(?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %389 = equal(%i23, %up23);
  if (%389) {
    Nil
  } else {
    %390 = take(%t25, %i23, axis=0);
    %391 = add(%i23, 1);
    %392 = tensor2_int64(%390);
    %393 = @tensor_array_unstack_tensor3_helper_int64(%391, %up23, %t25);
    Cons(%392, %393)
  }
}

def @tensor_array_unstack_tensor3_helper_int8(%i24: int32, %up24: int32, %t26: Tensor[(?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %394 = equal(%i24, %up24);
  if (%394) {
    Nil
  } else {
    %395 = take(%t26, %i24, axis=0);
    %396 = add(%i24, 1);
    %397 = tensor2_int8(%395);
    %398 = @tensor_array_unstack_tensor3_helper_int8(%396, %up24, %t26);
    Cons(%397, %398)
  }
}

def @tensor_array_unstack_tensor3_helper_uint16(%i25: int32, %up25: int32, %t27: Tensor[(?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %399 = equal(%i25, %up25);
  if (%399) {
    Nil
  } else {
    %400 = take(%t27, %i25, axis=0);
    %401 = add(%i25, 1);
    %402 = tensor2_uint16(%400);
    %403 = @tensor_array_unstack_tensor3_helper_uint16(%401, %up25, %t27);
    Cons(%402, %403)
  }
}

def @tensor_array_unstack_tensor3_helper_uint8(%i26: int32, %up26: int32, %t28: Tensor[(?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %404 = equal(%i26, %up26);
  if (%404) {
    Nil
  } else {
    %405 = take(%t28, %i26, axis=0);
    %406 = add(%i26, 1);
    %407 = tensor2_uint8(%405);
    %408 = @tensor_array_unstack_tensor3_helper_uint8(%406, %up26, %t28);
    Cons(%407, %408)
  }
}

def @tensor_array_unstack_tensor3_int16(%tensor21: Tensor[(?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %409 = shape_of(%tensor21, dtype="int32");
  %410 = take(%409, 0);
  @tensor_array_unstack_tensor3_helper_int16(0, %410, %tensor21)
}

def @tensor_array_unstack_tensor3_int32(%tensor22: Tensor[(?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %411 = shape_of(%tensor22, dtype="int32");
  %412 = take(%411, 0);
  @tensor_array_unstack_tensor3_helper_int32(0, %412, %tensor22)
}

def @tensor_array_unstack_tensor3_int64(%tensor23: Tensor[(?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %413 = shape_of(%tensor23, dtype="int32");
  %414 = take(%413, 0);
  @tensor_array_unstack_tensor3_helper_int64(0, %414, %tensor23)
}

def @tensor_array_unstack_tensor3_int8(%tensor24: Tensor[(?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %415 = shape_of(%tensor24, dtype="int32");
  %416 = take(%415, 0);
  @tensor_array_unstack_tensor3_helper_int8(0, %416, %tensor24)
}

def @tensor_array_unstack_tensor3_uint16(%tensor25: Tensor[(?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %417 = shape_of(%tensor25, dtype="int32");
  %418 = take(%417, 0);
  @tensor_array_unstack_tensor3_helper_uint16(0, %418, %tensor25)
}

def @tensor_array_unstack_tensor3_uint8(%tensor26: Tensor[(?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %419 = shape_of(%tensor26, dtype="int32");
  %420 = take(%419, 0);
  @tensor_array_unstack_tensor3_helper_uint8(0, %420, %tensor26)
}

def @tensor_array_unstack_tensor4_float16(%tensor27: Tensor[(?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %421 = shape_of(%tensor27, dtype="int32");
  %422 = take(%421, 0);
  @tensor_array_unstack_tensor4_helper_float16(0, %422, %tensor27)
}

def @tensor_array_unstack_tensor4_float32(%tensor28: Tensor[(?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %423 = shape_of(%tensor28, dtype="int32");
  %424 = take(%423, 0);
  @tensor_array_unstack_tensor4_helper_float32(0, %424, %tensor28)
}

def @tensor_array_unstack_tensor4_float64(%tensor29: Tensor[(?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %425 = shape_of(%tensor29, dtype="int32");
  %426 = take(%425, 0);
  @tensor_array_unstack_tensor4_helper_float64(0, %426, %tensor29)
}

def @tensor_array_unstack_tensor4_helper_float16(%i27: int32, %up27: int32, %t29: Tensor[(?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %427 = equal(%i27, %up27);
  if (%427) {
    Nil
  } else {
    %428 = take(%t29, %i27, axis=0);
    %429 = add(%i27, 1);
    %430 = tensor3_float16(%428);
    %431 = @tensor_array_unstack_tensor4_helper_float16(%429, %up27, %t29);
    Cons(%430, %431)
  }
}

def @tensor_array_unstack_tensor4_helper_float32(%i28: int32, %up28: int32, %t30: Tensor[(?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %432 = equal(%i28, %up28);
  if (%432) {
    Nil
  } else {
    %433 = take(%t30, %i28, axis=0);
    %434 = add(%i28, 1);
    %435 = tensor3_float32(%433);
    %436 = @tensor_array_unstack_tensor4_helper_float32(%434, %up28, %t30);
    Cons(%435, %436)
  }
}

def @tensor_array_unstack_tensor4_helper_float64(%i29: int32, %up29: int32, %t31: Tensor[(?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %437 = equal(%i29, %up29);
  if (%437) {
    Nil
  } else {
    %438 = take(%t31, %i29, axis=0);
    %439 = add(%i29, 1);
    %440 = tensor3_float64(%438);
    %441 = @tensor_array_unstack_tensor4_helper_float64(%439, %up29, %t31);
    Cons(%440, %441)
  }
}

def @tensor_array_unstack_tensor4_helper_int16(%i30: int32, %up30: int32, %t32: Tensor[(?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %442 = equal(%i30, %up30);
  if (%442) {
    Nil
  } else {
    %443 = take(%t32, %i30, axis=0);
    %444 = add(%i30, 1);
    %445 = tensor3_int16(%443);
    %446 = @tensor_array_unstack_tensor4_helper_int16(%444, %up30, %t32);
    Cons(%445, %446)
  }
}

def @tensor_array_unstack_tensor4_helper_int32(%i31: int32, %up31: int32, %t33: Tensor[(?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %447 = equal(%i31, %up31);
  if (%447) {
    Nil
  } else {
    %448 = take(%t33, %i31, axis=0);
    %449 = add(%i31, 1);
    %450 = tensor3_int32(%448);
    %451 = @tensor_array_unstack_tensor4_helper_int32(%449, %up31, %t33);
    Cons(%450, %451)
  }
}

def @tensor_array_unstack_tensor4_helper_int64(%i32: int32, %up32: int32, %t34: Tensor[(?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %452 = equal(%i32, %up32);
  if (%452) {
    Nil
  } else {
    %453 = take(%t34, %i32, axis=0);
    %454 = add(%i32, 1);
    %455 = tensor3_int64(%453);
    %456 = @tensor_array_unstack_tensor4_helper_int64(%454, %up32, %t34);
    Cons(%455, %456)
  }
}

def @tensor_array_unstack_tensor4_helper_int8(%i33: int32, %up33: int32, %t35: Tensor[(?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %457 = equal(%i33, %up33);
  if (%457) {
    Nil
  } else {
    %458 = take(%t35, %i33, axis=0);
    %459 = add(%i33, 1);
    %460 = tensor3_int8(%458);
    %461 = @tensor_array_unstack_tensor4_helper_int8(%459, %up33, %t35);
    Cons(%460, %461)
  }
}

def @tensor_array_unstack_tensor4_helper_uint16(%i34: int32, %up34: int32, %t36: Tensor[(?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %462 = equal(%i34, %up34);
  if (%462) {
    Nil
  } else {
    %463 = take(%t36, %i34, axis=0);
    %464 = add(%i34, 1);
    %465 = tensor3_uint16(%463);
    %466 = @tensor_array_unstack_tensor4_helper_uint16(%464, %up34, %t36);
    Cons(%465, %466)
  }
}

def @tensor_array_unstack_tensor4_helper_uint8(%i35: int32, %up35: int32, %t37: Tensor[(?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %467 = equal(%i35, %up35);
  if (%467) {
    Nil
  } else {
    %468 = take(%t37, %i35, axis=0);
    %469 = add(%i35, 1);
    %470 = tensor3_uint8(%468);
    %471 = @tensor_array_unstack_tensor4_helper_uint8(%469, %up35, %t37);
    Cons(%470, %471)
  }
}

def @tensor_array_unstack_tensor4_int16(%tensor30: Tensor[(?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %472 = shape_of(%tensor30, dtype="int32");
  %473 = take(%472, 0);
  @tensor_array_unstack_tensor4_helper_int16(0, %473, %tensor30)
}

def @tensor_array_unstack_tensor4_int32(%tensor31: Tensor[(?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %474 = shape_of(%tensor31, dtype="int32");
  %475 = take(%474, 0);
  @tensor_array_unstack_tensor4_helper_int32(0, %475, %tensor31)
}

def @tensor_array_unstack_tensor4_int64(%tensor32: Tensor[(?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %476 = shape_of(%tensor32, dtype="int32");
  %477 = take(%476, 0);
  @tensor_array_unstack_tensor4_helper_int64(0, %477, %tensor32)
}

def @tensor_array_unstack_tensor4_int8(%tensor33: Tensor[(?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %478 = shape_of(%tensor33, dtype="int32");
  %479 = take(%478, 0);
  @tensor_array_unstack_tensor4_helper_int8(0, %479, %tensor33)
}

def @tensor_array_unstack_tensor4_uint16(%tensor34: Tensor[(?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %480 = shape_of(%tensor34, dtype="int32");
  %481 = take(%480, 0);
  @tensor_array_unstack_tensor4_helper_uint16(0, %481, %tensor34)
}

def @tensor_array_unstack_tensor4_uint8(%tensor35: Tensor[(?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %482 = shape_of(%tensor35, dtype="int32");
  %483 = take(%482, 0);
  @tensor_array_unstack_tensor4_helper_uint8(0, %483, %tensor35)
}

def @tensor_array_unstack_tensor5_float16(%tensor36: Tensor[(?, ?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %484 = shape_of(%tensor36, dtype="int32");
  %485 = take(%484, 0);
  @tensor_array_unstack_tensor5_helper_float16(0, %485, %tensor36)
}

def @tensor_array_unstack_tensor5_float32(%tensor37: Tensor[(?, ?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %486 = shape_of(%tensor37, dtype="int32");
  %487 = take(%486, 0);
  @tensor_array_unstack_tensor5_helper_float32(0, %487, %tensor37)
}

def @tensor_array_unstack_tensor5_float64(%tensor38: Tensor[(?, ?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %488 = shape_of(%tensor38, dtype="int32");
  %489 = take(%488, 0);
  @tensor_array_unstack_tensor5_helper_float64(0, %489, %tensor38)
}

def @tensor_array_unstack_tensor5_helper_float16(%i36: int32, %up36: int32, %t38: Tensor[(?, ?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %490 = equal(%i36, %up36);
  if (%490) {
    Nil
  } else {
    %491 = take(%t38, %i36, axis=0);
    %492 = add(%i36, 1);
    %493 = tensor4_float16(%491);
    %494 = @tensor_array_unstack_tensor5_helper_float16(%492, %up36, %t38);
    Cons(%493, %494)
  }
}

def @tensor_array_unstack_tensor5_helper_float32(%i37: int32, %up37: int32, %t39: Tensor[(?, ?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %495 = equal(%i37, %up37);
  if (%495) {
    Nil
  } else {
    %496 = take(%t39, %i37, axis=0);
    %497 = add(%i37, 1);
    %498 = tensor4_float32(%496);
    %499 = @tensor_array_unstack_tensor5_helper_float32(%497, %up37, %t39);
    Cons(%498, %499)
  }
}

def @tensor_array_unstack_tensor5_helper_float64(%i38: int32, %up38: int32, %t40: Tensor[(?, ?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %500 = equal(%i38, %up38);
  if (%500) {
    Nil
  } else {
    %501 = take(%t40, %i38, axis=0);
    %502 = add(%i38, 1);
    %503 = tensor4_float64(%501);
    %504 = @tensor_array_unstack_tensor5_helper_float64(%502, %up38, %t40);
    Cons(%503, %504)
  }
}

def @tensor_array_unstack_tensor5_helper_int16(%i39: int32, %up39: int32, %t41: Tensor[(?, ?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %505 = equal(%i39, %up39);
  if (%505) {
    Nil
  } else {
    %506 = take(%t41, %i39, axis=0);
    %507 = add(%i39, 1);
    %508 = tensor4_int16(%506);
    %509 = @tensor_array_unstack_tensor5_helper_int16(%507, %up39, %t41);
    Cons(%508, %509)
  }
}

def @tensor_array_unstack_tensor5_helper_int32(%i40: int32, %up40: int32, %t42: Tensor[(?, ?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %510 = equal(%i40, %up40);
  if (%510) {
    Nil
  } else {
    %511 = take(%t42, %i40, axis=0);
    %512 = add(%i40, 1);
    %513 = tensor4_int32(%511);
    %514 = @tensor_array_unstack_tensor5_helper_int32(%512, %up40, %t42);
    Cons(%513, %514)
  }
}

def @tensor_array_unstack_tensor5_helper_int64(%i41: int32, %up41: int32, %t43: Tensor[(?, ?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %515 = equal(%i41, %up41);
  if (%515) {
    Nil
  } else {
    %516 = take(%t43, %i41, axis=0);
    %517 = add(%i41, 1);
    %518 = tensor4_int64(%516);
    %519 = @tensor_array_unstack_tensor5_helper_int64(%517, %up41, %t43);
    Cons(%518, %519)
  }
}

def @tensor_array_unstack_tensor5_helper_int8(%i42: int32, %up42: int32, %t44: Tensor[(?, ?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %520 = equal(%i42, %up42);
  if (%520) {
    Nil
  } else {
    %521 = take(%t44, %i42, axis=0);
    %522 = add(%i42, 1);
    %523 = tensor4_int8(%521);
    %524 = @tensor_array_unstack_tensor5_helper_int8(%522, %up42, %t44);
    Cons(%523, %524)
  }
}

def @tensor_array_unstack_tensor5_helper_uint16(%i43: int32, %up43: int32, %t45: Tensor[(?, ?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %525 = equal(%i43, %up43);
  if (%525) {
    Nil
  } else {
    %526 = take(%t45, %i43, axis=0);
    %527 = add(%i43, 1);
    %528 = tensor4_uint16(%526);
    %529 = @tensor_array_unstack_tensor5_helper_uint16(%527, %up43, %t45);
    Cons(%528, %529)
  }
}

def @tensor_array_unstack_tensor5_helper_uint8(%i44: int32, %up44: int32, %t46: Tensor[(?, ?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %530 = equal(%i44, %up44);
  if (%530) {
    Nil
  } else {
    %531 = take(%t46, %i44, axis=0);
    %532 = add(%i44, 1);
    %533 = tensor4_uint8(%531);
    %534 = @tensor_array_unstack_tensor5_helper_uint8(%532, %up44, %t46);
    Cons(%533, %534)
  }
}

def @tensor_array_unstack_tensor5_int16(%tensor39: Tensor[(?, ?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %535 = shape_of(%tensor39, dtype="int32");
  %536 = take(%535, 0);
  @tensor_array_unstack_tensor5_helper_int16(0, %536, %tensor39)
}

def @tensor_array_unstack_tensor5_int32(%tensor40: Tensor[(?, ?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %537 = shape_of(%tensor40, dtype="int32");
  %538 = take(%537, 0);
  @tensor_array_unstack_tensor5_helper_int32(0, %538, %tensor40)
}

def @tensor_array_unstack_tensor5_int64(%tensor41: Tensor[(?, ?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %539 = shape_of(%tensor41, dtype="int32");
  %540 = take(%539, 0);
  @tensor_array_unstack_tensor5_helper_int64(0, %540, %tensor41)
}

def @tensor_array_unstack_tensor5_int8(%tensor42: Tensor[(?, ?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %541 = shape_of(%tensor42, dtype="int32");
  %542 = take(%541, 0);
  @tensor_array_unstack_tensor5_helper_int8(0, %542, %tensor42)
}

def @tensor_array_unstack_tensor5_uint16(%tensor43: Tensor[(?, ?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %543 = shape_of(%tensor43, dtype="int32");
  %544 = take(%543, 0);
  @tensor_array_unstack_tensor5_helper_uint16(0, %544, %tensor43)
}

def @tensor_array_unstack_tensor5_uint8(%tensor44: Tensor[(?, ?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %545 = shape_of(%tensor44, dtype="int32");
  %546 = take(%545, 0);
  @tensor_array_unstack_tensor5_helper_uint8(0, %546, %tensor44)
}

def @tensor_array_unstack_tensor6_float16(%tensor45: Tensor[(?, ?, ?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %547 = shape_of(%tensor45, dtype="int32");
  %548 = take(%547, 0);
  @tensor_array_unstack_tensor6_helper_float16(0, %548, %tensor45)
}

def @tensor_array_unstack_tensor6_float32(%tensor46: Tensor[(?, ?, ?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %549 = shape_of(%tensor46, dtype="int32");
  %550 = take(%549, 0);
  @tensor_array_unstack_tensor6_helper_float32(0, %550, %tensor46)
}

def @tensor_array_unstack_tensor6_float64(%tensor47: Tensor[(?, ?, ?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %551 = shape_of(%tensor47, dtype="int32");
  %552 = take(%551, 0);
  @tensor_array_unstack_tensor6_helper_float64(0, %552, %tensor47)
}

def @tensor_array_unstack_tensor6_helper_float16(%i45: int32, %up45: int32, %t47: Tensor[(?, ?, ?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %553 = equal(%i45, %up45);
  if (%553) {
    Nil
  } else {
    %554 = take(%t47, %i45, axis=0);
    %555 = add(%i45, 1);
    %556 = tensor5_float16(%554);
    %557 = @tensor_array_unstack_tensor6_helper_float16(%555, %up45, %t47);
    Cons(%556, %557)
  }
}

def @tensor_array_unstack_tensor6_helper_float32(%i46: int32, %up46: int32, %t48: Tensor[(?, ?, ?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %558 = equal(%i46, %up46);
  if (%558) {
    Nil
  } else {
    %559 = take(%t48, %i46, axis=0);
    %560 = add(%i46, 1);
    %561 = tensor5_float32(%559);
    %562 = @tensor_array_unstack_tensor6_helper_float32(%560, %up46, %t48);
    Cons(%561, %562)
  }
}

def @tensor_array_unstack_tensor6_helper_float64(%i47: int32, %up47: int32, %t49: Tensor[(?, ?, ?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %563 = equal(%i47, %up47);
  if (%563) {
    Nil
  } else {
    %564 = take(%t49, %i47, axis=0);
    %565 = add(%i47, 1);
    %566 = tensor5_float64(%564);
    %567 = @tensor_array_unstack_tensor6_helper_float64(%565, %up47, %t49);
    Cons(%566, %567)
  }
}

def @tensor_array_unstack_tensor6_helper_int16(%i48: int32, %up48: int32, %t50: Tensor[(?, ?, ?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %568 = equal(%i48, %up48);
  if (%568) {
    Nil
  } else {
    %569 = take(%t50, %i48, axis=0);
    %570 = add(%i48, 1);
    %571 = tensor5_int16(%569);
    %572 = @tensor_array_unstack_tensor6_helper_int16(%570, %up48, %t50);
    Cons(%571, %572)
  }
}

def @tensor_array_unstack_tensor6_helper_int32(%i49: int32, %up49: int32, %t51: Tensor[(?, ?, ?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %573 = equal(%i49, %up49);
  if (%573) {
    Nil
  } else {
    %574 = take(%t51, %i49, axis=0);
    %575 = add(%i49, 1);
    %576 = tensor5_int32(%574);
    %577 = @tensor_array_unstack_tensor6_helper_int32(%575, %up49, %t51);
    Cons(%576, %577)
  }
}

def @tensor_array_unstack_tensor6_helper_int64(%i50: int32, %up50: int32, %t52: Tensor[(?, ?, ?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %578 = equal(%i50, %up50);
  if (%578) {
    Nil
  } else {
    %579 = take(%t52, %i50, axis=0);
    %580 = add(%i50, 1);
    %581 = tensor5_int64(%579);
    %582 = @tensor_array_unstack_tensor6_helper_int64(%580, %up50, %t52);
    Cons(%581, %582)
  }
}

def @tensor_array_unstack_tensor6_helper_int8(%i51: int32, %up51: int32, %t53: Tensor[(?, ?, ?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %583 = equal(%i51, %up51);
  if (%583) {
    Nil
  } else {
    %584 = take(%t53, %i51, axis=0);
    %585 = add(%i51, 1);
    %586 = tensor5_int8(%584);
    %587 = @tensor_array_unstack_tensor6_helper_int8(%585, %up51, %t53);
    Cons(%586, %587)
  }
}

def @tensor_array_unstack_tensor6_helper_uint16(%i52: int32, %up52: int32, %t54: Tensor[(?, ?, ?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %588 = equal(%i52, %up52);
  if (%588) {
    Nil
  } else {
    %589 = take(%t54, %i52, axis=0);
    %590 = add(%i52, 1);
    %591 = tensor5_uint16(%589);
    %592 = @tensor_array_unstack_tensor6_helper_uint16(%590, %up52, %t54);
    Cons(%591, %592)
  }
}

def @tensor_array_unstack_tensor6_helper_uint8(%i53: int32, %up53: int32, %t55: Tensor[(?, ?, ?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %593 = equal(%i53, %up53);
  if (%593) {
    Nil
  } else {
    %594 = take(%t55, %i53, axis=0);
    %595 = add(%i53, 1);
    %596 = tensor5_uint8(%594);
    %597 = @tensor_array_unstack_tensor6_helper_uint8(%595, %up53, %t55);
    Cons(%596, %597)
  }
}

def @tensor_array_unstack_tensor6_int16(%tensor48: Tensor[(?, ?, ?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %598 = shape_of(%tensor48, dtype="int32");
  %599 = take(%598, 0);
  @tensor_array_unstack_tensor6_helper_int16(0, %599, %tensor48)
}

def @tensor_array_unstack_tensor6_int32(%tensor49: Tensor[(?, ?, ?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %600 = shape_of(%tensor49, dtype="int32");
  %601 = take(%600, 0);
  @tensor_array_unstack_tensor6_helper_int32(0, %601, %tensor49)
}

def @tensor_array_unstack_tensor6_int64(%tensor50: Tensor[(?, ?, ?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %602 = shape_of(%tensor50, dtype="int32");
  %603 = take(%602, 0);
  @tensor_array_unstack_tensor6_helper_int64(0, %603, %tensor50)
}

def @tensor_array_unstack_tensor6_int8(%tensor51: Tensor[(?, ?, ?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %604 = shape_of(%tensor51, dtype="int32");
  %605 = take(%604, 0);
  @tensor_array_unstack_tensor6_helper_int8(0, %605, %tensor51)
}

def @tensor_array_unstack_tensor6_uint16(%tensor52: Tensor[(?, ?, ?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %606 = shape_of(%tensor52, dtype="int32");
  %607 = take(%606, 0);
  @tensor_array_unstack_tensor6_helper_uint16(0, %607, %tensor52)
}

def @tensor_array_unstack_tensor6_uint8(%tensor53: Tensor[(?, ?, ?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %608 = shape_of(%tensor53, dtype="int32");
  %609 = take(%608, 0);
  @tensor_array_unstack_tensor6_helper_uint8(0, %609, %tensor53)
}

def @tensor_array_write_float16(%tensor_array54: List[tensor_float16_t[]], %x31: int32, %v: tensor_float16_t[]) -> List[tensor_float16_t[]] {
  @update(%tensor_array54, %x31, %v)
}

def @tensor_array_write_float32(%tensor_array55: List[tensor_float32_t[]], %x32: int32, %v1: tensor_float32_t[]) -> List[tensor_float32_t[]] {
  @update(%tensor_array55, %x32, %v1)
}

def @tensor_array_write_float64(%tensor_array56: List[tensor_float64_t[]], %x33: int32, %v2: tensor_float64_t[]) -> List[tensor_float64_t[]] {
  @update(%tensor_array56, %x33, %v2)
}

def @tensor_array_write_int16(%tensor_array57: List[tensor_int16_t[]], %x34: int32, %v3: tensor_int16_t[]) -> List[tensor_int16_t[]] {
  @update(%tensor_array57, %x34, %v3)
}

def @tensor_array_write_int32(%tensor_array58: List[tensor_int32_t[]], %x35: int32, %v4: tensor_int32_t[]) -> List[tensor_int32_t[]] {
  @update(%tensor_array58, %x35, %v4)
}

def @tensor_array_write_int64(%tensor_array59: List[tensor_int64_t[]], %x36: int32, %v5: tensor_int64_t[]) -> List[tensor_int64_t[]] {
  @update(%tensor_array59, %x36, %v5)
}

def @tensor_array_write_int8(%tensor_array60: List[tensor_int8_t[]], %x37: int32, %v6: tensor_int8_t[]) -> List[tensor_int8_t[]] {
  @update(%tensor_array60, %x37, %v6)
}

def @tensor_array_write_uint16(%tensor_array61: List[tensor_uint16_t[]], %x38: int32, %v7: tensor_uint16_t[]) -> List[tensor_uint16_t[]] {
  @update(%tensor_array61, %x38, %v7)
}

def @tensor_array_write_uint8(%tensor_array62: List[tensor_uint8_t[]], %x39: int32, %v8: tensor_uint8_t[]) -> List[tensor_uint8_t[]] {
  @update(%tensor_array62, %x39, %v8)
}

def @tensor_concatenate_float16(%x40: tensor_float16_t[], %y1: tensor_float16_t[]) -> tensor_float16_t[] {
  match? (%x40) {
    tensor1_float16(%t111) => {
      match? (%y1) {
        tensor1_float16(%t121) => {
          %610 = (%t111, %t121);
          %611 = concatenate(%610);
          tensor1_float16(%611)
        },
      }
    },
    tensor2_float16(%t211) => {
      match? (%y1) {
        tensor2_float16(%t221) => {
          %612 = (%t211, %t221);
          %613 = concatenate(%612);
          tensor2_float16(%613)
        },
      }
    },
    tensor3_float16(%t311) => {
      match? (%y1) {
        tensor3_float16(%t321) => {
          %614 = (%t311, %t321);
          %615 = concatenate(%614);
          tensor3_float16(%615)
        },
      }
    },
    tensor4_float16(%t411) => {
      match? (%y1) {
        tensor4_float16(%t421) => {
          %616 = (%t411, %t421);
          %617 = concatenate(%616);
          tensor4_float16(%617)
        },
      }
    },
  }
}

def @tensor_concatenate_float32(%x41: tensor_float32_t[], %y2: tensor_float32_t[]) -> tensor_float32_t[] {
  match? (%x41) {
    tensor1_float32(%t112) => {
      match? (%y2) {
        tensor1_float32(%t122) => {
          %618 = (%t112, %t122);
          %619 = concatenate(%618);
          tensor1_float32(%619)
        },
      }
    },
    tensor2_float32(%t212) => {
      match? (%y2) {
        tensor2_float32(%t222) => {
          %620 = (%t212, %t222);
          %621 = concatenate(%620);
          tensor2_float32(%621)
        },
      }
    },
    tensor3_float32(%t312) => {
      match? (%y2) {
        tensor3_float32(%t322) => {
          %622 = (%t312, %t322);
          %623 = concatenate(%622);
          tensor3_float32(%623)
        },
      }
    },
    tensor4_float32(%t412) => {
      match? (%y2) {
        tensor4_float32(%t422) => {
          %624 = (%t412, %t422);
          %625 = concatenate(%624);
          tensor4_float32(%625)
        },
      }
    },
  }
}

def @tensor_concatenate_float64(%x42: tensor_float64_t[], %y3: tensor_float64_t[]) -> tensor_float64_t[] {
  match? (%x42) {
    tensor1_float64(%t113) => {
      match? (%y3) {
        tensor1_float64(%t123) => {
          %626 = (%t113, %t123);
          %627 = concatenate(%626);
          tensor1_float64(%627)
        },
      }
    },
    tensor2_float64(%t213) => {
      match? (%y3) {
        tensor2_float64(%t223) => {
          %628 = (%t213, %t223);
          %629 = concatenate(%628);
          tensor2_float64(%629)
        },
      }
    },
    tensor3_float64(%t313) => {
      match? (%y3) {
        tensor3_float64(%t323) => {
          %630 = (%t313, %t323);
          %631 = concatenate(%630);
          tensor3_float64(%631)
        },
      }
    },
    tensor4_float64(%t413) => {
      match? (%y3) {
        tensor4_float64(%t423) => {
          %632 = (%t413, %t423);
          %633 = concatenate(%632);
          tensor4_float64(%633)
        },
      }
    },
  }
}

def @tensor_concatenate_int16(%x43: tensor_int16_t[], %y4: tensor_int16_t[]) -> tensor_int16_t[] {
  match? (%x43) {
    tensor1_int16(%t114) => {
      match? (%y4) {
        tensor1_int16(%t124) => {
          %634 = (%t114, %t124);
          %635 = concatenate(%634);
          tensor1_int16(%635)
        },
      }
    },
    tensor2_int16(%t214) => {
      match? (%y4) {
        tensor2_int16(%t224) => {
          %636 = (%t214, %t224);
          %637 = concatenate(%636);
          tensor2_int16(%637)
        },
      }
    },
    tensor3_int16(%t314) => {
      match? (%y4) {
        tensor3_int16(%t324) => {
          %638 = (%t314, %t324);
          %639 = concatenate(%638);
          tensor3_int16(%639)
        },
      }
    },
    tensor4_int16(%t414) => {
      match? (%y4) {
        tensor4_int16(%t424) => {
          %640 = (%t414, %t424);
          %641 = concatenate(%640);
          tensor4_int16(%641)
        },
      }
    },
  }
}

def @tensor_concatenate_int32(%x44: tensor_int32_t[], %y5: tensor_int32_t[]) -> tensor_int32_t[] {
  match? (%x44) {
    tensor1_int32(%t115) => {
      match? (%y5) {
        tensor1_int32(%t125) => {
          %642 = (%t115, %t125);
          %643 = concatenate(%642);
          tensor1_int32(%643)
        },
      }
    },
    tensor2_int32(%t215) => {
      match? (%y5) {
        tensor2_int32(%t225) => {
          %644 = (%t215, %t225);
          %645 = concatenate(%644);
          tensor2_int32(%645)
        },
      }
    },
    tensor3_int32(%t315) => {
      match? (%y5) {
        tensor3_int32(%t325) => {
          %646 = (%t315, %t325);
          %647 = concatenate(%646);
          tensor3_int32(%647)
        },
      }
    },
    tensor4_int32(%t415) => {
      match? (%y5) {
        tensor4_int32(%t425) => {
          %648 = (%t415, %t425);
          %649 = concatenate(%648);
          tensor4_int32(%649)
        },
      }
    },
  }
}

def @tensor_concatenate_int64(%x45: tensor_int64_t[], %y6: tensor_int64_t[]) -> tensor_int64_t[] {
  match? (%x45) {
    tensor1_int64(%t116) => {
      match? (%y6) {
        tensor1_int64(%t126) => {
          %650 = (%t116, %t126);
          %651 = concatenate(%650);
          tensor1_int64(%651)
        },
      }
    },
    tensor2_int64(%t216) => {
      match? (%y6) {
        tensor2_int64(%t226) => {
          %652 = (%t216, %t226);
          %653 = concatenate(%652);
          tensor2_int64(%653)
        },
      }
    },
    tensor3_int64(%t316) => {
      match? (%y6) {
        tensor3_int64(%t326) => {
          %654 = (%t316, %t326);
          %655 = concatenate(%654);
          tensor3_int64(%655)
        },
      }
    },
    tensor4_int64(%t416) => {
      match? (%y6) {
        tensor4_int64(%t426) => {
          %656 = (%t416, %t426);
          %657 = concatenate(%656);
          tensor4_int64(%657)
        },
      }
    },
  }
}

def @tensor_concatenate_int8(%x46: tensor_int8_t[], %y7: tensor_int8_t[]) -> tensor_int8_t[] {
  match? (%x46) {
    tensor1_int8(%t117) => {
      match? (%y7) {
        tensor1_int8(%t127) => {
          %658 = (%t117, %t127);
          %659 = concatenate(%658);
          tensor1_int8(%659)
        },
      }
    },
    tensor2_int8(%t217) => {
      match? (%y7) {
        tensor2_int8(%t227) => {
          %660 = (%t217, %t227);
          %661 = concatenate(%660);
          tensor2_int8(%661)
        },
      }
    },
    tensor3_int8(%t317) => {
      match? (%y7) {
        tensor3_int8(%t327) => {
          %662 = (%t317, %t327);
          %663 = concatenate(%662);
          tensor3_int8(%663)
        },
      }
    },
    tensor4_int8(%t417) => {
      match? (%y7) {
        tensor4_int8(%t427) => {
          %664 = (%t417, %t427);
          %665 = concatenate(%664);
          tensor4_int8(%665)
        },
      }
    },
  }
}

def @tensor_concatenate_uint16(%x47: tensor_uint16_t[], %y8: tensor_uint16_t[]) -> tensor_uint16_t[] {
  match? (%x47) {
    tensor1_uint16(%t118) => {
      match? (%y8) {
        tensor1_uint16(%t128) => {
          %666 = (%t118, %t128);
          %667 = concatenate(%666);
          tensor1_uint16(%667)
        },
      }
    },
    tensor2_uint16(%t218) => {
      match? (%y8) {
        tensor2_uint16(%t228) => {
          %668 = (%t218, %t228);
          %669 = concatenate(%668);
          tensor2_uint16(%669)
        },
      }
    },
    tensor3_uint16(%t318) => {
      match? (%y8) {
        tensor3_uint16(%t328) => {
          %670 = (%t318, %t328);
          %671 = concatenate(%670);
          tensor3_uint16(%671)
        },
      }
    },
    tensor4_uint16(%t418) => {
      match? (%y8) {
        tensor4_uint16(%t428) => {
          %672 = (%t418, %t428);
          %673 = concatenate(%672);
          tensor4_uint16(%673)
        },
      }
    },
  }
}

def @tensor_concatenate_uint8(%x48: tensor_uint8_t[], %y9: tensor_uint8_t[]) -> tensor_uint8_t[] {
  match? (%x48) {
    tensor1_uint8(%t119) => {
      match? (%y9) {
        tensor1_uint8(%t129) => {
          %674 = (%t119, %t129);
          %675 = concatenate(%674);
          tensor1_uint8(%675)
        },
      }
    },
    tensor2_uint8(%t219) => {
      match? (%y9) {
        tensor2_uint8(%t229) => {
          %676 = (%t219, %t229);
          %677 = concatenate(%676);
          tensor2_uint8(%677)
        },
      }
    },
    tensor3_uint8(%t319) => {
      match? (%y9) {
        tensor3_uint8(%t329) => {
          %678 = (%t319, %t329);
          %679 = concatenate(%678);
          tensor3_uint8(%679)
        },
      }
    },
    tensor4_uint8(%t419) => {
      match? (%y9) {
        tensor4_uint8(%t429) => {
          %680 = (%t419, %t429);
          %681 = concatenate(%680);
          tensor4_uint8(%681)
        },
      }
    },
  }
}

def @tensor_expand_dims_float16(%x49: tensor_float16_t[]) -> tensor_float16_t[] {
  match? (%x49) {
    tensor0_float16(%t0) => {
      %682 = expand_dims(%t0, axis=0);
      tensor1_float16(%682)
    },
    tensor1_float16(%t110) => {
      %683 = expand_dims(%t110, axis=0);
      tensor2_float16(%683)
    },
    tensor2_float16(%t210) => {
      %684 = expand_dims(%t210, axis=0);
      tensor3_float16(%684)
    },
    tensor3_float16(%t310) => {
      %685 = expand_dims(%t310, axis=0);
      tensor4_float16(%685)
    },
    tensor4_float16(%t410) => {
      %686 = expand_dims(%t410, axis=0);
      tensor5_float16(%686)
    },
    tensor5_float16(%t56) => {
      %687 = expand_dims(%t56, axis=0);
      tensor6_float16(%687)
    },
  }
}

def @tensor_expand_dims_float32(%x50: tensor_float32_t[]) -> tensor_float32_t[] {
  match? (%x50) {
    tensor0_float32(%t01) => {
      %688 = expand_dims(%t01, axis=0);
      tensor1_float32(%688)
    },
    tensor1_float32(%t120) => {
      %689 = expand_dims(%t120, axis=0);
      tensor2_float32(%689)
    },
    tensor2_float32(%t220) => {
      %690 = expand_dims(%t220, axis=0);
      tensor3_float32(%690)
    },
    tensor3_float32(%t320) => {
      %691 = expand_dims(%t320, axis=0);
      tensor4_float32(%691)
    },
    tensor4_float32(%t420) => {
      %692 = expand_dims(%t420, axis=0);
      tensor5_float32(%692)
    },
    tensor5_float32(%t57) => {
      %693 = expand_dims(%t57, axis=0);
      tensor6_float32(%693)
    },
  }
}

def @tensor_expand_dims_float64(%x51: tensor_float64_t[]) -> tensor_float64_t[] {
  match? (%x51) {
    tensor0_float64(%t02) => {
      %694 = expand_dims(%t02, axis=0);
      tensor1_float64(%694)
    },
    tensor1_float64(%t130) => {
      %695 = expand_dims(%t130, axis=0);
      tensor2_float64(%695)
    },
    tensor2_float64(%t230) => {
      %696 = expand_dims(%t230, axis=0);
      tensor3_float64(%696)
    },
    tensor3_float64(%t330) => {
      %697 = expand_dims(%t330, axis=0);
      tensor4_float64(%697)
    },
    tensor4_float64(%t430) => {
      %698 = expand_dims(%t430, axis=0);
      tensor5_float64(%698)
    },
    tensor5_float64(%t58) => {
      %699 = expand_dims(%t58, axis=0);
      tensor6_float64(%699)
    },
  }
}

def @tensor_expand_dims_int16(%x52: tensor_int16_t[]) -> tensor_int16_t[] {
  match? (%x52) {
    tensor0_int16(%t03) => {
      %700 = expand_dims(%t03, axis=0);
      tensor1_int16(%700)
    },
    tensor1_int16(%t131) => {
      %701 = expand_dims(%t131, axis=0);
      tensor2_int16(%701)
    },
    tensor2_int16(%t231) => {
      %702 = expand_dims(%t231, axis=0);
      tensor3_int16(%702)
    },
    tensor3_int16(%t331) => {
      %703 = expand_dims(%t331, axis=0);
      tensor4_int16(%703)
    },
    tensor4_int16(%t431) => {
      %704 = expand_dims(%t431, axis=0);
      tensor5_int16(%704)
    },
    tensor5_int16(%t59) => {
      %705 = expand_dims(%t59, axis=0);
      tensor6_int16(%705)
    },
  }
}

def @tensor_expand_dims_int32(%x53: tensor_int32_t[]) -> tensor_int32_t[] {
  match? (%x53) {
    tensor0_int32(%t04) => {
      %706 = expand_dims(%t04, axis=0);
      tensor1_int32(%706)
    },
    tensor1_int32(%t132) => {
      %707 = expand_dims(%t132, axis=0);
      tensor2_int32(%707)
    },
    tensor2_int32(%t232) => {
      %708 = expand_dims(%t232, axis=0);
      tensor3_int32(%708)
    },
    tensor3_int32(%t332) => {
      %709 = expand_dims(%t332, axis=0);
      tensor4_int32(%709)
    },
    tensor4_int32(%t432) => {
      %710 = expand_dims(%t432, axis=0);
      tensor5_int32(%710)
    },
    tensor5_int32(%t510) => {
      %711 = expand_dims(%t510, axis=0);
      tensor6_int32(%711)
    },
  }
}

def @tensor_expand_dims_int64(%x54: tensor_int64_t[]) -> tensor_int64_t[] {
  match? (%x54) {
    tensor0_int64(%t05) => {
      %712 = expand_dims(%t05, axis=0);
      tensor1_int64(%712)
    },
    tensor1_int64(%t133) => {
      %713 = expand_dims(%t133, axis=0);
      tensor2_int64(%713)
    },
    tensor2_int64(%t233) => {
      %714 = expand_dims(%t233, axis=0);
      tensor3_int64(%714)
    },
    tensor3_int64(%t333) => {
      %715 = expand_dims(%t333, axis=0);
      tensor4_int64(%715)
    },
    tensor4_int64(%t433) => {
      %716 = expand_dims(%t433, axis=0);
      tensor5_int64(%716)
    },
    tensor5_int64(%t511) => {
      %717 = expand_dims(%t511, axis=0);
      tensor6_int64(%717)
    },
  }
}

def @tensor_expand_dims_int8(%x55: tensor_int8_t[]) -> tensor_int8_t[] {
  match? (%x55) {
    tensor0_int8(%t06) => {
      %718 = expand_dims(%t06, axis=0);
      tensor1_int8(%718)
    },
    tensor1_int8(%t134) => {
      %719 = expand_dims(%t134, axis=0);
      tensor2_int8(%719)
    },
    tensor2_int8(%t234) => {
      %720 = expand_dims(%t234, axis=0);
      tensor3_int8(%720)
    },
    tensor3_int8(%t334) => {
      %721 = expand_dims(%t334, axis=0);
      tensor4_int8(%721)
    },
    tensor4_int8(%t434) => {
      %722 = expand_dims(%t434, axis=0);
      tensor5_int8(%722)
    },
    tensor5_int8(%t512) => {
      %723 = expand_dims(%t512, axis=0);
      tensor6_int8(%723)
    },
  }
}

def @tensor_expand_dims_uint16(%x56: tensor_uint16_t[]) -> tensor_uint16_t[] {
  match? (%x56) {
    tensor0_uint16(%t07) => {
      %724 = expand_dims(%t07, axis=0);
      tensor1_uint16(%724)
    },
    tensor1_uint16(%t135) => {
      %725 = expand_dims(%t135, axis=0);
      tensor2_uint16(%725)
    },
    tensor2_uint16(%t235) => {
      %726 = expand_dims(%t235, axis=0);
      tensor3_uint16(%726)
    },
    tensor3_uint16(%t335) => {
      %727 = expand_dims(%t335, axis=0);
      tensor4_uint16(%727)
    },
    tensor4_uint16(%t435) => {
      %728 = expand_dims(%t435, axis=0);
      tensor5_uint16(%728)
    },
    tensor5_uint16(%t513) => {
      %729 = expand_dims(%t513, axis=0);
      tensor6_uint16(%729)
    },
  }
}

def @tensor_expand_dims_uint8(%x57: tensor_uint8_t[]) -> tensor_uint8_t[] {
  match? (%x57) {
    tensor0_uint8(%t08) => {
      %730 = expand_dims(%t08, axis=0);
      tensor1_uint8(%730)
    },
    tensor1_uint8(%t136) => {
      %731 = expand_dims(%t136, axis=0);
      tensor2_uint8(%731)
    },
    tensor2_uint8(%t236) => {
      %732 = expand_dims(%t236, axis=0);
      tensor3_uint8(%732)
    },
    tensor3_uint8(%t336) => {
      %733 = expand_dims(%t336, axis=0);
      tensor4_uint8(%733)
    },
    tensor4_uint8(%t436) => {
      %734 = expand_dims(%t436, axis=0);
      tensor5_uint8(%734)
    },
    tensor5_uint8(%t514) => {
      %735 = expand_dims(%t514, axis=0);
      tensor6_uint8(%735)
    },
  }
}

def @tensor_take_float16(%tensor54: tensor_float16_t[], %lower: int32, %upper: int32) -> tensor_float16_t[] {
  match? (%tensor54) {
    tensor1_float16(%t137) => {
      %736 = arange(%lower, %upper, 1, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][0], dtype="int32");
      %737 = take(%t137, %736);
      tensor1_float16(%737)
    },
    tensor2_float16(%t237) => {
      %738 = arange(%lower, %upper, 1, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][1], dtype="int32");
      %739 = take(%t237, %738, axis=0);
      tensor2_float16(%739)
    },
    tensor3_float16(%t337) => {
      %740 = arange(%lower, %upper, 1, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][2], dtype="int32");
      %741 = take(%t337, %740, axis=0);
      tensor3_float16(%741)
    },
    tensor4_float16(%t437) => {
      %742 = arange(%lower, %upper, 1, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][3], dtype="int32");
      %743 = take(%t437, %742, axis=0);
      tensor4_float16(%743)
    },
    tensor5_float16(%t515) => {
      %744 = arange(%lower, %upper, 1, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][4], dtype="int32");
      %745 = take(%t515, %744, axis=0);
      tensor5_float16(%745)
    },
    tensor6_float16(%t61) => {
      %746 = arange(%lower, %upper, 1, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][5], dtype="int32");
      %747 = take(%t61, %746, axis=0);
      tensor6_float16(%747)
    },
  }
}

def @tensor_take_float32(%tensor55: tensor_float32_t[], %lower1: int32, %upper1: int32) -> tensor_float32_t[] {
  match? (%tensor55) {
    tensor1_float32(%t138) => {
      %748 = arange(%lower1, %upper1, 1, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][6], dtype="int32");
      %749 = take(%t138, %748);
      tensor1_float32(%749)
    },
    tensor2_float32(%t238) => {
      %750 = arange(%lower1, %upper1, 1, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][7], dtype="int32");
      %751 = take(%t238, %750, axis=0);
      tensor2_float32(%751)
    },
    tensor3_float32(%t338) => {
      %752 = arange(%lower1, %upper1, 1, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][8], dtype="int32");
      %753 = take(%t338, %752, axis=0);
      tensor3_float32(%753)
    },
    tensor4_float32(%t438) => {
      %754 = arange(%lower1, %upper1, 1, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][9], dtype="int32");
      %755 = take(%t438, %754, axis=0);
      tensor4_float32(%755)
    },
    tensor5_float32(%t516) => {
      %756 = arange(%lower1, %upper1, 1, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][10], dtype="int32");
      %757 = take(%t516, %756, axis=0);
      tensor5_float32(%757)
    },
    tensor6_float32(%t62) => {
      %758 = arange(%lower1, %upper1, 1, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][11], dtype="int32");
      %759 = take(%t62, %758, axis=0);
      tensor6_float32(%759)
    },
  }
}

def @tensor_take_float64(%tensor56: tensor_float64_t[], %lower2: int32, %upper2: int32) -> tensor_float64_t[] {
  match? (%tensor56) {
    tensor1_float64(%t139) => {
      %760 = arange(%lower2, %upper2, 1, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][12], dtype="int32");
      %761 = take(%t139, %760);
      tensor1_float64(%761)
    },
    tensor2_float64(%t239) => {
      %762 = arange(%lower2, %upper2, 1, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][13], dtype="int32");
      %763 = take(%t239, %762, axis=0);
      tensor2_float64(%763)
    },
    tensor3_float64(%t339) => {
      %764 = arange(%lower2, %upper2, 1, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][14], dtype="int32");
      %765 = take(%t339, %764, axis=0);
      tensor3_float64(%765)
    },
    tensor4_float64(%t439) => {
      %766 = arange(%lower2, %upper2, 1, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][15], dtype="int32");
      %767 = take(%t439, %766, axis=0);
      tensor4_float64(%767)
    },
    tensor5_float64(%t517) => {
      %768 = arange(%lower2, %upper2, 1, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][16], dtype="int32");
      %769 = take(%t517, %768, axis=0);
      tensor5_float64(%769)
    },
    tensor6_float64(%t63) => {
      %770 = arange(%lower2, %upper2, 1, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][17], dtype="int32");
      %771 = take(%t63, %770, axis=0);
      tensor6_float64(%771)
    },
  }
}

def @tensor_take_int16(%tensor57: tensor_int16_t[], %lower3: int32, %upper3: int32) -> tensor_int16_t[] {
  match? (%tensor57) {
    tensor1_int16(%t140) => {
      %772 = arange(%lower3, %upper3, 1, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][18], dtype="int32");
      %773 = take(%t140, %772);
      tensor1_int16(%773)
    },
    tensor2_int16(%t240) => {
      %774 = arange(%lower3, %upper3, 1, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][19], dtype="int32");
      %775 = take(%t240, %774, axis=0);
      tensor2_int16(%775)
    },
    tensor3_int16(%t340) => {
      %776 = arange(%lower3, %upper3, 1, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][20], dtype="int32");
      %777 = take(%t340, %776, axis=0);
      tensor3_int16(%777)
    },
    tensor4_int16(%t440) => {
      %778 = arange(%lower3, %upper3, 1, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][21], dtype="int32");
      %779 = take(%t440, %778, axis=0);
      tensor4_int16(%779)
    },
    tensor5_int16(%t518) => {
      %780 = arange(%lower3, %upper3, 1, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][22], dtype="int32");
      %781 = take(%t518, %780, axis=0);
      tensor5_int16(%781)
    },
    tensor6_int16(%t64) => {
      %782 = arange(%lower3, %upper3, 1, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][23], dtype="int32");
      %783 = take(%t64, %782, axis=0);
      tensor6_int16(%783)
    },
  }
}

def @tensor_take_int32(%tensor58: tensor_int32_t[], %lower4: int32, %upper4: int32) -> tensor_int32_t[] {
  match? (%tensor58) {
    tensor1_int32(%t141) => {
      %784 = arange(%lower4, %upper4, 1, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][24], dtype="int32");
      %785 = take(%t141, %784);
      tensor1_int32(%785)
    },
    tensor2_int32(%t241) => {
      %786 = arange(%lower4, %upper4, 1, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][25], dtype="int32");
      %787 = take(%t241, %786, axis=0);
      tensor2_int32(%787)
    },
    tensor3_int32(%t341) => {
      %788 = arange(%lower4, %upper4, 1, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][26], dtype="int32");
      %789 = take(%t341, %788, axis=0);
      tensor3_int32(%789)
    },
    tensor4_int32(%t441) => {
      %790 = arange(%lower4, %upper4, 1, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][27], dtype="int32");
      %791 = take(%t441, %790, axis=0);
      tensor4_int32(%791)
    },
    tensor5_int32(%t519) => {
      %792 = arange(%lower4, %upper4, 1, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][28], dtype="int32");
      %793 = take(%t519, %792, axis=0);
      tensor5_int32(%793)
    },
    tensor6_int32(%t65) => {
      %794 = arange(%lower4, %upper4, 1, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][29], dtype="int32");
      %795 = take(%t65, %794, axis=0);
      tensor6_int32(%795)
    },
  }
}

def @tensor_take_int64(%tensor59: tensor_int64_t[], %lower5: int32, %upper5: int32) -> tensor_int64_t[] {
  match? (%tensor59) {
    tensor1_int64(%t142) => {
      %796 = arange(%lower5, %upper5, 1, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][30], dtype="int32");
      %797 = take(%t142, %796);
      tensor1_int64(%797)
    },
    tensor2_int64(%t242) => {
      %798 = arange(%lower5, %upper5, 1, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][31], dtype="int32");
      %799 = take(%t242, %798, axis=0);
      tensor2_int64(%799)
    },
    tensor3_int64(%t342) => {
      %800 = arange(%lower5, %upper5, 1, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][32], dtype="int32");
      %801 = take(%t342, %800, axis=0);
      tensor3_int64(%801)
    },
    tensor4_int64(%t442) => {
      %802 = arange(%lower5, %upper5, 1, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][33], dtype="int32");
      %803 = take(%t442, %802, axis=0);
      tensor4_int64(%803)
    },
    tensor5_int64(%t520) => {
      %804 = arange(%lower5, %upper5, 1, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][34], dtype="int32");
      %805 = take(%t520, %804, axis=0);
      tensor5_int64(%805)
    },
    tensor6_int64(%t66) => {
      %806 = arange(%lower5, %upper5, 1, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][35], dtype="int32");
      %807 = take(%t66, %806, axis=0);
      tensor6_int64(%807)
    },
  }
}

def @tensor_take_int8(%tensor60: tensor_int8_t[], %lower6: int32, %upper6: int32) -> tensor_int8_t[] {
  match? (%tensor60) {
    tensor1_int8(%t143) => {
      %808 = arange(%lower6, %upper6, 1, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][36], dtype="int32");
      %809 = take(%t143, %808);
      tensor1_int8(%809)
    },
    tensor2_int8(%t243) => {
      %810 = arange(%lower6, %upper6, 1, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][37], dtype="int32");
      %811 = take(%t243, %810, axis=0);
      tensor2_int8(%811)
    },
    tensor3_int8(%t343) => {
      %812 = arange(%lower6, %upper6, 1, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][38], dtype="int32");
      %813 = take(%t343, %812, axis=0);
      tensor3_int8(%813)
    },
    tensor4_int8(%t443) => {
      %814 = arange(%lower6, %upper6, 1, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][39], dtype="int32");
      %815 = take(%t443, %814, axis=0);
      tensor4_int8(%815)
    },
    tensor5_int8(%t521) => {
      %816 = arange(%lower6, %upper6, 1, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][40], dtype="int32");
      %817 = take(%t521, %816, axis=0);
      tensor5_int8(%817)
    },
    tensor6_int8(%t67) => {
      %818 = arange(%lower6, %upper6, 1, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][41], dtype="int32");
      %819 = take(%t67, %818, axis=0);
      tensor6_int8(%819)
    },
  }
}

def @tensor_take_uint16(%tensor61: tensor_uint16_t[], %lower7: int32, %upper7: int32) -> tensor_uint16_t[] {
  match? (%tensor61) {
    tensor1_uint16(%t144) => {
      %820 = arange(%lower7, %upper7, 1, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][42], dtype="int32");
      %821 = take(%t144, %820);
      tensor1_uint16(%821)
    },
    tensor2_uint16(%t244) => {
      %822 = arange(%lower7, %upper7, 1, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][43], dtype="int32");
      %823 = take(%t244, %822, axis=0);
      tensor2_uint16(%823)
    },
    tensor3_uint16(%t344) => {
      %824 = arange(%lower7, %upper7, 1, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][44], dtype="int32");
      %825 = take(%t344, %824, axis=0);
      tensor3_uint16(%825)
    },
    tensor4_uint16(%t444) => {
      %826 = arange(%lower7, %upper7, 1, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][45], dtype="int32");
      %827 = take(%t444, %826, axis=0);
      tensor4_uint16(%827)
    },
    tensor5_uint16(%t522) => {
      %828 = arange(%lower7, %upper7, 1, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][46], dtype="int32");
      %829 = take(%t522, %828, axis=0);
      tensor5_uint16(%829)
    },
    tensor6_uint16(%t68) => {
      %830 = arange(%lower7, %upper7, 1, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][47], dtype="int32");
      %831 = take(%t68, %830, axis=0);
      tensor6_uint16(%831)
    },
  }
}

def @tensor_take_uint8(%tensor62: tensor_uint8_t[], %lower8: int32, %upper8: int32) -> tensor_uint8_t[] {
  match? (%tensor62) {
    tensor1_uint8(%t145) => {
      %832 = arange(%lower8, %upper8, 1, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][48], dtype="int32");
      %833 = take(%t145, %832);
      tensor1_uint8(%833)
    },
    tensor2_uint8(%t245) => {
      %834 = arange(%lower8, %upper8, 1, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][49], dtype="int32");
      %835 = take(%t245, %834, axis=0);
      tensor2_uint8(%835)
    },
    tensor3_uint8(%t345) => {
      %836 = arange(%lower8, %upper8, 1, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][50], dtype="int32");
      %837 = take(%t345, %836, axis=0);
      tensor3_uint8(%837)
    },
    tensor4_uint8(%t445) => {
      %838 = arange(%lower8, %upper8, 1, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][51], dtype="int32");
      %839 = take(%t445, %838, axis=0);
      tensor4_uint8(%839)
    },
    tensor5_uint8(%t523) => {
      %840 = arange(%lower8, %upper8, 1, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][52], dtype="int32");
      %841 = take(%t523, %840, axis=0);
      tensor5_uint8(%841)
    },
    tensor6_uint8(%t69) => {
      %842 = arange(%lower8, %upper8, 1, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][53], dtype="int32");
      %843 = take(%t69, %842, axis=0);
      tensor6_uint8(%843)
    },
  }
}

def @tl[A](%xs13: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:59:11 */) -> List[A] {
  match? (%xs13) {
    Cons(_, %rest6: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:60:23 */) => {
      %rest6
    },
  }
}

def @tmap[A, B](%f10: fn (A) -> B /* ty=fn (A) -> B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:280:12 */, %t60: Tree[A] /* ty=Tree[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:275:9 */) -> Tree[B] {
  match (%t60) {
    Rose(%v9: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:280:15 */, %sub_trees1: List[Tree[A]] /* ty=List[Tree[A]] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:280:35 */) => {
      let %list_f: fn (Tree[A]) -> Tree[B] /* ty=fn (Tree[A]) -> Tree[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:280:26 */ = fn (%tt: Tree[A] /* ty=Tree[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:278:19 */) -> Tree[B] {
        @tmap(%f10, %tt) /* ty=Tree[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:278:9 */
      } /* ty=fn (Tree[A]) -> Tree[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:277:7 */;
      %844 = %f10(%v9) /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:280:12 */;
      %845 = @map(%list_f, %sub_trees1) /* ty=List[Tree[B]] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:280:20 */;
      Rose(%844, %845) /* ty=Tree[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:280:7 */
    },
  }
}

def @unfoldl[A, B](%f11: fn (A) -> Option[(A, B)] /* ty=fn (A) -> Option[(A, B)] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:258:17 */, %seed: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:258:21 */) -> List[B] {
  %846 = @unfoldr(%f11, %seed) /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:258:8 */;
  @rev(%846) /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:258:3 */
}

def @unfoldr[A, B](%f12: fn (A) -> Option[(A, B)] /* ty=fn (A) -> Option[(A, B)] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:245:41 */, %seed1: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:244:14 */) -> List[B] {
  %847 = %f12(%seed1) /* ty=Option[(A, B)] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:244:10 */;
  match (%847) {
    Some(%val: (A, B) /* ty=(A, B) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:245:45 */) => {
      %848 = %val.0 /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:245:45 */;
      %849 = %val.1 /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:245:24 */;
      %850 = @unfoldr(%f12, %848) /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:245:32 */;
      Cons(%849, %850) /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:245:19 */
    },
    None => {
      Nil /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:246:13 */
    },
  }
}

def @update[A](%xs14: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:32 */, %n2: int32 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:38 */, %v10: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:46 */) -> List[A] {
  %851 = equal(%n2, 0 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:89:15 */) /* ty=bool span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:89:7 */;
  if (%851) {
    %852 = @tl(%xs14) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:90:14 */;
    Cons(%v10, %852) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:90:5 */
  } else {
    %853 = @tl(%xs14) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:28 */;
    %854 = subtract(%n2, 1 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:44 */) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:38 */;
    %855 = @hd(%xs14) /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:10 */;
    %856 = @update(%853, %854, %v10) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:20 */;
    Cons(%855, %856) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:5 */
  }
}

def @zip[A, B](%xs15: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:187:11 */, %ys1: List[B] /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:187:16 */) -> List[(A, B)] {
  %857 = (%xs15, %ys1) /* ty=(List[A], List[B]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:187:10 */;
  match (%857) {
    (Cons(%x58: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:188:53 */, %x_rest: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:188:67 */), Cons(%y10: B /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:188:57 */, %y_rest: List[B] /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:188:76 */)) => {
      %858 = (%x58, %y10) /* ty=(A, B) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:188:52 */;
      %859 = @zip(%x_rest, %y_rest) /* ty=List[(A, B)] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:188:62 */;
      Cons(%858, %859) /* ty=List[(A, B)] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:188:47 */
    },
    _ => {
      Nil /* ty=List[(A, B)] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:189:10 */
    },
  }
}

#[metadata]
{
  "root": 1, 
  "nodes": [
    {
      "type_key": ""
    }, 
    {
      "type_key": "Map", 
      "keys": [
        "relay.Constant", 
        "relay.Var"
      ], 
      "data": [2, 59]
    }, 
    {
      "type_key": "Array", 
      "data": [
        3, 
        6, 
        7, 
        8, 
        9, 
        10, 
        11, 
        12, 
        13, 
        14, 
        15, 
        16, 
        17, 
        18, 
        19, 
        20, 
        21, 
        22, 
        23, 
        24, 
        25, 
        26, 
        27, 
        28, 
        29, 
        30, 
        31, 
        32, 
        33, 
        34, 
        35, 
        36, 
        37, 
        38, 
        39, 
        40, 
        41, 
        42, 
        43, 
        44, 
        45, 
        46, 
        47, 
        48, 
        49, 
        50, 
        51, 
        52, 
        53, 
        54, 
        55, 
        56, 
        57, 
        58
      ]
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "0", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "VirtualDevice", 
      "attrs": {
        "device_type_int": "-1", 
        "memory_scope": "5", 
        "target": "0", 
        "virtual_device_id": "-1"
      }
    }, 
    {
      "type_key": "runtime.String"
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "1", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "2", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "3", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "4", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "5", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "6", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "7", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "8", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "9", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "10", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "11", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "12", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "13", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "14", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "15", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "16", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "17", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "18", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "19", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "20", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "21", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "22", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "23", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "24", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "25", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "26", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "27", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "28", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "29", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "30", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "31", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "32", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "33", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "34", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "35", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "36", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "37", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "38", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "39", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "40", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "41", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "42", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "43", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "44", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "45", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "46", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "47", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "48", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "49", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "50", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "51", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "52", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "53", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [
        60, 
        65, 
        70, 
        75, 
        80, 
        85, 
        90, 
        95, 
        100, 
        105, 
        110, 
        115, 
        120, 
        125, 
        130, 
        135, 
        140, 
        145
      ]
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "63", 
        "vid": "61", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "62"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "64", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "68", 
        "vid": "66", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "67"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "69", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "73", 
        "vid": "71", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "72"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "74", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "78", 
        "vid": "76", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "77"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "79", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "83", 
        "vid": "81", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "82"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "84", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "88", 
        "vid": "86", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "87"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "89", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "93", 
        "vid": "91", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "92"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "94", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "98", 
        "vid": "96", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "97"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "99", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "103", 
        "vid": "101", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "102"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "104", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "108", 
        "vid": "106", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "107"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "109", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "113", 
        "vid": "111", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "112"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "114", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "118", 
        "vid": "116", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "117"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "119", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "123", 
        "vid": "121", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "122"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "124", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "128", 
        "vid": "126", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "127"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "129", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "133", 
        "vid": "131", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "132"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "134", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "138", 
        "vid": "136", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "137"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "139", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "143", 
        "vid": "141", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "142"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "144", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "148", 
        "vid": "146", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "147"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "149", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }
  ], 
  "b64ndarrays": [
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA="
  ], 
  "attrs": {"tvm_version": "0.13.dev0"}
}