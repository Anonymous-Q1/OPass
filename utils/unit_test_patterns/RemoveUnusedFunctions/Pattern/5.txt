#[version = "0.0.5"]
type List[A] {
  Cons(A, List[A]),
  Nil,
}

type Option[A] {
  Some(A),
  None,
}

type Tree[A] {
  Rose(A, List[Tree[A]]),
}

type tensor_float16_t {
  tensor_nil_float16,
  tensor0_float16(float16),
  tensor1_float16(Tensor[(?), float16]),
  tensor2_float16(Tensor[(?, ?), float16]),
  tensor3_float16(Tensor[(?, ?, ?), float16]),
  tensor4_float16(Tensor[(?, ?, ?, ?), float16]),
  tensor5_float16(Tensor[(?, ?, ?, ?, ?), float16]),
  tensor6_float16(Tensor[(?, ?, ?, ?, ?, ?), float16]),
}

type tensor_float32_t {
  tensor_nil_float32,
  tensor0_float32(float32),
  tensor1_float32(Tensor[(?), float32]),
  tensor2_float32(Tensor[(?, ?), float32]),
  tensor3_float32(Tensor[(?, ?, ?), float32]),
  tensor4_float32(Tensor[(?, ?, ?, ?), float32]),
  tensor5_float32(Tensor[(?, ?, ?, ?, ?), float32]),
  tensor6_float32(Tensor[(?, ?, ?, ?, ?, ?), float32]),
}

type tensor_float64_t {
  tensor_nil_float64,
  tensor0_float64(float64),
  tensor1_float64(Tensor[(?), float64]),
  tensor2_float64(Tensor[(?, ?), float64]),
  tensor3_float64(Tensor[(?, ?, ?), float64]),
  tensor4_float64(Tensor[(?, ?, ?, ?), float64]),
  tensor5_float64(Tensor[(?, ?, ?, ?, ?), float64]),
  tensor6_float64(Tensor[(?, ?, ?, ?, ?, ?), float64]),
}

type tensor_int16_t {
  tensor_nil_int16,
  tensor0_int16(int16),
  tensor1_int16(Tensor[(?), int16]),
  tensor2_int16(Tensor[(?, ?), int16]),
  tensor3_int16(Tensor[(?, ?, ?), int16]),
  tensor4_int16(Tensor[(?, ?, ?, ?), int16]),
  tensor5_int16(Tensor[(?, ?, ?, ?, ?), int16]),
  tensor6_int16(Tensor[(?, ?, ?, ?, ?, ?), int16]),
}

type tensor_int32_t {
  tensor_nil_int32,
  tensor0_int32(int32),
  tensor1_int32(Tensor[(?), int32]),
  tensor2_int32(Tensor[(?, ?), int32]),
  tensor3_int32(Tensor[(?, ?, ?), int32]),
  tensor4_int32(Tensor[(?, ?, ?, ?), int32]),
  tensor5_int32(Tensor[(?, ?, ?, ?, ?), int32]),
  tensor6_int32(Tensor[(?, ?, ?, ?, ?, ?), int32]),
}

type tensor_int64_t {
  tensor_nil_int64,
  tensor0_int64(int64),
  tensor1_int64(Tensor[(?), int64]),
  tensor2_int64(Tensor[(?, ?), int64]),
  tensor3_int64(Tensor[(?, ?, ?), int64]),
  tensor4_int64(Tensor[(?, ?, ?, ?), int64]),
  tensor5_int64(Tensor[(?, ?, ?, ?, ?), int64]),
  tensor6_int64(Tensor[(?, ?, ?, ?, ?, ?), int64]),
}

type tensor_int8_t {
  tensor_nil_int8,
  tensor0_int8(int8),
  tensor1_int8(Tensor[(?), int8]),
  tensor2_int8(Tensor[(?, ?), int8]),
  tensor3_int8(Tensor[(?, ?, ?), int8]),
  tensor4_int8(Tensor[(?, ?, ?, ?), int8]),
  tensor5_int8(Tensor[(?, ?, ?, ?, ?), int8]),
  tensor6_int8(Tensor[(?, ?, ?, ?, ?, ?), int8]),
}

type tensor_uint16_t {
  tensor_nil_uint16,
  tensor0_uint16(uint16),
  tensor1_uint16(Tensor[(?), uint16]),
  tensor2_uint16(Tensor[(?, ?), uint16]),
  tensor3_uint16(Tensor[(?, ?, ?), uint16]),
  tensor4_uint16(Tensor[(?, ?, ?, ?), uint16]),
  tensor5_uint16(Tensor[(?, ?, ?, ?, ?), uint16]),
  tensor6_uint16(Tensor[(?, ?, ?, ?, ?, ?), uint16]),
}

type tensor_uint8_t {
  tensor_nil_uint8,
  tensor0_uint8(uint8),
  tensor1_uint8(Tensor[(?), uint8]),
  tensor2_uint8(Tensor[(?, ?), uint8]),
  tensor3_uint8(Tensor[(?, ?, ?), uint8]),
  tensor4_uint8(Tensor[(?, ?, ?, ?), uint8]),
  tensor5_uint8(Tensor[(?, ?, ?, ?, ?), uint8]),
  tensor6_uint8(Tensor[(?, ?, ?, ?, ?, ?), uint8]),
}

def @compose[A, B, C](%f: fn (B) -> C /* ty=fn (B) -> C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:27:5 */, %g: fn (A) -> B /* ty=fn (A) -> B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:27:8 */) -> fn (A) -> C {
  fn (%x: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:27:11 */) -> C {
    %0 = %g(%x) /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:27:8 */;
    %f(%0) /* ty=C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:27:5 */
  } /* ty=fn (A) -> C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:26:3 */
}

def @concat[A](%xs: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:162:21 */, %ys: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:162:16 */) -> List[A] {
  @foldr(Cons, %ys, %xs) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:162:3 */
}

def @filter[A](%f1: fn (A) -> bool /* ty=fn (A) -> bool span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:174:17 */, %xs1: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:169:10 */) -> List[A] {
  match (%xs1) {
    Cons(%x1: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:172:14 */, %rest: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:174:21 */) => {
      %1 = %f1(%x1) /* ty=bool span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:171:11 */;
      if (%1) {
        %2 = @filter(%f1, %rest) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:172:18 */;
        Cons(%x1, %2) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:172:9 */
      } else {
        @filter(%f1, %rest) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:174:9 */
      }
    },
    Nil => {
      Nil /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:177:12 */
    },
  }
}

def @flip[A, B, C](%f2: fn (A, B) -> C /* ty=fn (A, B) -> C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:33:5 */) -> fn (B, A) -> C {
  fn (%b: B /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:33:12 */, %a: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:33:8 */) -> C {
    %f2(%a, %b) /* ty=C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:33:5 */
  } /* ty=fn (B, A) -> C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:32:3 */
}

def @foldl[A, B](%f3: fn (A, B) -> A /* ty=fn (A, B) -> A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:115:35 */, %acc: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:116:12 */, %xs2: List[B] /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:114:10 */) -> A {
  match (%xs2) {
    Cons(%x2: B /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:115:44 */, %rest1: List[B] /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:115:49 */) => {
      %3 = %f3(%acc, %x2) /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:115:35 */;
      @foldl(%f3, %3, %rest1) /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:115:24 */
    },
    Nil => {
      %acc
    },
  }
}

def @foldr[A, B](%f4: fn (A, B) -> B /* ty=fn (A, B) -> B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:128:38 */, %acc1: B /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:129:12 */, %xs3: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:127:10 */) -> B {
  match (%xs3) {
    Cons(%x3: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:128:27 */, %rest2: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:128:48 */) => {
      %4 = @foldr(%f4, %acc1, %rest2) /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:128:31 */;
      %f4(%x3, %4) /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:128:24 */
    },
    Nil => {
      %acc1
    },
  }
}

def @foldr1[A](%f5: fn (A, A) -> A /* ty=fn (A, A) -> A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:142:39 */, %xs4: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:140:11 */) -> A {
  match? (%xs4) {
    Cons(%x4: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:141:22 */, Nil) => {
      %x4
    },
    Cons(%x5: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:142:27 */, %rest3: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:142:43 */) => {
      %5 = @foldr1(%f5, %rest3) /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:142:31 */;
      %f5(%x5, %5) /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:142:24 */
    },
  }
}

def @hd[A](%xs5: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:50:11 */) -> A {
  match? (%xs5) {
    Cons(%x6: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:51:20 */, _) => {
      %x6
    },
  }
}

def @id[A](%x7: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:22:3 */) -> A {
  %x7
}

def @iterate[A](%f6: fn (A) -> A /* ty=fn (A) -> A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:304:28 */, %n: int32 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:304:32 */) -> fn (A) -> A {
  %6 = equal(%n, 0 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:301:15 */) /* ty=bool span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:301:7 */;
  if (%6) {
    @id
  } else {
    %7 = subtract(%n, 1 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:304:38 */) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:304:32 */;
    %8 = @iterate(%f6, %7) /* ty=fn (A) -> A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:304:18 */;
    @compose(%f6, %8) /* ty=fn [A](A) -> A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:304:5 */
  }
}

def @length[A](%xs6: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:79:10 */) -> int32 {
  match (%xs6) {
    Cons(_, %rest4: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:80:35 */) => {
      %9 = @length(%rest4) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:80:27 */;
      add(1 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:80:24 */, %9) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:80:24 */
    },
    Nil => {
      0 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:81:13 */
    },
  }
}

def @main(%v) {
  %10 = @tensor_array_int32(3);
  %11 = tensor1_int32(%v);
  %12 = @tensor_array_write_int32(%10, 0, %11);
  @tensor_array_stack_int32(%12)
}

def @map[A, B](%f7: fn (A) -> B /* ty=fn (A) -> B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:102:43 */, %xs7: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:101:10 */) -> List[B] {
  match (%xs7) {
    Cons(%x8: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:102:32 */, %rest5: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:102:47 */) => {
      %13 = %f7(%x8) /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:102:29 */;
      %14 = @map(%f7, %rest5) /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:102:37 */;
      Cons(%13, %14) /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:102:24 */
    },
    Nil => {
      Nil /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:103:12 */
    },
  }
}

def @map_accuml[A, B, C](%f8: fn (A, B) -> (A, C) /* ty=fn (A, B) -> (A, C) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:222:18 */, %init: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:225:21 */, %xs8: List[B] /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:225:36 */) -> (A, List[C]) {
  let %updater: fn ((A, List[C]), B) -> (A, List[C]) /* ty=fn ((A, List[C]), B) -> (A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:225:10 */ = fn (%acc2: (A, List[C]) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:223:31 */, %x9: B /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:222:29 */) -> (A, List[C]) {
    %15 = %acc2.0 /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:222:21 */;
    let %f_out: (A, C) /* ty=(A, C) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:223:21 */ = %f8(%15, %x9) /* ty=(A, C) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:222:18 */;
    %16 = %f_out.1 /* ty=C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:223:21 */;
    %17 = %acc2.1 /* ty=List[C] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:223:31 */;
    %18 = %f_out.0 /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:223:6 */;
    %19 = Cons(%16, %17) /* ty=List[C] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:223:16 */;
    (%18, %19) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:223:5 */
  } /* ty=fn ((A, List[C]), B) -> (A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:221:3 */;
  %20 = Nil /* ty=List[C] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:225:30 */;
  %21 = (%init, %20) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:225:20 */;
  @foldl(%updater, %21, %xs8) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:225:3 */
}

def @map_accumr[A, B, C](%f9: fn (A, B) -> (A, C) /* ty=fn (A, B) -> (A, C) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:208:18 */, %init1: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:211:21 */, %xs9: List[B] /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:211:36 */) -> (A, List[C]) {
  let %updater1: fn (B, (A, List[C])) -> (A, List[C]) /* ty=fn (B, (A, List[C])) -> (A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:211:10 */ = fn (%x10: B /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:208:29 */, %acc3: (A, List[C]) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:209:31 */) -> (A, List[C]) {
    %22 = %acc3.0 /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:208:21 */;
    let %f_out1: (A, C) /* ty=(A, C) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:209:21 */ = %f9(%22, %x10) /* ty=(A, C) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:208:18 */;
    %23 = %f_out1.1 /* ty=C span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:209:21 */;
    %24 = %acc3.1 /* ty=List[C] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:209:31 */;
    %25 = %f_out1.0 /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:209:6 */;
    %26 = Cons(%23, %24) /* ty=List[C] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:209:16 */;
    (%25, %26) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:209:5 */
  } /* ty=fn (B, (A, List[C])) -> (A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:207:3 */;
  %27 = Nil /* ty=List[C] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:211:30 */;
  %28 = (%init1, %27) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:211:20 */;
  @foldr(%updater1, %28, %xs9) /* ty=(A, List[C]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:211:3 */
}

def @nth[A](%xs10: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:71:14 */, %n1: int32 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:71:20 */) -> A {
  %29 = equal(%n1, 0 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:68:15 */) /* ty=bool span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:68:7 */;
  if (%29) {
    @hd(%xs10) /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:69:5 */
  } else {
    %30 = @tl(%xs10) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:71:10 */;
    %31 = subtract(%n1, 1 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:71:26 */) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:71:20 */;
    @nth(%30, %31) /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:71:5 */
  }
}

def @rev[A](%xs11: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:64 */) -> List[A] {
  %32 = fn (%h: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:47 */, %t: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:51 */) -> List[A] {
    Cons(%h, %t) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:42 */
  } /* ty=fn (A, List[A]) -> List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:16 */;
  %33 = @flip(%32) /* ty=fn (List[A], A) -> List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:10 */;
  %34 = Nil /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:59 */;
  @foldl(%33, %34, %xs11) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:197:3 */
}

def @size[A](%t1: Tree[A] /* ty=Tree[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:289:9 */) -> int32 {
  match (%t1) {
    Rose(_, %sub_trees: List[Tree[A]] /* ty=List[Tree[A]] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:291:29 */) => {
      %35 = @map(@size, %sub_trees) /* ty=List[int32] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:291:16 */;
      %36 = @sum(%35) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:291:11 */;
      add(1 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:291:8 */, %36) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:290:5 */
    },
  }
}

def @sum(%xs12: List[int32] /* ty=List[int32] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:154:21 */) -> int32 {
  let %add_f: fn (int32, int32) -> int32 /* ty=fn (int32, int32) -> int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:154:10 */ = fn (%x11: int32 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:152:5 */, %y: int32 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:152:10 */) -> int32 {
    add(%x11, %y) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:152:5 */
  } /* ty=fn (int32, int32) -> int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:151:3 */;
  @foldl(%add_f, 0 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:154:19 */, %xs12) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:154:3 */
}

def @ta_split_helper_float16(%tensor_array: List[tensor_float16_t[]], %value1: tensor_float16_t[], %offset1: int32, %current1: int32, %limit1: int32, %lengths: Tensor[(?), int32]) -> List[tensor_float16_t[]] {
  %37 = equal(%current1, %limit1);
  if (%37) {
    %tensor_array
  } else {
    %38 = take(%lengths, %current1);
    %39 = add(%offset1, %38);
    %40 = add(%current1, 1);
    %41 = take(%lengths, %current1);
    %42 = add(%41, %offset1);
    %43 = @ta_split_helper_float16(%tensor_array, %value1, %39, %40, %limit1, %lengths);
    %44 = @tensor_take_float16(%value1, %offset1, %42);
    @tensor_array_write_float16(%43, %current1, %44)
  }
}

def @ta_split_helper_float32(%tensor_array1: List[tensor_float32_t[]], %value11: tensor_float32_t[], %offset11: int32, %current11: int32, %limit11: int32, %lengths1: Tensor[(?), int32]) -> List[tensor_float32_t[]] {
  %45 = equal(%current11, %limit11);
  if (%45) {
    %tensor_array1
  } else {
    %46 = take(%lengths1, %current11);
    %47 = add(%offset11, %46);
    %48 = add(%current11, 1);
    %49 = take(%lengths1, %current11);
    %50 = add(%49, %offset11);
    %51 = @ta_split_helper_float32(%tensor_array1, %value11, %47, %48, %limit11, %lengths1);
    %52 = @tensor_take_float32(%value11, %offset11, %50);
    @tensor_array_write_float32(%51, %current11, %52)
  }
}

def @ta_split_helper_float64(%tensor_array2: List[tensor_float64_t[]], %value12: tensor_float64_t[], %offset12: int32, %current12: int32, %limit12: int32, %lengths2: Tensor[(?), int32]) -> List[tensor_float64_t[]] {
  %53 = equal(%current12, %limit12);
  if (%53) {
    %tensor_array2
  } else {
    %54 = take(%lengths2, %current12);
    %55 = add(%offset12, %54);
    %56 = add(%current12, 1);
    %57 = take(%lengths2, %current12);
    %58 = add(%57, %offset12);
    %59 = @ta_split_helper_float64(%tensor_array2, %value12, %55, %56, %limit12, %lengths2);
    %60 = @tensor_take_float64(%value12, %offset12, %58);
    @tensor_array_write_float64(%59, %current12, %60)
  }
}

def @ta_split_helper_int16(%tensor_array3: List[tensor_int16_t[]], %value13: tensor_int16_t[], %offset13: int32, %current13: int32, %limit13: int32, %lengths3: Tensor[(?), int32]) -> List[tensor_int16_t[]] {
  %61 = equal(%current13, %limit13);
  if (%61) {
    %tensor_array3
  } else {
    %62 = take(%lengths3, %current13);
    %63 = add(%offset13, %62);
    %64 = add(%current13, 1);
    %65 = take(%lengths3, %current13);
    %66 = add(%65, %offset13);
    %67 = @ta_split_helper_int16(%tensor_array3, %value13, %63, %64, %limit13, %lengths3);
    %68 = @tensor_take_int16(%value13, %offset13, %66);
    @tensor_array_write_int16(%67, %current13, %68)
  }
}

def @ta_split_helper_int32(%tensor_array4: List[tensor_int32_t[]], %value14: tensor_int32_t[], %offset14: int32, %current14: int32, %limit14: int32, %lengths4: Tensor[(?), int32]) -> List[tensor_int32_t[]] {
  %69 = equal(%current14, %limit14);
  if (%69) {
    %tensor_array4
  } else {
    %70 = take(%lengths4, %current14);
    %71 = add(%offset14, %70);
    %72 = add(%current14, 1);
    %73 = take(%lengths4, %current14);
    %74 = add(%73, %offset14);
    %75 = @ta_split_helper_int32(%tensor_array4, %value14, %71, %72, %limit14, %lengths4);
    %76 = @tensor_take_int32(%value14, %offset14, %74);
    @tensor_array_write_int32(%75, %current14, %76)
  }
}

def @ta_split_helper_int64(%tensor_array5: List[tensor_int64_t[]], %value15: tensor_int64_t[], %offset15: int32, %current15: int32, %limit15: int32, %lengths5: Tensor[(?), int32]) -> List[tensor_int64_t[]] {
  %77 = equal(%current15, %limit15);
  if (%77) {
    %tensor_array5
  } else {
    %78 = take(%lengths5, %current15);
    %79 = add(%offset15, %78);
    %80 = add(%current15, 1);
    %81 = take(%lengths5, %current15);
    %82 = add(%81, %offset15);
    %83 = @ta_split_helper_int64(%tensor_array5, %value15, %79, %80, %limit15, %lengths5);
    %84 = @tensor_take_int64(%value15, %offset15, %82);
    @tensor_array_write_int64(%83, %current15, %84)
  }
}

def @ta_split_helper_int8(%tensor_array6: List[tensor_int8_t[]], %value16: tensor_int8_t[], %offset16: int32, %current16: int32, %limit16: int32, %lengths6: Tensor[(?), int32]) -> List[tensor_int8_t[]] {
  %85 = equal(%current16, %limit16);
  if (%85) {
    %tensor_array6
  } else {
    %86 = take(%lengths6, %current16);
    %87 = add(%offset16, %86);
    %88 = add(%current16, 1);
    %89 = take(%lengths6, %current16);
    %90 = add(%89, %offset16);
    %91 = @ta_split_helper_int8(%tensor_array6, %value16, %87, %88, %limit16, %lengths6);
    %92 = @tensor_take_int8(%value16, %offset16, %90);
    @tensor_array_write_int8(%91, %current16, %92)
  }
}

def @ta_split_helper_uint16(%tensor_array7: List[tensor_uint16_t[]], %value17: tensor_uint16_t[], %offset17: int32, %current17: int32, %limit17: int32, %lengths7: Tensor[(?), int32]) -> List[tensor_uint16_t[]] {
  %93 = equal(%current17, %limit17);
  if (%93) {
    %tensor_array7
  } else {
    %94 = take(%lengths7, %current17);
    %95 = add(%offset17, %94);
    %96 = add(%current17, 1);
    %97 = take(%lengths7, %current17);
    %98 = add(%97, %offset17);
    %99 = @ta_split_helper_uint16(%tensor_array7, %value17, %95, %96, %limit17, %lengths7);
    %100 = @tensor_take_uint16(%value17, %offset17, %98);
    @tensor_array_write_uint16(%99, %current17, %100)
  }
}

def @ta_split_helper_uint8(%tensor_array8: List[tensor_uint8_t[]], %value18: tensor_uint8_t[], %offset18: int32, %current18: int32, %limit18: int32, %lengths8: Tensor[(?), int32]) -> List[tensor_uint8_t[]] {
  %101 = equal(%current18, %limit18);
  if (%101) {
    %tensor_array8
  } else {
    %102 = take(%lengths8, %current18);
    %103 = add(%offset18, %102);
    %104 = add(%current18, 1);
    %105 = take(%lengths8, %current18);
    %106 = add(%105, %offset18);
    %107 = @ta_split_helper_uint8(%tensor_array8, %value18, %103, %104, %limit18, %lengths8);
    %108 = @tensor_take_uint8(%value18, %offset18, %106);
    @tensor_array_write_uint8(%107, %current18, %108)
  }
}

def @tensor_array_concat_float16(%tensor_array9: List[tensor_float16_t[]]) -> tensor_float16_t[] {
  match? (%tensor_array9) {
    Nil => {
      tensor_nil_float16
    },
    Cons(%hd, %tl) => {
      match? (%tl) {
        Nil => {
          %hd
        },
        _ => {
          %109 = @tensor_array_concat_float16(%tl);
          @tensor_concatenate_float16(%hd, %109)
        },
      }
    },
  }
}

def @tensor_array_concat_float32(%tensor_array10: List[tensor_float32_t[]]) -> tensor_float32_t[] {
  match? (%tensor_array10) {
    Nil => {
      tensor_nil_float32
    },
    Cons(%hd1, %tl1) => {
      match? (%tl1) {
        Nil => {
          %hd1
        },
        _ => {
          %110 = @tensor_array_concat_float32(%tl1);
          @tensor_concatenate_float32(%hd1, %110)
        },
      }
    },
  }
}

def @tensor_array_concat_float64(%tensor_array11: List[tensor_float64_t[]]) -> tensor_float64_t[] {
  match? (%tensor_array11) {
    Nil => {
      tensor_nil_float64
    },
    Cons(%hd2, %tl2) => {
      match? (%tl2) {
        Nil => {
          %hd2
        },
        _ => {
          %111 = @tensor_array_concat_float64(%tl2);
          @tensor_concatenate_float64(%hd2, %111)
        },
      }
    },
  }
}

def @tensor_array_concat_int16(%tensor_array12: List[tensor_int16_t[]]) -> tensor_int16_t[] {
  match? (%tensor_array12) {
    Nil => {
      tensor_nil_int16
    },
    Cons(%hd3, %tl3) => {
      match? (%tl3) {
        Nil => {
          %hd3
        },
        _ => {
          %112 = @tensor_array_concat_int16(%tl3);
          @tensor_concatenate_int16(%hd3, %112)
        },
      }
    },
  }
}

def @tensor_array_concat_int32(%tensor_array13: List[tensor_int32_t[]]) -> tensor_int32_t[] {
  match? (%tensor_array13) {
    Nil => {
      tensor_nil_int32
    },
    Cons(%hd4, %tl4) => {
      match? (%tl4) {
        Nil => {
          %hd4
        },
        _ => {
          %113 = @tensor_array_concat_int32(%tl4);
          @tensor_concatenate_int32(%hd4, %113)
        },
      }
    },
  }
}

def @tensor_array_concat_int64(%tensor_array14: List[tensor_int64_t[]]) -> tensor_int64_t[] {
  match? (%tensor_array14) {
    Nil => {
      tensor_nil_int64
    },
    Cons(%hd5, %tl5) => {
      match? (%tl5) {
        Nil => {
          %hd5
        },
        _ => {
          %114 = @tensor_array_concat_int64(%tl5);
          @tensor_concatenate_int64(%hd5, %114)
        },
      }
    },
  }
}

def @tensor_array_concat_int8(%tensor_array15: List[tensor_int8_t[]]) -> tensor_int8_t[] {
  match? (%tensor_array15) {
    Nil => {
      tensor_nil_int8
    },
    Cons(%hd6, %tl6) => {
      match? (%tl6) {
        Nil => {
          %hd6
        },
        _ => {
          %115 = @tensor_array_concat_int8(%tl6);
          @tensor_concatenate_int8(%hd6, %115)
        },
      }
    },
  }
}

def @tensor_array_concat_uint16(%tensor_array16: List[tensor_uint16_t[]]) -> tensor_uint16_t[] {
  match? (%tensor_array16) {
    Nil => {
      tensor_nil_uint16
    },
    Cons(%hd7, %tl7) => {
      match? (%tl7) {
        Nil => {
          %hd7
        },
        _ => {
          %116 = @tensor_array_concat_uint16(%tl7);
          @tensor_concatenate_uint16(%hd7, %116)
        },
      }
    },
  }
}

def @tensor_array_concat_uint8(%tensor_array17: List[tensor_uint8_t[]]) -> tensor_uint8_t[] {
  match? (%tensor_array17) {
    Nil => {
      tensor_nil_uint8
    },
    Cons(%hd8, %tl8) => {
      match? (%tl8) {
        Nil => {
          %hd8
        },
        _ => {
          %117 = @tensor_array_concat_uint8(%tl8);
          @tensor_concatenate_uint8(%hd8, %117)
        },
      }
    },
  }
}

def @tensor_array_float16(%x12: int32) -> List[tensor_float16_t[]] {
  %118 = equal(%x12, 0);
  if (%118) {
    Nil
  } else {
    %119 = subtract(%x12, 1);
    %120 = tensor_nil_float16;
    %121 = @tensor_array_float16(%119);
    Cons(%120, %121)
  }
}

def @tensor_array_float32(%x13: int32) -> List[tensor_float32_t[]] {
  %122 = equal(%x13, 0);
  if (%122) {
    Nil
  } else {
    %123 = subtract(%x13, 1);
    %124 = tensor_nil_float32;
    %125 = @tensor_array_float32(%123);
    Cons(%124, %125)
  }
}

def @tensor_array_float64(%x14: int32) -> List[tensor_float64_t[]] {
  %126 = equal(%x14, 0);
  if (%126) {
    Nil
  } else {
    %127 = subtract(%x14, 1);
    %128 = tensor_nil_float64;
    %129 = @tensor_array_float64(%127);
    Cons(%128, %129)
  }
}

def @tensor_array_int16(%x15: int32) -> List[tensor_int16_t[]] {
  %130 = equal(%x15, 0);
  if (%130) {
    Nil
  } else {
    %131 = subtract(%x15, 1);
    %132 = tensor_nil_int16;
    %133 = @tensor_array_int16(%131);
    Cons(%132, %133)
  }
}

def @tensor_array_int32(%x16: int32) -> List[tensor_int32_t[]] {
  %134 = equal(%x16, 0);
  if (%134) {
    Nil
  } else {
    %135 = subtract(%x16, 1);
    %136 = tensor_nil_int32;
    %137 = @tensor_array_int32(%135);
    Cons(%136, %137)
  }
}

def @tensor_array_int64(%x17: int32) -> List[tensor_int64_t[]] {
  %138 = equal(%x17, 0);
  if (%138) {
    Nil
  } else {
    %139 = subtract(%x17, 1);
    %140 = tensor_nil_int64;
    %141 = @tensor_array_int64(%139);
    Cons(%140, %141)
  }
}

def @tensor_array_int8(%x18: int32) -> List[tensor_int8_t[]] {
  %142 = equal(%x18, 0);
  if (%142) {
    Nil
  } else {
    %143 = subtract(%x18, 1);
    %144 = tensor_nil_int8;
    %145 = @tensor_array_int8(%143);
    Cons(%144, %145)
  }
}

def @tensor_array_read_float16(%tensor_array18: List[tensor_float16_t[]], %x19: int32) -> tensor_float16_t[] {
  @nth(%tensor_array18, %x19)
}

def @tensor_array_read_float32(%tensor_array19: List[tensor_float32_t[]], %x20: int32) -> tensor_float32_t[] {
  @nth(%tensor_array19, %x20)
}

def @tensor_array_read_float64(%tensor_array20: List[tensor_float64_t[]], %x21: int32) -> tensor_float64_t[] {
  @nth(%tensor_array20, %x21)
}

def @tensor_array_read_int16(%tensor_array21: List[tensor_int16_t[]], %x22: int32) -> tensor_int16_t[] {
  @nth(%tensor_array21, %x22)
}

def @tensor_array_read_int32(%tensor_array22: List[tensor_int32_t[]], %x23: int32) -> tensor_int32_t[] {
  @nth(%tensor_array22, %x23)
}

def @tensor_array_read_int64(%tensor_array23: List[tensor_int64_t[]], %x24: int32) -> tensor_int64_t[] {
  @nth(%tensor_array23, %x24)
}

def @tensor_array_read_int8(%tensor_array24: List[tensor_int8_t[]], %x25: int32) -> tensor_int8_t[] {
  @nth(%tensor_array24, %x25)
}

def @tensor_array_read_uint16(%tensor_array25: List[tensor_uint16_t[]], %x26: int32) -> tensor_uint16_t[] {
  @nth(%tensor_array25, %x26)
}

def @tensor_array_read_uint8(%tensor_array26: List[tensor_uint8_t[]], %x27: int32) -> tensor_uint8_t[] {
  @nth(%tensor_array26, %x27)
}

def @tensor_array_scatter_float16(%tensor_array27: List[tensor_float16_t[]], %indices: Tensor[(?), int32], %values: List[tensor_float16_t[]]) -> List[tensor_float16_t[]] {
  %146 = shape_of(%indices, dtype="int32");
  %147 = take(%146, 0);
  @tensor_array_scatter_helper_float16(%tensor_array27, 0, %147, %indices, %values)
}

def @tensor_array_scatter_float32(%tensor_array28: List[tensor_float32_t[]], %indices1: Tensor[(?), int32], %values1: List[tensor_float32_t[]]) -> List[tensor_float32_t[]] {
  %148 = shape_of(%indices1, dtype="int32");
  %149 = take(%148, 0);
  @tensor_array_scatter_helper_float32(%tensor_array28, 0, %149, %indices1, %values1)
}

def @tensor_array_scatter_float64(%tensor_array29: List[tensor_float64_t[]], %indices2: Tensor[(?), int32], %values2: List[tensor_float64_t[]]) -> List[tensor_float64_t[]] {
  %150 = shape_of(%indices2, dtype="int32");
  %151 = take(%150, 0);
  @tensor_array_scatter_helper_float64(%tensor_array29, 0, %151, %indices2, %values2)
}

def @tensor_array_scatter_helper_float16(%ta: List[tensor_float16_t[]], %current: int32, %limit: int32, %indices_: Tensor[(?), int32], %values_: List[tensor_float16_t[]]) -> List[tensor_float16_t[]] {
  %152 = equal(%current, %limit);
  if (%152) {
    %ta
  } else {
    %153 = take(%indices_, %current);
    %154 = @tensor_array_read_float16(%values_, %current);
    %155 = @tensor_array_write_float16(%ta, %153, %154);
    %156 = add(%current, 1);
    @tensor_array_scatter_helper_float16(%155, %156, %limit, %indices_, %values_)
  }
}

def @tensor_array_scatter_helper_float32(%ta1: List[tensor_float32_t[]], %current2: int32, %limit2: int32, %indices_1: Tensor[(?), int32], %values_1: List[tensor_float32_t[]]) -> List[tensor_float32_t[]] {
  %157 = equal(%current2, %limit2);
  if (%157) {
    %ta1
  } else {
    %158 = take(%indices_1, %current2);
    %159 = @tensor_array_read_float32(%values_1, %current2);
    %160 = @tensor_array_write_float32(%ta1, %158, %159);
    %161 = add(%current2, 1);
    @tensor_array_scatter_helper_float32(%160, %161, %limit2, %indices_1, %values_1)
  }
}

def @tensor_array_scatter_helper_float64(%ta2: List[tensor_float64_t[]], %current3: int32, %limit3: int32, %indices_2: Tensor[(?), int32], %values_2: List[tensor_float64_t[]]) -> List[tensor_float64_t[]] {
  %162 = equal(%current3, %limit3);
  if (%162) {
    %ta2
  } else {
    %163 = take(%indices_2, %current3);
    %164 = @tensor_array_read_float64(%values_2, %current3);
    %165 = @tensor_array_write_float64(%ta2, %163, %164);
    %166 = add(%current3, 1);
    @tensor_array_scatter_helper_float64(%165, %166, %limit3, %indices_2, %values_2)
  }
}

def @tensor_array_scatter_helper_int16(%ta3: List[tensor_int16_t[]], %current4: int32, %limit4: int32, %indices_3: Tensor[(?), int32], %values_3: List[tensor_int16_t[]]) -> List[tensor_int16_t[]] {
  %167 = equal(%current4, %limit4);
  if (%167) {
    %ta3
  } else {
    %168 = take(%indices_3, %current4);
    %169 = @tensor_array_read_int16(%values_3, %current4);
    %170 = @tensor_array_write_int16(%ta3, %168, %169);
    %171 = add(%current4, 1);
    @tensor_array_scatter_helper_int16(%170, %171, %limit4, %indices_3, %values_3)
  }
}

def @tensor_array_scatter_helper_int32(%ta4: List[tensor_int32_t[]], %current5: int32, %limit5: int32, %indices_4: Tensor[(?), int32], %values_4: List[tensor_int32_t[]]) -> List[tensor_int32_t[]] {
  %172 = equal(%current5, %limit5);
  if (%172) {
    %ta4
  } else {
    %173 = take(%indices_4, %current5);
    %174 = @tensor_array_read_int32(%values_4, %current5);
    %175 = @tensor_array_write_int32(%ta4, %173, %174);
    %176 = add(%current5, 1);
    @tensor_array_scatter_helper_int32(%175, %176, %limit5, %indices_4, %values_4)
  }
}

def @tensor_array_scatter_helper_int64(%ta5: List[tensor_int64_t[]], %current6: int32, %limit6: int32, %indices_5: Tensor[(?), int32], %values_5: List[tensor_int64_t[]]) -> List[tensor_int64_t[]] {
  %177 = equal(%current6, %limit6);
  if (%177) {
    %ta5
  } else {
    %178 = take(%indices_5, %current6);
    %179 = @tensor_array_read_int64(%values_5, %current6);
    %180 = @tensor_array_write_int64(%ta5, %178, %179);
    %181 = add(%current6, 1);
    @tensor_array_scatter_helper_int64(%180, %181, %limit6, %indices_5, %values_5)
  }
}

def @tensor_array_scatter_helper_int8(%ta6: List[tensor_int8_t[]], %current7: int32, %limit7: int32, %indices_6: Tensor[(?), int32], %values_6: List[tensor_int8_t[]]) -> List[tensor_int8_t[]] {
  %182 = equal(%current7, %limit7);
  if (%182) {
    %ta6
  } else {
    %183 = take(%indices_6, %current7);
    %184 = @tensor_array_read_int8(%values_6, %current7);
    %185 = @tensor_array_write_int8(%ta6, %183, %184);
    %186 = add(%current7, 1);
    @tensor_array_scatter_helper_int8(%185, %186, %limit7, %indices_6, %values_6)
  }
}

def @tensor_array_scatter_helper_uint16(%ta7: List[tensor_uint16_t[]], %current8: int32, %limit8: int32, %indices_7: Tensor[(?), int32], %values_7: List[tensor_uint16_t[]]) -> List[tensor_uint16_t[]] {
  %187 = equal(%current8, %limit8);
  if (%187) {
    %ta7
  } else {
    %188 = take(%indices_7, %current8);
    %189 = @tensor_array_read_uint16(%values_7, %current8);
    %190 = @tensor_array_write_uint16(%ta7, %188, %189);
    %191 = add(%current8, 1);
    @tensor_array_scatter_helper_uint16(%190, %191, %limit8, %indices_7, %values_7)
  }
}

def @tensor_array_scatter_helper_uint8(%ta8: List[tensor_uint8_t[]], %current9: int32, %limit9: int32, %indices_8: Tensor[(?), int32], %values_8: List[tensor_uint8_t[]]) -> List[tensor_uint8_t[]] {
  %192 = equal(%current9, %limit9);
  if (%192) {
    %ta8
  } else {
    %193 = take(%indices_8, %current9);
    %194 = @tensor_array_read_uint8(%values_8, %current9);
    %195 = @tensor_array_write_uint8(%ta8, %193, %194);
    %196 = add(%current9, 1);
    @tensor_array_scatter_helper_uint8(%195, %196, %limit9, %indices_8, %values_8)
  }
}

def @tensor_array_scatter_int16(%tensor_array30: List[tensor_int16_t[]], %indices3: Tensor[(?), int32], %values3: List[tensor_int16_t[]]) -> List[tensor_int16_t[]] {
  %197 = shape_of(%indices3, dtype="int32");
  %198 = take(%197, 0);
  @tensor_array_scatter_helper_int16(%tensor_array30, 0, %198, %indices3, %values3)
}

def @tensor_array_scatter_int32(%tensor_array31: List[tensor_int32_t[]], %indices4: Tensor[(?), int32], %values4: List[tensor_int32_t[]]) -> List[tensor_int32_t[]] {
  %199 = shape_of(%indices4, dtype="int32");
  %200 = take(%199, 0);
  @tensor_array_scatter_helper_int32(%tensor_array31, 0, %200, %indices4, %values4)
}

def @tensor_array_scatter_int64(%tensor_array32: List[tensor_int64_t[]], %indices5: Tensor[(?), int32], %values5: List[tensor_int64_t[]]) -> List[tensor_int64_t[]] {
  %201 = shape_of(%indices5, dtype="int32");
  %202 = take(%201, 0);
  @tensor_array_scatter_helper_int64(%tensor_array32, 0, %202, %indices5, %values5)
}

def @tensor_array_scatter_int8(%tensor_array33: List[tensor_int8_t[]], %indices6: Tensor[(?), int32], %values6: List[tensor_int8_t[]]) -> List[tensor_int8_t[]] {
  %203 = shape_of(%indices6, dtype="int32");
  %204 = take(%203, 0);
  @tensor_array_scatter_helper_int8(%tensor_array33, 0, %204, %indices6, %values6)
}

def @tensor_array_scatter_uint16(%tensor_array34: List[tensor_uint16_t[]], %indices7: Tensor[(?), int32], %values7: List[tensor_uint16_t[]]) -> List[tensor_uint16_t[]] {
  %205 = shape_of(%indices7, dtype="int32");
  %206 = take(%205, 0);
  @tensor_array_scatter_helper_uint16(%tensor_array34, 0, %206, %indices7, %values7)
}

def @tensor_array_scatter_uint8(%tensor_array35: List[tensor_uint8_t[]], %indices8: Tensor[(?), int32], %values8: List[tensor_uint8_t[]]) -> List[tensor_uint8_t[]] {
  %207 = shape_of(%indices8, dtype="int32");
  %208 = take(%207, 0);
  @tensor_array_scatter_helper_uint8(%tensor_array35, 0, %208, %indices8, %values8)
}

def @tensor_array_split_float16(%tensor_array36: List[tensor_float16_t[]], %value: tensor_float16_t[], %lengths9: Tensor[(?), int32]) -> List[tensor_float16_t[]] {
  %209 = shape_of(%lengths9, dtype="int32");
  %210 = take(%209, 0);
  @ta_split_helper_float16(%tensor_array36, %value, 0, 0, %210, %lengths9)
}

def @tensor_array_split_float32(%tensor_array37: List[tensor_float32_t[]], %value2: tensor_float32_t[], %lengths10: Tensor[(?), int32]) -> List[tensor_float32_t[]] {
  %211 = shape_of(%lengths10, dtype="int32");
  %212 = take(%211, 0);
  @ta_split_helper_float32(%tensor_array37, %value2, 0, 0, %212, %lengths10)
}

def @tensor_array_split_float64(%tensor_array38: List[tensor_float64_t[]], %value3: tensor_float64_t[], %lengths11: Tensor[(?), int32]) -> List[tensor_float64_t[]] {
  %213 = shape_of(%lengths11, dtype="int32");
  %214 = take(%213, 0);
  @ta_split_helper_float64(%tensor_array38, %value3, 0, 0, %214, %lengths11)
}

def @tensor_array_split_int16(%tensor_array39: List[tensor_int16_t[]], %value4: tensor_int16_t[], %lengths12: Tensor[(?), int32]) -> List[tensor_int16_t[]] {
  %215 = shape_of(%lengths12, dtype="int32");
  %216 = take(%215, 0);
  @ta_split_helper_int16(%tensor_array39, %value4, 0, 0, %216, %lengths12)
}

def @tensor_array_split_int32(%tensor_array40: List[tensor_int32_t[]], %value5: tensor_int32_t[], %lengths13: Tensor[(?), int32]) -> List[tensor_int32_t[]] {
  %217 = shape_of(%lengths13, dtype="int32");
  %218 = take(%217, 0);
  @ta_split_helper_int32(%tensor_array40, %value5, 0, 0, %218, %lengths13)
}

def @tensor_array_split_int64(%tensor_array41: List[tensor_int64_t[]], %value6: tensor_int64_t[], %lengths14: Tensor[(?), int32]) -> List[tensor_int64_t[]] {
  %219 = shape_of(%lengths14, dtype="int32");
  %220 = take(%219, 0);
  @ta_split_helper_int64(%tensor_array41, %value6, 0, 0, %220, %lengths14)
}

def @tensor_array_split_int8(%tensor_array42: List[tensor_int8_t[]], %value7: tensor_int8_t[], %lengths15: Tensor[(?), int32]) -> List[tensor_int8_t[]] {
  %221 = shape_of(%lengths15, dtype="int32");
  %222 = take(%221, 0);
  @ta_split_helper_int8(%tensor_array42, %value7, 0, 0, %222, %lengths15)
}

def @tensor_array_split_uint16(%tensor_array43: List[tensor_uint16_t[]], %value8: tensor_uint16_t[], %lengths16: Tensor[(?), int32]) -> List[tensor_uint16_t[]] {
  %223 = shape_of(%lengths16, dtype="int32");
  %224 = take(%223, 0);
  @ta_split_helper_uint16(%tensor_array43, %value8, 0, 0, %224, %lengths16)
}

def @tensor_array_split_uint8(%tensor_array44: List[tensor_uint8_t[]], %value9: tensor_uint8_t[], %lengths17: Tensor[(?), int32]) -> List[tensor_uint8_t[]] {
  %225 = shape_of(%lengths17, dtype="int32");
  %226 = take(%225, 0);
  @ta_split_helper_uint8(%tensor_array44, %value9, 0, 0, %226, %lengths17)
}

def @tensor_array_stack_float16(%tensor_array45: List[tensor_float16_t[]]) -> tensor_float16_t[] {
  let %x_4 = @map(@tensor_expand_dims_float16, %tensor_array45);
  let %x_5 = @hd(%x_4);
  let %x_6 = @tl(%x_4);
  let %x_7 = @foldl(@tensor_concatenate_float16, %x_5, %x_6);
  %x_7
}

def @tensor_array_stack_float32(%tensor_array46: List[tensor_float32_t[]]) -> tensor_float32_t[] {
  let %x_0 = @map(@tensor_expand_dims_float32, %tensor_array46);
  let %x_1 = @hd(%x_0);
  let %x_2 = @tl(%x_0);
  let %x_3 = @foldl(@tensor_concatenate_float32, %x_1, %x_2);
  %x_3
}

def @tensor_array_stack_float64(%tensor_array47: List[tensor_float64_t[]]) -> tensor_float64_t[] {
  let %x_8 = @map(@tensor_expand_dims_float64, %tensor_array47);
  let %x_9 = @hd(%x_8);
  let %x_10 = @tl(%x_8);
  let %x_11 = @foldl(@tensor_concatenate_float64, %x_9, %x_10);
  %x_11
}

def @tensor_array_stack_int16(%tensor_array48: List[tensor_int16_t[]]) -> tensor_int16_t[] {
  let %x_24 = @map(@tensor_expand_dims_int16, %tensor_array48);
  let %x_25 = @hd(%x_24);
  let %x_26 = @tl(%x_24);
  let %x_27 = @foldl(@tensor_concatenate_int16, %x_25, %x_26);
  %x_27
}

def @tensor_array_stack_int32(%tensor_array49: List[tensor_int32_t[]]) -> tensor_int32_t[] {
  let %x_12 = @map(@tensor_expand_dims_int32, %tensor_array49);
  let %x_13 = @hd(%x_12);
  let %x_14 = @tl(%x_12);
  let %x_15 = @foldl(@tensor_concatenate_int32, %x_13, %x_14);
  %x_15
}

def @tensor_array_stack_int64(%tensor_array50: List[tensor_int64_t[]]) -> tensor_int64_t[] {
  let %x_32 = @map(@tensor_expand_dims_int64, %tensor_array50);
  let %x_33 = @hd(%x_32);
  let %x_34 = @tl(%x_32);
  let %x_35 = @foldl(@tensor_concatenate_int64, %x_33, %x_34);
  %x_35
}

def @tensor_array_stack_int8(%tensor_array51: List[tensor_int8_t[]]) -> tensor_int8_t[] {
  let %x_20 = @map(@tensor_expand_dims_int8, %tensor_array51);
  let %x_21 = @hd(%x_20);
  let %x_22 = @tl(%x_20);
  let %x_23 = @foldl(@tensor_concatenate_int8, %x_21, %x_22);
  %x_23
}

def @tensor_array_stack_uint16(%tensor_array52: List[tensor_uint16_t[]]) -> tensor_uint16_t[] {
  let %x_28 = @map(@tensor_expand_dims_uint16, %tensor_array52);
  let %x_29 = @hd(%x_28);
  let %x_30 = @tl(%x_28);
  let %x_31 = @foldl(@tensor_concatenate_uint16, %x_29, %x_30);
  %x_31
}

def @tensor_array_stack_uint8(%tensor_array53: List[tensor_uint8_t[]]) -> tensor_uint8_t[] {
  let %x_16 = @map(@tensor_expand_dims_uint8, %tensor_array53);
  let %x_17 = @hd(%x_16);
  let %x_18 = @tl(%x_16);
  let %x_19 = @foldl(@tensor_concatenate_uint8, %x_17, %x_18);
  %x_19
}

def @tensor_array_uint16(%x28: int32) -> List[tensor_uint16_t[]] {
  %227 = equal(%x28, 0);
  if (%227) {
    Nil
  } else {
    %228 = subtract(%x28, 1);
    %229 = tensor_nil_uint16;
    %230 = @tensor_array_uint16(%228);
    Cons(%229, %230)
  }
}

def @tensor_array_uint8(%x29: int32) -> List[tensor_uint8_t[]] {
  %231 = equal(%x29, 0);
  if (%231) {
    Nil
  } else {
    %232 = subtract(%x29, 1);
    %233 = tensor_nil_uint8;
    %234 = @tensor_array_uint8(%232);
    Cons(%233, %234)
  }
}

def @tensor_array_unstack_tensor1_float16(%tensor: Tensor[(?), float16]) -> List[tensor_float16_t[]] {
  %235 = shape_of(%tensor, dtype="int32");
  %236 = take(%235, 0);
  @tensor_array_unstack_tensor1_helper_float16(0, %236, %tensor)
}

def @tensor_array_unstack_tensor1_float32(%tensor1: Tensor[(?), float32]) -> List[tensor_float32_t[]] {
  %237 = shape_of(%tensor1, dtype="int32");
  %238 = take(%237, 0);
  @tensor_array_unstack_tensor1_helper_float32(0, %238, %tensor1)
}

def @tensor_array_unstack_tensor1_float64(%tensor2: Tensor[(?), float64]) -> List[tensor_float64_t[]] {
  %239 = shape_of(%tensor2, dtype="int32");
  %240 = take(%239, 0);
  @tensor_array_unstack_tensor1_helper_float64(0, %240, %tensor2)
}

def @tensor_array_unstack_tensor1_helper_float16(%i: int32, %up: int32, %t2: Tensor[(?), float16]) -> List[tensor_float16_t[]] {
  %241 = equal(%i, %up);
  if (%241) {
    Nil
  } else {
    %242 = take(%t2, %i);
    %243 = add(%i, 1);
    %244 = tensor0_float16(%242);
    %245 = @tensor_array_unstack_tensor1_helper_float16(%243, %up, %t2);
    Cons(%244, %245)
  }
}

def @tensor_array_unstack_tensor1_helper_float32(%i1: int32, %up1: int32, %t3: Tensor[(?), float32]) -> List[tensor_float32_t[]] {
  %246 = equal(%i1, %up1);
  if (%246) {
    Nil
  } else {
    %247 = take(%t3, %i1);
    %248 = add(%i1, 1);
    %249 = tensor0_float32(%247);
    %250 = @tensor_array_unstack_tensor1_helper_float32(%248, %up1, %t3);
    Cons(%249, %250)
  }
}

def @tensor_array_unstack_tensor1_helper_float64(%i2: int32, %up2: int32, %t4: Tensor[(?), float64]) -> List[tensor_float64_t[]] {
  %251 = equal(%i2, %up2);
  if (%251) {
    Nil
  } else {
    %252 = take(%t4, %i2);
    %253 = add(%i2, 1);
    %254 = tensor0_float64(%252);
    %255 = @tensor_array_unstack_tensor1_helper_float64(%253, %up2, %t4);
    Cons(%254, %255)
  }
}

def @tensor_array_unstack_tensor1_helper_int16(%i3: int32, %up3: int32, %t5: Tensor[(?), int16]) -> List[tensor_int16_t[]] {
  %256 = equal(%i3, %up3);
  if (%256) {
    Nil
  } else {
    %257 = take(%t5, %i3);
    %258 = add(%i3, 1);
    %259 = tensor0_int16(%257);
    %260 = @tensor_array_unstack_tensor1_helper_int16(%258, %up3, %t5);
    Cons(%259, %260)
  }
}

def @tensor_array_unstack_tensor1_helper_int32(%i4: int32, %up4: int32, %t6: Tensor[(?), int32]) -> List[tensor_int32_t[]] {
  %261 = equal(%i4, %up4);
  if (%261) {
    Nil
  } else {
    %262 = take(%t6, %i4);
    %263 = add(%i4, 1);
    %264 = tensor0_int32(%262);
    %265 = @tensor_array_unstack_tensor1_helper_int32(%263, %up4, %t6);
    Cons(%264, %265)
  }
}

def @tensor_array_unstack_tensor1_helper_int64(%i5: int32, %up5: int32, %t7: Tensor[(?), int64]) -> List[tensor_int64_t[]] {
  %266 = equal(%i5, %up5);
  if (%266) {
    Nil
  } else {
    %267 = take(%t7, %i5);
    %268 = add(%i5, 1);
    %269 = tensor0_int64(%267);
    %270 = @tensor_array_unstack_tensor1_helper_int64(%268, %up5, %t7);
    Cons(%269, %270)
  }
}

def @tensor_array_unstack_tensor1_helper_int8(%i6: int32, %up6: int32, %t8: Tensor[(?), int8]) -> List[tensor_int8_t[]] {
  %271 = equal(%i6, %up6);
  if (%271) {
    Nil
  } else {
    %272 = take(%t8, %i6);
    %273 = add(%i6, 1);
    %274 = tensor0_int8(%272);
    %275 = @tensor_array_unstack_tensor1_helper_int8(%273, %up6, %t8);
    Cons(%274, %275)
  }
}

def @tensor_array_unstack_tensor1_helper_uint16(%i7: int32, %up7: int32, %t9: Tensor[(?), uint16]) -> List[tensor_uint16_t[]] {
  %276 = equal(%i7, %up7);
  if (%276) {
    Nil
  } else {
    %277 = take(%t9, %i7);
    %278 = add(%i7, 1);
    %279 = tensor0_uint16(%277);
    %280 = @tensor_array_unstack_tensor1_helper_uint16(%278, %up7, %t9);
    Cons(%279, %280)
  }
}

def @tensor_array_unstack_tensor1_helper_uint8(%i8: int32, %up8: int32, %t10: Tensor[(?), uint8]) -> List[tensor_uint8_t[]] {
  %281 = equal(%i8, %up8);
  if (%281) {
    Nil
  } else {
    %282 = take(%t10, %i8);
    %283 = add(%i8, 1);
    %284 = tensor0_uint8(%282);
    %285 = @tensor_array_unstack_tensor1_helper_uint8(%283, %up8, %t10);
    Cons(%284, %285)
  }
}

def @tensor_array_unstack_tensor1_int16(%tensor3: Tensor[(?), int16]) -> List[tensor_int16_t[]] {
  %286 = shape_of(%tensor3, dtype="int32");
  %287 = take(%286, 0);
  @tensor_array_unstack_tensor1_helper_int16(0, %287, %tensor3)
}

def @tensor_array_unstack_tensor1_int32(%tensor4: Tensor[(?), int32]) -> List[tensor_int32_t[]] {
  %288 = shape_of(%tensor4, dtype="int32");
  %289 = take(%288, 0);
  @tensor_array_unstack_tensor1_helper_int32(0, %289, %tensor4)
}

def @tensor_array_unstack_tensor1_int64(%tensor5: Tensor[(?), int64]) -> List[tensor_int64_t[]] {
  %290 = shape_of(%tensor5, dtype="int32");
  %291 = take(%290, 0);
  @tensor_array_unstack_tensor1_helper_int64(0, %291, %tensor5)
}

def @tensor_array_unstack_tensor1_int8(%tensor6: Tensor[(?), int8]) -> List[tensor_int8_t[]] {
  %292 = shape_of(%tensor6, dtype="int32");
  %293 = take(%292, 0);
  @tensor_array_unstack_tensor1_helper_int8(0, %293, %tensor6)
}

def @tensor_array_unstack_tensor1_uint16(%tensor7: Tensor[(?), uint16]) -> List[tensor_uint16_t[]] {
  %294 = shape_of(%tensor7, dtype="int32");
  %295 = take(%294, 0);
  @tensor_array_unstack_tensor1_helper_uint16(0, %295, %tensor7)
}

def @tensor_array_unstack_tensor1_uint8(%tensor8: Tensor[(?), uint8]) -> List[tensor_uint8_t[]] {
  %296 = shape_of(%tensor8, dtype="int32");
  %297 = take(%296, 0);
  @tensor_array_unstack_tensor1_helper_uint8(0, %297, %tensor8)
}

def @tensor_array_unstack_tensor2_float16(%tensor9: Tensor[(?, ?), float16]) -> List[tensor_float16_t[]] {
  %298 = shape_of(%tensor9, dtype="int32");
  %299 = take(%298, 0);
  @tensor_array_unstack_tensor2_helper_float16(0, %299, %tensor9)
}

def @tensor_array_unstack_tensor2_float32(%tensor10: Tensor[(?, ?), float32]) -> List[tensor_float32_t[]] {
  %300 = shape_of(%tensor10, dtype="int32");
  %301 = take(%300, 0);
  @tensor_array_unstack_tensor2_helper_float32(0, %301, %tensor10)
}

def @tensor_array_unstack_tensor2_float64(%tensor11: Tensor[(?, ?), float64]) -> List[tensor_float64_t[]] {
  %302 = shape_of(%tensor11, dtype="int32");
  %303 = take(%302, 0);
  @tensor_array_unstack_tensor2_helper_float64(0, %303, %tensor11)
}

def @tensor_array_unstack_tensor2_helper_float16(%i9: int32, %up9: int32, %t11: Tensor[(?, ?), float16]) -> List[tensor_float16_t[]] {
  %304 = equal(%i9, %up9);
  if (%304) {
    Nil
  } else {
    %305 = take(%t11, %i9, axis=0);
    %306 = add(%i9, 1);
    %307 = tensor1_float16(%305);
    %308 = @tensor_array_unstack_tensor2_helper_float16(%306, %up9, %t11);
    Cons(%307, %308)
  }
}

def @tensor_array_unstack_tensor2_helper_float32(%i10: int32, %up10: int32, %t12: Tensor[(?, ?), float32]) -> List[tensor_float32_t[]] {
  %309 = equal(%i10, %up10);
  if (%309) {
    Nil
  } else {
    %310 = take(%t12, %i10, axis=0);
    %311 = add(%i10, 1);
    %312 = tensor1_float32(%310);
    %313 = @tensor_array_unstack_tensor2_helper_float32(%311, %up10, %t12);
    Cons(%312, %313)
  }
}

def @tensor_array_unstack_tensor2_helper_float64(%i11: int32, %up11: int32, %t13: Tensor[(?, ?), float64]) -> List[tensor_float64_t[]] {
  %314 = equal(%i11, %up11);
  if (%314) {
    Nil
  } else {
    %315 = take(%t13, %i11, axis=0);
    %316 = add(%i11, 1);
    %317 = tensor1_float64(%315);
    %318 = @tensor_array_unstack_tensor2_helper_float64(%316, %up11, %t13);
    Cons(%317, %318)
  }
}

def @tensor_array_unstack_tensor2_helper_int16(%i12: int32, %up12: int32, %t14: Tensor[(?, ?), int16]) -> List[tensor_int16_t[]] {
  %319 = equal(%i12, %up12);
  if (%319) {
    Nil
  } else {
    %320 = take(%t14, %i12, axis=0);
    %321 = add(%i12, 1);
    %322 = tensor1_int16(%320);
    %323 = @tensor_array_unstack_tensor2_helper_int16(%321, %up12, %t14);
    Cons(%322, %323)
  }
}

def @tensor_array_unstack_tensor2_helper_int32(%i13: int32, %up13: int32, %t15: Tensor[(?, ?), int32]) -> List[tensor_int32_t[]] {
  %324 = equal(%i13, %up13);
  if (%324) {
    Nil
  } else {
    %325 = take(%t15, %i13, axis=0);
    %326 = add(%i13, 1);
    %327 = tensor1_int32(%325);
    %328 = @tensor_array_unstack_tensor2_helper_int32(%326, %up13, %t15);
    Cons(%327, %328)
  }
}

def @tensor_array_unstack_tensor2_helper_int64(%i14: int32, %up14: int32, %t16: Tensor[(?, ?), int64]) -> List[tensor_int64_t[]] {
  %329 = equal(%i14, %up14);
  if (%329) {
    Nil
  } else {
    %330 = take(%t16, %i14, axis=0);
    %331 = add(%i14, 1);
    %332 = tensor1_int64(%330);
    %333 = @tensor_array_unstack_tensor2_helper_int64(%331, %up14, %t16);
    Cons(%332, %333)
  }
}

def @tensor_array_unstack_tensor2_helper_int8(%i15: int32, %up15: int32, %t17: Tensor[(?, ?), int8]) -> List[tensor_int8_t[]] {
  %334 = equal(%i15, %up15);
  if (%334) {
    Nil
  } else {
    %335 = take(%t17, %i15, axis=0);
    %336 = add(%i15, 1);
    %337 = tensor1_int8(%335);
    %338 = @tensor_array_unstack_tensor2_helper_int8(%336, %up15, %t17);
    Cons(%337, %338)
  }
}

def @tensor_array_unstack_tensor2_helper_uint16(%i16: int32, %up16: int32, %t18: Tensor[(?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %339 = equal(%i16, %up16);
  if (%339) {
    Nil
  } else {
    %340 = take(%t18, %i16, axis=0);
    %341 = add(%i16, 1);
    %342 = tensor1_uint16(%340);
    %343 = @tensor_array_unstack_tensor2_helper_uint16(%341, %up16, %t18);
    Cons(%342, %343)
  }
}

def @tensor_array_unstack_tensor2_helper_uint8(%i17: int32, %up17: int32, %t19: Tensor[(?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %344 = equal(%i17, %up17);
  if (%344) {
    Nil
  } else {
    %345 = take(%t19, %i17, axis=0);
    %346 = add(%i17, 1);
    %347 = tensor1_uint8(%345);
    %348 = @tensor_array_unstack_tensor2_helper_uint8(%346, %up17, %t19);
    Cons(%347, %348)
  }
}

def @tensor_array_unstack_tensor2_int16(%tensor12: Tensor[(?, ?), int16]) -> List[tensor_int16_t[]] {
  %349 = shape_of(%tensor12, dtype="int32");
  %350 = take(%349, 0);
  @tensor_array_unstack_tensor2_helper_int16(0, %350, %tensor12)
}

def @tensor_array_unstack_tensor2_int32(%tensor13: Tensor[(?, ?), int32]) -> List[tensor_int32_t[]] {
  %351 = shape_of(%tensor13, dtype="int32");
  %352 = take(%351, 0);
  @tensor_array_unstack_tensor2_helper_int32(0, %352, %tensor13)
}

def @tensor_array_unstack_tensor2_int64(%tensor14: Tensor[(?, ?), int64]) -> List[tensor_int64_t[]] {
  %353 = shape_of(%tensor14, dtype="int32");
  %354 = take(%353, 0);
  @tensor_array_unstack_tensor2_helper_int64(0, %354, %tensor14)
}

def @tensor_array_unstack_tensor2_int8(%tensor15: Tensor[(?, ?), int8]) -> List[tensor_int8_t[]] {
  %355 = shape_of(%tensor15, dtype="int32");
  %356 = take(%355, 0);
  @tensor_array_unstack_tensor2_helper_int8(0, %356, %tensor15)
}

def @tensor_array_unstack_tensor2_uint16(%tensor16: Tensor[(?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %357 = shape_of(%tensor16, dtype="int32");
  %358 = take(%357, 0);
  @tensor_array_unstack_tensor2_helper_uint16(0, %358, %tensor16)
}

def @tensor_array_unstack_tensor2_uint8(%tensor17: Tensor[(?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %359 = shape_of(%tensor17, dtype="int32");
  %360 = take(%359, 0);
  @tensor_array_unstack_tensor2_helper_uint8(0, %360, %tensor17)
}

def @tensor_array_unstack_tensor3_float16(%tensor18: Tensor[(?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %361 = shape_of(%tensor18, dtype="int32");
  %362 = take(%361, 0);
  @tensor_array_unstack_tensor3_helper_float16(0, %362, %tensor18)
}

def @tensor_array_unstack_tensor3_float32(%tensor19: Tensor[(?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %363 = shape_of(%tensor19, dtype="int32");
  %364 = take(%363, 0);
  @tensor_array_unstack_tensor3_helper_float32(0, %364, %tensor19)
}

def @tensor_array_unstack_tensor3_float64(%tensor20: Tensor[(?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %365 = shape_of(%tensor20, dtype="int32");
  %366 = take(%365, 0);
  @tensor_array_unstack_tensor3_helper_float64(0, %366, %tensor20)
}

def @tensor_array_unstack_tensor3_helper_float16(%i18: int32, %up18: int32, %t20: Tensor[(?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %367 = equal(%i18, %up18);
  if (%367) {
    Nil
  } else {
    %368 = take(%t20, %i18, axis=0);
    %369 = add(%i18, 1);
    %370 = tensor2_float16(%368);
    %371 = @tensor_array_unstack_tensor3_helper_float16(%369, %up18, %t20);
    Cons(%370, %371)
  }
}

def @tensor_array_unstack_tensor3_helper_float32(%i19: int32, %up19: int32, %t21: Tensor[(?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %372 = equal(%i19, %up19);
  if (%372) {
    Nil
  } else {
    %373 = take(%t21, %i19, axis=0);
    %374 = add(%i19, 1);
    %375 = tensor2_float32(%373);
    %376 = @tensor_array_unstack_tensor3_helper_float32(%374, %up19, %t21);
    Cons(%375, %376)
  }
}

def @tensor_array_unstack_tensor3_helper_float64(%i20: int32, %up20: int32, %t22: Tensor[(?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %377 = equal(%i20, %up20);
  if (%377) {
    Nil
  } else {
    %378 = take(%t22, %i20, axis=0);
    %379 = add(%i20, 1);
    %380 = tensor2_float64(%378);
    %381 = @tensor_array_unstack_tensor3_helper_float64(%379, %up20, %t22);
    Cons(%380, %381)
  }
}

def @tensor_array_unstack_tensor3_helper_int16(%i21: int32, %up21: int32, %t23: Tensor[(?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %382 = equal(%i21, %up21);
  if (%382) {
    Nil
  } else {
    %383 = take(%t23, %i21, axis=0);
    %384 = add(%i21, 1);
    %385 = tensor2_int16(%383);
    %386 = @tensor_array_unstack_tensor3_helper_int16(%384, %up21, %t23);
    Cons(%385, %386)
  }
}

def @tensor_array_unstack_tensor3_helper_int32(%i22: int32, %up22: int32, %t24: Tensor[(?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %387 = equal(%i22, %up22);
  if (%387) {
    Nil
  } else {
    %388 = take(%t24, %i22, axis=0);
    %389 = add(%i22, 1);
    %390 = tensor2_int32(%388);
    %391 = @tensor_array_unstack_tensor3_helper_int32(%389, %up22, %t24);
    Cons(%390, %391)
  }
}

def @tensor_array_unstack_tensor3_helper_int64(%i23: int32, %up23: int32, %t25: Tensor[(?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %392 = equal(%i23, %up23);
  if (%392) {
    Nil
  } else {
    %393 = take(%t25, %i23, axis=0);
    %394 = add(%i23, 1);
    %395 = tensor2_int64(%393);
    %396 = @tensor_array_unstack_tensor3_helper_int64(%394, %up23, %t25);
    Cons(%395, %396)
  }
}

def @tensor_array_unstack_tensor3_helper_int8(%i24: int32, %up24: int32, %t26: Tensor[(?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %397 = equal(%i24, %up24);
  if (%397) {
    Nil
  } else {
    %398 = take(%t26, %i24, axis=0);
    %399 = add(%i24, 1);
    %400 = tensor2_int8(%398);
    %401 = @tensor_array_unstack_tensor3_helper_int8(%399, %up24, %t26);
    Cons(%400, %401)
  }
}

def @tensor_array_unstack_tensor3_helper_uint16(%i25: int32, %up25: int32, %t27: Tensor[(?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %402 = equal(%i25, %up25);
  if (%402) {
    Nil
  } else {
    %403 = take(%t27, %i25, axis=0);
    %404 = add(%i25, 1);
    %405 = tensor2_uint16(%403);
    %406 = @tensor_array_unstack_tensor3_helper_uint16(%404, %up25, %t27);
    Cons(%405, %406)
  }
}

def @tensor_array_unstack_tensor3_helper_uint8(%i26: int32, %up26: int32, %t28: Tensor[(?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %407 = equal(%i26, %up26);
  if (%407) {
    Nil
  } else {
    %408 = take(%t28, %i26, axis=0);
    %409 = add(%i26, 1);
    %410 = tensor2_uint8(%408);
    %411 = @tensor_array_unstack_tensor3_helper_uint8(%409, %up26, %t28);
    Cons(%410, %411)
  }
}

def @tensor_array_unstack_tensor3_int16(%tensor21: Tensor[(?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %412 = shape_of(%tensor21, dtype="int32");
  %413 = take(%412, 0);
  @tensor_array_unstack_tensor3_helper_int16(0, %413, %tensor21)
}

def @tensor_array_unstack_tensor3_int32(%tensor22: Tensor[(?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %414 = shape_of(%tensor22, dtype="int32");
  %415 = take(%414, 0);
  @tensor_array_unstack_tensor3_helper_int32(0, %415, %tensor22)
}

def @tensor_array_unstack_tensor3_int64(%tensor23: Tensor[(?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %416 = shape_of(%tensor23, dtype="int32");
  %417 = take(%416, 0);
  @tensor_array_unstack_tensor3_helper_int64(0, %417, %tensor23)
}

def @tensor_array_unstack_tensor3_int8(%tensor24: Tensor[(?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %418 = shape_of(%tensor24, dtype="int32");
  %419 = take(%418, 0);
  @tensor_array_unstack_tensor3_helper_int8(0, %419, %tensor24)
}

def @tensor_array_unstack_tensor3_uint16(%tensor25: Tensor[(?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %420 = shape_of(%tensor25, dtype="int32");
  %421 = take(%420, 0);
  @tensor_array_unstack_tensor3_helper_uint16(0, %421, %tensor25)
}

def @tensor_array_unstack_tensor3_uint8(%tensor26: Tensor[(?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %422 = shape_of(%tensor26, dtype="int32");
  %423 = take(%422, 0);
  @tensor_array_unstack_tensor3_helper_uint8(0, %423, %tensor26)
}

def @tensor_array_unstack_tensor4_float16(%tensor27: Tensor[(?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %424 = shape_of(%tensor27, dtype="int32");
  %425 = take(%424, 0);
  @tensor_array_unstack_tensor4_helper_float16(0, %425, %tensor27)
}

def @tensor_array_unstack_tensor4_float32(%tensor28: Tensor[(?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %426 = shape_of(%tensor28, dtype="int32");
  %427 = take(%426, 0);
  @tensor_array_unstack_tensor4_helper_float32(0, %427, %tensor28)
}

def @tensor_array_unstack_tensor4_float64(%tensor29: Tensor[(?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %428 = shape_of(%tensor29, dtype="int32");
  %429 = take(%428, 0);
  @tensor_array_unstack_tensor4_helper_float64(0, %429, %tensor29)
}

def @tensor_array_unstack_tensor4_helper_float16(%i27: int32, %up27: int32, %t29: Tensor[(?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %430 = equal(%i27, %up27);
  if (%430) {
    Nil
  } else {
    %431 = take(%t29, %i27, axis=0);
    %432 = add(%i27, 1);
    %433 = tensor3_float16(%431);
    %434 = @tensor_array_unstack_tensor4_helper_float16(%432, %up27, %t29);
    Cons(%433, %434)
  }
}

def @tensor_array_unstack_tensor4_helper_float32(%i28: int32, %up28: int32, %t30: Tensor[(?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %435 = equal(%i28, %up28);
  if (%435) {
    Nil
  } else {
    %436 = take(%t30, %i28, axis=0);
    %437 = add(%i28, 1);
    %438 = tensor3_float32(%436);
    %439 = @tensor_array_unstack_tensor4_helper_float32(%437, %up28, %t30);
    Cons(%438, %439)
  }
}

def @tensor_array_unstack_tensor4_helper_float64(%i29: int32, %up29: int32, %t31: Tensor[(?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %440 = equal(%i29, %up29);
  if (%440) {
    Nil
  } else {
    %441 = take(%t31, %i29, axis=0);
    %442 = add(%i29, 1);
    %443 = tensor3_float64(%441);
    %444 = @tensor_array_unstack_tensor4_helper_float64(%442, %up29, %t31);
    Cons(%443, %444)
  }
}

def @tensor_array_unstack_tensor4_helper_int16(%i30: int32, %up30: int32, %t32: Tensor[(?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %445 = equal(%i30, %up30);
  if (%445) {
    Nil
  } else {
    %446 = take(%t32, %i30, axis=0);
    %447 = add(%i30, 1);
    %448 = tensor3_int16(%446);
    %449 = @tensor_array_unstack_tensor4_helper_int16(%447, %up30, %t32);
    Cons(%448, %449)
  }
}

def @tensor_array_unstack_tensor4_helper_int32(%i31: int32, %up31: int32, %t33: Tensor[(?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %450 = equal(%i31, %up31);
  if (%450) {
    Nil
  } else {
    %451 = take(%t33, %i31, axis=0);
    %452 = add(%i31, 1);
    %453 = tensor3_int32(%451);
    %454 = @tensor_array_unstack_tensor4_helper_int32(%452, %up31, %t33);
    Cons(%453, %454)
  }
}

def @tensor_array_unstack_tensor4_helper_int64(%i32: int32, %up32: int32, %t34: Tensor[(?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %455 = equal(%i32, %up32);
  if (%455) {
    Nil
  } else {
    %456 = take(%t34, %i32, axis=0);
    %457 = add(%i32, 1);
    %458 = tensor3_int64(%456);
    %459 = @tensor_array_unstack_tensor4_helper_int64(%457, %up32, %t34);
    Cons(%458, %459)
  }
}

def @tensor_array_unstack_tensor4_helper_int8(%i33: int32, %up33: int32, %t35: Tensor[(?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %460 = equal(%i33, %up33);
  if (%460) {
    Nil
  } else {
    %461 = take(%t35, %i33, axis=0);
    %462 = add(%i33, 1);
    %463 = tensor3_int8(%461);
    %464 = @tensor_array_unstack_tensor4_helper_int8(%462, %up33, %t35);
    Cons(%463, %464)
  }
}

def @tensor_array_unstack_tensor4_helper_uint16(%i34: int32, %up34: int32, %t36: Tensor[(?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %465 = equal(%i34, %up34);
  if (%465) {
    Nil
  } else {
    %466 = take(%t36, %i34, axis=0);
    %467 = add(%i34, 1);
    %468 = tensor3_uint16(%466);
    %469 = @tensor_array_unstack_tensor4_helper_uint16(%467, %up34, %t36);
    Cons(%468, %469)
  }
}

def @tensor_array_unstack_tensor4_helper_uint8(%i35: int32, %up35: int32, %t37: Tensor[(?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %470 = equal(%i35, %up35);
  if (%470) {
    Nil
  } else {
    %471 = take(%t37, %i35, axis=0);
    %472 = add(%i35, 1);
    %473 = tensor3_uint8(%471);
    %474 = @tensor_array_unstack_tensor4_helper_uint8(%472, %up35, %t37);
    Cons(%473, %474)
  }
}

def @tensor_array_unstack_tensor4_int16(%tensor30: Tensor[(?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %475 = shape_of(%tensor30, dtype="int32");
  %476 = take(%475, 0);
  @tensor_array_unstack_tensor4_helper_int16(0, %476, %tensor30)
}

def @tensor_array_unstack_tensor4_int32(%tensor31: Tensor[(?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %477 = shape_of(%tensor31, dtype="int32");
  %478 = take(%477, 0);
  @tensor_array_unstack_tensor4_helper_int32(0, %478, %tensor31)
}

def @tensor_array_unstack_tensor4_int64(%tensor32: Tensor[(?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %479 = shape_of(%tensor32, dtype="int32");
  %480 = take(%479, 0);
  @tensor_array_unstack_tensor4_helper_int64(0, %480, %tensor32)
}

def @tensor_array_unstack_tensor4_int8(%tensor33: Tensor[(?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %481 = shape_of(%tensor33, dtype="int32");
  %482 = take(%481, 0);
  @tensor_array_unstack_tensor4_helper_int8(0, %482, %tensor33)
}

def @tensor_array_unstack_tensor4_uint16(%tensor34: Tensor[(?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %483 = shape_of(%tensor34, dtype="int32");
  %484 = take(%483, 0);
  @tensor_array_unstack_tensor4_helper_uint16(0, %484, %tensor34)
}

def @tensor_array_unstack_tensor4_uint8(%tensor35: Tensor[(?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %485 = shape_of(%tensor35, dtype="int32");
  %486 = take(%485, 0);
  @tensor_array_unstack_tensor4_helper_uint8(0, %486, %tensor35)
}

def @tensor_array_unstack_tensor5_float16(%tensor36: Tensor[(?, ?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %487 = shape_of(%tensor36, dtype="int32");
  %488 = take(%487, 0);
  @tensor_array_unstack_tensor5_helper_float16(0, %488, %tensor36)
}

def @tensor_array_unstack_tensor5_float32(%tensor37: Tensor[(?, ?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %489 = shape_of(%tensor37, dtype="int32");
  %490 = take(%489, 0);
  @tensor_array_unstack_tensor5_helper_float32(0, %490, %tensor37)
}

def @tensor_array_unstack_tensor5_float64(%tensor38: Tensor[(?, ?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %491 = shape_of(%tensor38, dtype="int32");
  %492 = take(%491, 0);
  @tensor_array_unstack_tensor5_helper_float64(0, %492, %tensor38)
}

def @tensor_array_unstack_tensor5_helper_float16(%i36: int32, %up36: int32, %t38: Tensor[(?, ?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %493 = equal(%i36, %up36);
  if (%493) {
    Nil
  } else {
    %494 = take(%t38, %i36, axis=0);
    %495 = add(%i36, 1);
    %496 = tensor4_float16(%494);
    %497 = @tensor_array_unstack_tensor5_helper_float16(%495, %up36, %t38);
    Cons(%496, %497)
  }
}

def @tensor_array_unstack_tensor5_helper_float32(%i37: int32, %up37: int32, %t39: Tensor[(?, ?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %498 = equal(%i37, %up37);
  if (%498) {
    Nil
  } else {
    %499 = take(%t39, %i37, axis=0);
    %500 = add(%i37, 1);
    %501 = tensor4_float32(%499);
    %502 = @tensor_array_unstack_tensor5_helper_float32(%500, %up37, %t39);
    Cons(%501, %502)
  }
}

def @tensor_array_unstack_tensor5_helper_float64(%i38: int32, %up38: int32, %t40: Tensor[(?, ?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %503 = equal(%i38, %up38);
  if (%503) {
    Nil
  } else {
    %504 = take(%t40, %i38, axis=0);
    %505 = add(%i38, 1);
    %506 = tensor4_float64(%504);
    %507 = @tensor_array_unstack_tensor5_helper_float64(%505, %up38, %t40);
    Cons(%506, %507)
  }
}

def @tensor_array_unstack_tensor5_helper_int16(%i39: int32, %up39: int32, %t41: Tensor[(?, ?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %508 = equal(%i39, %up39);
  if (%508) {
    Nil
  } else {
    %509 = take(%t41, %i39, axis=0);
    %510 = add(%i39, 1);
    %511 = tensor4_int16(%509);
    %512 = @tensor_array_unstack_tensor5_helper_int16(%510, %up39, %t41);
    Cons(%511, %512)
  }
}

def @tensor_array_unstack_tensor5_helper_int32(%i40: int32, %up40: int32, %t42: Tensor[(?, ?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %513 = equal(%i40, %up40);
  if (%513) {
    Nil
  } else {
    %514 = take(%t42, %i40, axis=0);
    %515 = add(%i40, 1);
    %516 = tensor4_int32(%514);
    %517 = @tensor_array_unstack_tensor5_helper_int32(%515, %up40, %t42);
    Cons(%516, %517)
  }
}

def @tensor_array_unstack_tensor5_helper_int64(%i41: int32, %up41: int32, %t43: Tensor[(?, ?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %518 = equal(%i41, %up41);
  if (%518) {
    Nil
  } else {
    %519 = take(%t43, %i41, axis=0);
    %520 = add(%i41, 1);
    %521 = tensor4_int64(%519);
    %522 = @tensor_array_unstack_tensor5_helper_int64(%520, %up41, %t43);
    Cons(%521, %522)
  }
}

def @tensor_array_unstack_tensor5_helper_int8(%i42: int32, %up42: int32, %t44: Tensor[(?, ?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %523 = equal(%i42, %up42);
  if (%523) {
    Nil
  } else {
    %524 = take(%t44, %i42, axis=0);
    %525 = add(%i42, 1);
    %526 = tensor4_int8(%524);
    %527 = @tensor_array_unstack_tensor5_helper_int8(%525, %up42, %t44);
    Cons(%526, %527)
  }
}

def @tensor_array_unstack_tensor5_helper_uint16(%i43: int32, %up43: int32, %t45: Tensor[(?, ?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %528 = equal(%i43, %up43);
  if (%528) {
    Nil
  } else {
    %529 = take(%t45, %i43, axis=0);
    %530 = add(%i43, 1);
    %531 = tensor4_uint16(%529);
    %532 = @tensor_array_unstack_tensor5_helper_uint16(%530, %up43, %t45);
    Cons(%531, %532)
  }
}

def @tensor_array_unstack_tensor5_helper_uint8(%i44: int32, %up44: int32, %t46: Tensor[(?, ?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %533 = equal(%i44, %up44);
  if (%533) {
    Nil
  } else {
    %534 = take(%t46, %i44, axis=0);
    %535 = add(%i44, 1);
    %536 = tensor4_uint8(%534);
    %537 = @tensor_array_unstack_tensor5_helper_uint8(%535, %up44, %t46);
    Cons(%536, %537)
  }
}

def @tensor_array_unstack_tensor5_int16(%tensor39: Tensor[(?, ?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %538 = shape_of(%tensor39, dtype="int32");
  %539 = take(%538, 0);
  @tensor_array_unstack_tensor5_helper_int16(0, %539, %tensor39)
}

def @tensor_array_unstack_tensor5_int32(%tensor40: Tensor[(?, ?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %540 = shape_of(%tensor40, dtype="int32");
  %541 = take(%540, 0);
  @tensor_array_unstack_tensor5_helper_int32(0, %541, %tensor40)
}

def @tensor_array_unstack_tensor5_int64(%tensor41: Tensor[(?, ?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %542 = shape_of(%tensor41, dtype="int32");
  %543 = take(%542, 0);
  @tensor_array_unstack_tensor5_helper_int64(0, %543, %tensor41)
}

def @tensor_array_unstack_tensor5_int8(%tensor42: Tensor[(?, ?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %544 = shape_of(%tensor42, dtype="int32");
  %545 = take(%544, 0);
  @tensor_array_unstack_tensor5_helper_int8(0, %545, %tensor42)
}

def @tensor_array_unstack_tensor5_uint16(%tensor43: Tensor[(?, ?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %546 = shape_of(%tensor43, dtype="int32");
  %547 = take(%546, 0);
  @tensor_array_unstack_tensor5_helper_uint16(0, %547, %tensor43)
}

def @tensor_array_unstack_tensor5_uint8(%tensor44: Tensor[(?, ?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %548 = shape_of(%tensor44, dtype="int32");
  %549 = take(%548, 0);
  @tensor_array_unstack_tensor5_helper_uint8(0, %549, %tensor44)
}

def @tensor_array_unstack_tensor6_float16(%tensor45: Tensor[(?, ?, ?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %550 = shape_of(%tensor45, dtype="int32");
  %551 = take(%550, 0);
  @tensor_array_unstack_tensor6_helper_float16(0, %551, %tensor45)
}

def @tensor_array_unstack_tensor6_float32(%tensor46: Tensor[(?, ?, ?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %552 = shape_of(%tensor46, dtype="int32");
  %553 = take(%552, 0);
  @tensor_array_unstack_tensor6_helper_float32(0, %553, %tensor46)
}

def @tensor_array_unstack_tensor6_float64(%tensor47: Tensor[(?, ?, ?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %554 = shape_of(%tensor47, dtype="int32");
  %555 = take(%554, 0);
  @tensor_array_unstack_tensor6_helper_float64(0, %555, %tensor47)
}

def @tensor_array_unstack_tensor6_helper_float16(%i45: int32, %up45: int32, %t47: Tensor[(?, ?, ?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %556 = equal(%i45, %up45);
  if (%556) {
    Nil
  } else {
    %557 = take(%t47, %i45, axis=0);
    %558 = add(%i45, 1);
    %559 = tensor5_float16(%557);
    %560 = @tensor_array_unstack_tensor6_helper_float16(%558, %up45, %t47);
    Cons(%559, %560)
  }
}

def @tensor_array_unstack_tensor6_helper_float32(%i46: int32, %up46: int32, %t48: Tensor[(?, ?, ?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %561 = equal(%i46, %up46);
  if (%561) {
    Nil
  } else {
    %562 = take(%t48, %i46, axis=0);
    %563 = add(%i46, 1);
    %564 = tensor5_float32(%562);
    %565 = @tensor_array_unstack_tensor6_helper_float32(%563, %up46, %t48);
    Cons(%564, %565)
  }
}

def @tensor_array_unstack_tensor6_helper_float64(%i47: int32, %up47: int32, %t49: Tensor[(?, ?, ?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %566 = equal(%i47, %up47);
  if (%566) {
    Nil
  } else {
    %567 = take(%t49, %i47, axis=0);
    %568 = add(%i47, 1);
    %569 = tensor5_float64(%567);
    %570 = @tensor_array_unstack_tensor6_helper_float64(%568, %up47, %t49);
    Cons(%569, %570)
  }
}

def @tensor_array_unstack_tensor6_helper_int16(%i48: int32, %up48: int32, %t50: Tensor[(?, ?, ?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %571 = equal(%i48, %up48);
  if (%571) {
    Nil
  } else {
    %572 = take(%t50, %i48, axis=0);
    %573 = add(%i48, 1);
    %574 = tensor5_int16(%572);
    %575 = @tensor_array_unstack_tensor6_helper_int16(%573, %up48, %t50);
    Cons(%574, %575)
  }
}

def @tensor_array_unstack_tensor6_helper_int32(%i49: int32, %up49: int32, %t51: Tensor[(?, ?, ?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %576 = equal(%i49, %up49);
  if (%576) {
    Nil
  } else {
    %577 = take(%t51, %i49, axis=0);
    %578 = add(%i49, 1);
    %579 = tensor5_int32(%577);
    %580 = @tensor_array_unstack_tensor6_helper_int32(%578, %up49, %t51);
    Cons(%579, %580)
  }
}

def @tensor_array_unstack_tensor6_helper_int64(%i50: int32, %up50: int32, %t52: Tensor[(?, ?, ?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %581 = equal(%i50, %up50);
  if (%581) {
    Nil
  } else {
    %582 = take(%t52, %i50, axis=0);
    %583 = add(%i50, 1);
    %584 = tensor5_int64(%582);
    %585 = @tensor_array_unstack_tensor6_helper_int64(%583, %up50, %t52);
    Cons(%584, %585)
  }
}

def @tensor_array_unstack_tensor6_helper_int8(%i51: int32, %up51: int32, %t53: Tensor[(?, ?, ?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %586 = equal(%i51, %up51);
  if (%586) {
    Nil
  } else {
    %587 = take(%t53, %i51, axis=0);
    %588 = add(%i51, 1);
    %589 = tensor5_int8(%587);
    %590 = @tensor_array_unstack_tensor6_helper_int8(%588, %up51, %t53);
    Cons(%589, %590)
  }
}

def @tensor_array_unstack_tensor6_helper_uint16(%i52: int32, %up52: int32, %t54: Tensor[(?, ?, ?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %591 = equal(%i52, %up52);
  if (%591) {
    Nil
  } else {
    %592 = take(%t54, %i52, axis=0);
    %593 = add(%i52, 1);
    %594 = tensor5_uint16(%592);
    %595 = @tensor_array_unstack_tensor6_helper_uint16(%593, %up52, %t54);
    Cons(%594, %595)
  }
}

def @tensor_array_unstack_tensor6_helper_uint8(%i53: int32, %up53: int32, %t55: Tensor[(?, ?, ?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %596 = equal(%i53, %up53);
  if (%596) {
    Nil
  } else {
    %597 = take(%t55, %i53, axis=0);
    %598 = add(%i53, 1);
    %599 = tensor5_uint8(%597);
    %600 = @tensor_array_unstack_tensor6_helper_uint8(%598, %up53, %t55);
    Cons(%599, %600)
  }
}

def @tensor_array_unstack_tensor6_int16(%tensor48: Tensor[(?, ?, ?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %601 = shape_of(%tensor48, dtype="int32");
  %602 = take(%601, 0);
  @tensor_array_unstack_tensor6_helper_int16(0, %602, %tensor48)
}

def @tensor_array_unstack_tensor6_int32(%tensor49: Tensor[(?, ?, ?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %603 = shape_of(%tensor49, dtype="int32");
  %604 = take(%603, 0);
  @tensor_array_unstack_tensor6_helper_int32(0, %604, %tensor49)
}

def @tensor_array_unstack_tensor6_int64(%tensor50: Tensor[(?, ?, ?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %605 = shape_of(%tensor50, dtype="int32");
  %606 = take(%605, 0);
  @tensor_array_unstack_tensor6_helper_int64(0, %606, %tensor50)
}

def @tensor_array_unstack_tensor6_int8(%tensor51: Tensor[(?, ?, ?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %607 = shape_of(%tensor51, dtype="int32");
  %608 = take(%607, 0);
  @tensor_array_unstack_tensor6_helper_int8(0, %608, %tensor51)
}

def @tensor_array_unstack_tensor6_uint16(%tensor52: Tensor[(?, ?, ?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %609 = shape_of(%tensor52, dtype="int32");
  %610 = take(%609, 0);
  @tensor_array_unstack_tensor6_helper_uint16(0, %610, %tensor52)
}

def @tensor_array_unstack_tensor6_uint8(%tensor53: Tensor[(?, ?, ?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %611 = shape_of(%tensor53, dtype="int32");
  %612 = take(%611, 0);
  @tensor_array_unstack_tensor6_helper_uint8(0, %612, %tensor53)
}

def @tensor_array_write_float16(%tensor_array54: List[tensor_float16_t[]], %x30: int32, %v1: tensor_float16_t[]) -> List[tensor_float16_t[]] {
  @update(%tensor_array54, %x30, %v1)
}

def @tensor_array_write_float32(%tensor_array55: List[tensor_float32_t[]], %x31: int32, %v2: tensor_float32_t[]) -> List[tensor_float32_t[]] {
  @update(%tensor_array55, %x31, %v2)
}

def @tensor_array_write_float64(%tensor_array56: List[tensor_float64_t[]], %x32: int32, %v3: tensor_float64_t[]) -> List[tensor_float64_t[]] {
  @update(%tensor_array56, %x32, %v3)
}

def @tensor_array_write_int16(%tensor_array57: List[tensor_int16_t[]], %x33: int32, %v4: tensor_int16_t[]) -> List[tensor_int16_t[]] {
  @update(%tensor_array57, %x33, %v4)
}

def @tensor_array_write_int32(%tensor_array58: List[tensor_int32_t[]], %x34: int32, %v5: tensor_int32_t[]) -> List[tensor_int32_t[]] {
  @update(%tensor_array58, %x34, %v5)
}

def @tensor_array_write_int64(%tensor_array59: List[tensor_int64_t[]], %x35: int32, %v6: tensor_int64_t[]) -> List[tensor_int64_t[]] {
  @update(%tensor_array59, %x35, %v6)
}

def @tensor_array_write_int8(%tensor_array60: List[tensor_int8_t[]], %x36: int32, %v7: tensor_int8_t[]) -> List[tensor_int8_t[]] {
  @update(%tensor_array60, %x36, %v7)
}

def @tensor_array_write_uint16(%tensor_array61: List[tensor_uint16_t[]], %x37: int32, %v8: tensor_uint16_t[]) -> List[tensor_uint16_t[]] {
  @update(%tensor_array61, %x37, %v8)
}

def @tensor_array_write_uint8(%tensor_array62: List[tensor_uint8_t[]], %x38: int32, %v9: tensor_uint8_t[]) -> List[tensor_uint8_t[]] {
  @update(%tensor_array62, %x38, %v9)
}

def @tensor_concatenate_float16(%x39: tensor_float16_t[], %y1: tensor_float16_t[]) -> tensor_float16_t[] {
  match? (%x39) {
    tensor1_float16(%t111) => {
      match? (%y1) {
        tensor1_float16(%t121) => {
          %613 = (%t111, %t121);
          %614 = concatenate(%613);
          tensor1_float16(%614)
        },
      }
    },
    tensor2_float16(%t211) => {
      match? (%y1) {
        tensor2_float16(%t221) => {
          %615 = (%t211, %t221);
          %616 = concatenate(%615);
          tensor2_float16(%616)
        },
      }
    },
    tensor3_float16(%t311) => {
      match? (%y1) {
        tensor3_float16(%t321) => {
          %617 = (%t311, %t321);
          %618 = concatenate(%617);
          tensor3_float16(%618)
        },
      }
    },
    tensor4_float16(%t411) => {
      match? (%y1) {
        tensor4_float16(%t421) => {
          %619 = (%t411, %t421);
          %620 = concatenate(%619);
          tensor4_float16(%620)
        },
      }
    },
  }
}

def @tensor_concatenate_float32(%x40: tensor_float32_t[], %y2: tensor_float32_t[]) -> tensor_float32_t[] {
  match? (%x40) {
    tensor1_float32(%t112) => {
      match? (%y2) {
        tensor1_float32(%t122) => {
          %621 = (%t112, %t122);
          %622 = concatenate(%621);
          tensor1_float32(%622)
        },
      }
    },
    tensor2_float32(%t212) => {
      match? (%y2) {
        tensor2_float32(%t222) => {
          %623 = (%t212, %t222);
          %624 = concatenate(%623);
          tensor2_float32(%624)
        },
      }
    },
    tensor3_float32(%t312) => {
      match? (%y2) {
        tensor3_float32(%t322) => {
          %625 = (%t312, %t322);
          %626 = concatenate(%625);
          tensor3_float32(%626)
        },
      }
    },
    tensor4_float32(%t412) => {
      match? (%y2) {
        tensor4_float32(%t422) => {
          %627 = (%t412, %t422);
          %628 = concatenate(%627);
          tensor4_float32(%628)
        },
      }
    },
  }
}

def @tensor_concatenate_float64(%x41: tensor_float64_t[], %y3: tensor_float64_t[]) -> tensor_float64_t[] {
  match? (%x41) {
    tensor1_float64(%t113) => {
      match? (%y3) {
        tensor1_float64(%t123) => {
          %629 = (%t113, %t123);
          %630 = concatenate(%629);
          tensor1_float64(%630)
        },
      }
    },
    tensor2_float64(%t213) => {
      match? (%y3) {
        tensor2_float64(%t223) => {
          %631 = (%t213, %t223);
          %632 = concatenate(%631);
          tensor2_float64(%632)
        },
      }
    },
    tensor3_float64(%t313) => {
      match? (%y3) {
        tensor3_float64(%t323) => {
          %633 = (%t313, %t323);
          %634 = concatenate(%633);
          tensor3_float64(%634)
        },
      }
    },
    tensor4_float64(%t413) => {
      match? (%y3) {
        tensor4_float64(%t423) => {
          %635 = (%t413, %t423);
          %636 = concatenate(%635);
          tensor4_float64(%636)
        },
      }
    },
  }
}

def @tensor_concatenate_int16(%x42: tensor_int16_t[], %y4: tensor_int16_t[]) -> tensor_int16_t[] {
  match? (%x42) {
    tensor1_int16(%t114) => {
      match? (%y4) {
        tensor1_int16(%t124) => {
          %637 = (%t114, %t124);
          %638 = concatenate(%637);
          tensor1_int16(%638)
        },
      }
    },
    tensor2_int16(%t214) => {
      match? (%y4) {
        tensor2_int16(%t224) => {
          %639 = (%t214, %t224);
          %640 = concatenate(%639);
          tensor2_int16(%640)
        },
      }
    },
    tensor3_int16(%t314) => {
      match? (%y4) {
        tensor3_int16(%t324) => {
          %641 = (%t314, %t324);
          %642 = concatenate(%641);
          tensor3_int16(%642)
        },
      }
    },
    tensor4_int16(%t414) => {
      match? (%y4) {
        tensor4_int16(%t424) => {
          %643 = (%t414, %t424);
          %644 = concatenate(%643);
          tensor4_int16(%644)
        },
      }
    },
  }
}

def @tensor_concatenate_int32(%x43: tensor_int32_t[], %y5: tensor_int32_t[]) -> tensor_int32_t[] {
  match? (%x43) {
    tensor1_int32(%t115) => {
      match? (%y5) {
        tensor1_int32(%t125) => {
          %645 = (%t115, %t125);
          %646 = concatenate(%645);
          tensor1_int32(%646)
        },
      }
    },
    tensor2_int32(%t215) => {
      match? (%y5) {
        tensor2_int32(%t225) => {
          %647 = (%t215, %t225);
          %648 = concatenate(%647);
          tensor2_int32(%648)
        },
      }
    },
    tensor3_int32(%t315) => {
      match? (%y5) {
        tensor3_int32(%t325) => {
          %649 = (%t315, %t325);
          %650 = concatenate(%649);
          tensor3_int32(%650)
        },
      }
    },
    tensor4_int32(%t415) => {
      match? (%y5) {
        tensor4_int32(%t425) => {
          %651 = (%t415, %t425);
          %652 = concatenate(%651);
          tensor4_int32(%652)
        },
      }
    },
  }
}

def @tensor_concatenate_int64(%x44: tensor_int64_t[], %y6: tensor_int64_t[]) -> tensor_int64_t[] {
  match? (%x44) {
    tensor1_int64(%t116) => {
      match? (%y6) {
        tensor1_int64(%t126) => {
          %653 = (%t116, %t126);
          %654 = concatenate(%653);
          tensor1_int64(%654)
        },
      }
    },
    tensor2_int64(%t216) => {
      match? (%y6) {
        tensor2_int64(%t226) => {
          %655 = (%t216, %t226);
          %656 = concatenate(%655);
          tensor2_int64(%656)
        },
      }
    },
    tensor3_int64(%t316) => {
      match? (%y6) {
        tensor3_int64(%t326) => {
          %657 = (%t316, %t326);
          %658 = concatenate(%657);
          tensor3_int64(%658)
        },
      }
    },
    tensor4_int64(%t416) => {
      match? (%y6) {
        tensor4_int64(%t426) => {
          %659 = (%t416, %t426);
          %660 = concatenate(%659);
          tensor4_int64(%660)
        },
      }
    },
  }
}

def @tensor_concatenate_int8(%x45: tensor_int8_t[], %y7: tensor_int8_t[]) -> tensor_int8_t[] {
  match? (%x45) {
    tensor1_int8(%t117) => {
      match? (%y7) {
        tensor1_int8(%t127) => {
          %661 = (%t117, %t127);
          %662 = concatenate(%661);
          tensor1_int8(%662)
        },
      }
    },
    tensor2_int8(%t217) => {
      match? (%y7) {
        tensor2_int8(%t227) => {
          %663 = (%t217, %t227);
          %664 = concatenate(%663);
          tensor2_int8(%664)
        },
      }
    },
    tensor3_int8(%t317) => {
      match? (%y7) {
        tensor3_int8(%t327) => {
          %665 = (%t317, %t327);
          %666 = concatenate(%665);
          tensor3_int8(%666)
        },
      }
    },
    tensor4_int8(%t417) => {
      match? (%y7) {
        tensor4_int8(%t427) => {
          %667 = (%t417, %t427);
          %668 = concatenate(%667);
          tensor4_int8(%668)
        },
      }
    },
  }
}

def @tensor_concatenate_uint16(%x46: tensor_uint16_t[], %y8: tensor_uint16_t[]) -> tensor_uint16_t[] {
  match? (%x46) {
    tensor1_uint16(%t118) => {
      match? (%y8) {
        tensor1_uint16(%t128) => {
          %669 = (%t118, %t128);
          %670 = concatenate(%669);
          tensor1_uint16(%670)
        },
      }
    },
    tensor2_uint16(%t218) => {
      match? (%y8) {
        tensor2_uint16(%t228) => {
          %671 = (%t218, %t228);
          %672 = concatenate(%671);
          tensor2_uint16(%672)
        },
      }
    },
    tensor3_uint16(%t318) => {
      match? (%y8) {
        tensor3_uint16(%t328) => {
          %673 = (%t318, %t328);
          %674 = concatenate(%673);
          tensor3_uint16(%674)
        },
      }
    },
    tensor4_uint16(%t418) => {
      match? (%y8) {
        tensor4_uint16(%t428) => {
          %675 = (%t418, %t428);
          %676 = concatenate(%675);
          tensor4_uint16(%676)
        },
      }
    },
  }
}

def @tensor_concatenate_uint8(%x47: tensor_uint8_t[], %y9: tensor_uint8_t[]) -> tensor_uint8_t[] {
  match? (%x47) {
    tensor1_uint8(%t119) => {
      match? (%y9) {
        tensor1_uint8(%t129) => {
          %677 = (%t119, %t129);
          %678 = concatenate(%677);
          tensor1_uint8(%678)
        },
      }
    },
    tensor2_uint8(%t219) => {
      match? (%y9) {
        tensor2_uint8(%t229) => {
          %679 = (%t219, %t229);
          %680 = concatenate(%679);
          tensor2_uint8(%680)
        },
      }
    },
    tensor3_uint8(%t319) => {
      match? (%y9) {
        tensor3_uint8(%t329) => {
          %681 = (%t319, %t329);
          %682 = concatenate(%681);
          tensor3_uint8(%682)
        },
      }
    },
    tensor4_uint8(%t419) => {
      match? (%y9) {
        tensor4_uint8(%t429) => {
          %683 = (%t419, %t429);
          %684 = concatenate(%683);
          tensor4_uint8(%684)
        },
      }
    },
  }
}

def @tensor_expand_dims_float16(%x48: tensor_float16_t[]) -> tensor_float16_t[] {
  match? (%x48) {
    tensor0_float16(%t0) => {
      %685 = expand_dims(%t0, axis=0);
      tensor1_float16(%685)
    },
    tensor1_float16(%t110) => {
      %686 = expand_dims(%t110, axis=0);
      tensor2_float16(%686)
    },
    tensor2_float16(%t210) => {
      %687 = expand_dims(%t210, axis=0);
      tensor3_float16(%687)
    },
    tensor3_float16(%t310) => {
      %688 = expand_dims(%t310, axis=0);
      tensor4_float16(%688)
    },
    tensor4_float16(%t410) => {
      %689 = expand_dims(%t410, axis=0);
      tensor5_float16(%689)
    },
    tensor5_float16(%t56) => {
      %690 = expand_dims(%t56, axis=0);
      tensor6_float16(%690)
    },
  }
}

def @tensor_expand_dims_float32(%x49: tensor_float32_t[]) -> tensor_float32_t[] {
  match? (%x49) {
    tensor0_float32(%t01) => {
      %691 = expand_dims(%t01, axis=0);
      tensor1_float32(%691)
    },
    tensor1_float32(%t120) => {
      %692 = expand_dims(%t120, axis=0);
      tensor2_float32(%692)
    },
    tensor2_float32(%t220) => {
      %693 = expand_dims(%t220, axis=0);
      tensor3_float32(%693)
    },
    tensor3_float32(%t320) => {
      %694 = expand_dims(%t320, axis=0);
      tensor4_float32(%694)
    },
    tensor4_float32(%t420) => {
      %695 = expand_dims(%t420, axis=0);
      tensor5_float32(%695)
    },
    tensor5_float32(%t57) => {
      %696 = expand_dims(%t57, axis=0);
      tensor6_float32(%696)
    },
  }
}

def @tensor_expand_dims_float64(%x50: tensor_float64_t[]) -> tensor_float64_t[] {
  match? (%x50) {
    tensor0_float64(%t02) => {
      %697 = expand_dims(%t02, axis=0);
      tensor1_float64(%697)
    },
    tensor1_float64(%t130) => {
      %698 = expand_dims(%t130, axis=0);
      tensor2_float64(%698)
    },
    tensor2_float64(%t230) => {
      %699 = expand_dims(%t230, axis=0);
      tensor3_float64(%699)
    },
    tensor3_float64(%t330) => {
      %700 = expand_dims(%t330, axis=0);
      tensor4_float64(%700)
    },
    tensor4_float64(%t430) => {
      %701 = expand_dims(%t430, axis=0);
      tensor5_float64(%701)
    },
    tensor5_float64(%t58) => {
      %702 = expand_dims(%t58, axis=0);
      tensor6_float64(%702)
    },
  }
}

def @tensor_expand_dims_int16(%x51: tensor_int16_t[]) -> tensor_int16_t[] {
  match? (%x51) {
    tensor0_int16(%t03) => {
      %703 = expand_dims(%t03, axis=0);
      tensor1_int16(%703)
    },
    tensor1_int16(%t131) => {
      %704 = expand_dims(%t131, axis=0);
      tensor2_int16(%704)
    },
    tensor2_int16(%t231) => {
      %705 = expand_dims(%t231, axis=0);
      tensor3_int16(%705)
    },
    tensor3_int16(%t331) => {
      %706 = expand_dims(%t331, axis=0);
      tensor4_int16(%706)
    },
    tensor4_int16(%t431) => {
      %707 = expand_dims(%t431, axis=0);
      tensor5_int16(%707)
    },
    tensor5_int16(%t59) => {
      %708 = expand_dims(%t59, axis=0);
      tensor6_int16(%708)
    },
  }
}

def @tensor_expand_dims_int32(%x52: tensor_int32_t[]) -> tensor_int32_t[] {
  match? (%x52) {
    tensor0_int32(%t04) => {
      %709 = expand_dims(%t04, axis=0);
      tensor1_int32(%709)
    },
    tensor1_int32(%t132) => {
      %710 = expand_dims(%t132, axis=0);
      tensor2_int32(%710)
    },
    tensor2_int32(%t232) => {
      %711 = expand_dims(%t232, axis=0);
      tensor3_int32(%711)
    },
    tensor3_int32(%t332) => {
      %712 = expand_dims(%t332, axis=0);
      tensor4_int32(%712)
    },
    tensor4_int32(%t432) => {
      %713 = expand_dims(%t432, axis=0);
      tensor5_int32(%713)
    },
    tensor5_int32(%t510) => {
      %714 = expand_dims(%t510, axis=0);
      tensor6_int32(%714)
    },
  }
}

def @tensor_expand_dims_int64(%x53: tensor_int64_t[]) -> tensor_int64_t[] {
  match? (%x53) {
    tensor0_int64(%t05) => {
      %715 = expand_dims(%t05, axis=0);
      tensor1_int64(%715)
    },
    tensor1_int64(%t133) => {
      %716 = expand_dims(%t133, axis=0);
      tensor2_int64(%716)
    },
    tensor2_int64(%t233) => {
      %717 = expand_dims(%t233, axis=0);
      tensor3_int64(%717)
    },
    tensor3_int64(%t333) => {
      %718 = expand_dims(%t333, axis=0);
      tensor4_int64(%718)
    },
    tensor4_int64(%t433) => {
      %719 = expand_dims(%t433, axis=0);
      tensor5_int64(%719)
    },
    tensor5_int64(%t511) => {
      %720 = expand_dims(%t511, axis=0);
      tensor6_int64(%720)
    },
  }
}

def @tensor_expand_dims_int8(%x54: tensor_int8_t[]) -> tensor_int8_t[] {
  match? (%x54) {
    tensor0_int8(%t06) => {
      %721 = expand_dims(%t06, axis=0);
      tensor1_int8(%721)
    },
    tensor1_int8(%t134) => {
      %722 = expand_dims(%t134, axis=0);
      tensor2_int8(%722)
    },
    tensor2_int8(%t234) => {
      %723 = expand_dims(%t234, axis=0);
      tensor3_int8(%723)
    },
    tensor3_int8(%t334) => {
      %724 = expand_dims(%t334, axis=0);
      tensor4_int8(%724)
    },
    tensor4_int8(%t434) => {
      %725 = expand_dims(%t434, axis=0);
      tensor5_int8(%725)
    },
    tensor5_int8(%t512) => {
      %726 = expand_dims(%t512, axis=0);
      tensor6_int8(%726)
    },
  }
}

def @tensor_expand_dims_uint16(%x55: tensor_uint16_t[]) -> tensor_uint16_t[] {
  match? (%x55) {
    tensor0_uint16(%t07) => {
      %727 = expand_dims(%t07, axis=0);
      tensor1_uint16(%727)
    },
    tensor1_uint16(%t135) => {
      %728 = expand_dims(%t135, axis=0);
      tensor2_uint16(%728)
    },
    tensor2_uint16(%t235) => {
      %729 = expand_dims(%t235, axis=0);
      tensor3_uint16(%729)
    },
    tensor3_uint16(%t335) => {
      %730 = expand_dims(%t335, axis=0);
      tensor4_uint16(%730)
    },
    tensor4_uint16(%t435) => {
      %731 = expand_dims(%t435, axis=0);
      tensor5_uint16(%731)
    },
    tensor5_uint16(%t513) => {
      %732 = expand_dims(%t513, axis=0);
      tensor6_uint16(%732)
    },
  }
}

def @tensor_expand_dims_uint8(%x56: tensor_uint8_t[]) -> tensor_uint8_t[] {
  match? (%x56) {
    tensor0_uint8(%t08) => {
      %733 = expand_dims(%t08, axis=0);
      tensor1_uint8(%733)
    },
    tensor1_uint8(%t136) => {
      %734 = expand_dims(%t136, axis=0);
      tensor2_uint8(%734)
    },
    tensor2_uint8(%t236) => {
      %735 = expand_dims(%t236, axis=0);
      tensor3_uint8(%735)
    },
    tensor3_uint8(%t336) => {
      %736 = expand_dims(%t336, axis=0);
      tensor4_uint8(%736)
    },
    tensor4_uint8(%t436) => {
      %737 = expand_dims(%t436, axis=0);
      tensor5_uint8(%737)
    },
    tensor5_uint8(%t514) => {
      %738 = expand_dims(%t514, axis=0);
      tensor6_uint8(%738)
    },
  }
}

def @tensor_take_float16(%tensor54: tensor_float16_t[], %lower: int32, %upper: int32) -> tensor_float16_t[] {
  match? (%tensor54) {
    tensor1_float16(%t137) => {
      %739 = arange(%lower, %upper, 1, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][0], dtype="int32");
      %740 = take(%t137, %739);
      tensor1_float16(%740)
    },
    tensor2_float16(%t237) => {
      %741 = arange(%lower, %upper, 1, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][1], dtype="int32");
      %742 = take(%t237, %741, axis=0);
      tensor2_float16(%742)
    },
    tensor3_float16(%t337) => {
      %743 = arange(%lower, %upper, 1, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][2], dtype="int32");
      %744 = take(%t337, %743, axis=0);
      tensor3_float16(%744)
    },
    tensor4_float16(%t437) => {
      %745 = arange(%lower, %upper, 1, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][3], dtype="int32");
      %746 = take(%t437, %745, axis=0);
      tensor4_float16(%746)
    },
    tensor5_float16(%t515) => {
      %747 = arange(%lower, %upper, 1, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][4], dtype="int32");
      %748 = take(%t515, %747, axis=0);
      tensor5_float16(%748)
    },
    tensor6_float16(%t61) => {
      %749 = arange(%lower, %upper, 1, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][5], dtype="int32");
      %750 = take(%t61, %749, axis=0);
      tensor6_float16(%750)
    },
  }
}

def @tensor_take_float32(%tensor55: tensor_float32_t[], %lower1: int32, %upper1: int32) -> tensor_float32_t[] {
  match? (%tensor55) {
    tensor1_float32(%t138) => {
      %751 = arange(%lower1, %upper1, 1, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][6], dtype="int32");
      %752 = take(%t138, %751);
      tensor1_float32(%752)
    },
    tensor2_float32(%t238) => {
      %753 = arange(%lower1, %upper1, 1, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][7], dtype="int32");
      %754 = take(%t238, %753, axis=0);
      tensor2_float32(%754)
    },
    tensor3_float32(%t338) => {
      %755 = arange(%lower1, %upper1, 1, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][8], dtype="int32");
      %756 = take(%t338, %755, axis=0);
      tensor3_float32(%756)
    },
    tensor4_float32(%t438) => {
      %757 = arange(%lower1, %upper1, 1, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][9], dtype="int32");
      %758 = take(%t438, %757, axis=0);
      tensor4_float32(%758)
    },
    tensor5_float32(%t516) => {
      %759 = arange(%lower1, %upper1, 1, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][10], dtype="int32");
      %760 = take(%t516, %759, axis=0);
      tensor5_float32(%760)
    },
    tensor6_float32(%t62) => {
      %761 = arange(%lower1, %upper1, 1, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][11], dtype="int32");
      %762 = take(%t62, %761, axis=0);
      tensor6_float32(%762)
    },
  }
}

def @tensor_take_float64(%tensor56: tensor_float64_t[], %lower2: int32, %upper2: int32) -> tensor_float64_t[] {
  match? (%tensor56) {
    tensor1_float64(%t139) => {
      %763 = arange(%lower2, %upper2, 1, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][12], dtype="int32");
      %764 = take(%t139, %763);
      tensor1_float64(%764)
    },
    tensor2_float64(%t239) => {
      %765 = arange(%lower2, %upper2, 1, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][13], dtype="int32");
      %766 = take(%t239, %765, axis=0);
      tensor2_float64(%766)
    },
    tensor3_float64(%t339) => {
      %767 = arange(%lower2, %upper2, 1, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][14], dtype="int32");
      %768 = take(%t339, %767, axis=0);
      tensor3_float64(%768)
    },
    tensor4_float64(%t439) => {
      %769 = arange(%lower2, %upper2, 1, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][15], dtype="int32");
      %770 = take(%t439, %769, axis=0);
      tensor4_float64(%770)
    },
    tensor5_float64(%t517) => {
      %771 = arange(%lower2, %upper2, 1, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][16], dtype="int32");
      %772 = take(%t517, %771, axis=0);
      tensor5_float64(%772)
    },
    tensor6_float64(%t63) => {
      %773 = arange(%lower2, %upper2, 1, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][17], dtype="int32");
      %774 = take(%t63, %773, axis=0);
      tensor6_float64(%774)
    },
  }
}

def @tensor_take_int16(%tensor57: tensor_int16_t[], %lower3: int32, %upper3: int32) -> tensor_int16_t[] {
  match? (%tensor57) {
    tensor1_int16(%t140) => {
      %775 = arange(%lower3, %upper3, 1, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][18], dtype="int32");
      %776 = take(%t140, %775);
      tensor1_int16(%776)
    },
    tensor2_int16(%t240) => {
      %777 = arange(%lower3, %upper3, 1, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][19], dtype="int32");
      %778 = take(%t240, %777, axis=0);
      tensor2_int16(%778)
    },
    tensor3_int16(%t340) => {
      %779 = arange(%lower3, %upper3, 1, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][20], dtype="int32");
      %780 = take(%t340, %779, axis=0);
      tensor3_int16(%780)
    },
    tensor4_int16(%t440) => {
      %781 = arange(%lower3, %upper3, 1, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][21], dtype="int32");
      %782 = take(%t440, %781, axis=0);
      tensor4_int16(%782)
    },
    tensor5_int16(%t518) => {
      %783 = arange(%lower3, %upper3, 1, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][22], dtype="int32");
      %784 = take(%t518, %783, axis=0);
      tensor5_int16(%784)
    },
    tensor6_int16(%t64) => {
      %785 = arange(%lower3, %upper3, 1, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][23], dtype="int32");
      %786 = take(%t64, %785, axis=0);
      tensor6_int16(%786)
    },
  }
}

def @tensor_take_int32(%tensor58: tensor_int32_t[], %lower4: int32, %upper4: int32) -> tensor_int32_t[] {
  match? (%tensor58) {
    tensor1_int32(%t141) => {
      %787 = arange(%lower4, %upper4, 1, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][24], dtype="int32");
      %788 = take(%t141, %787);
      tensor1_int32(%788)
    },
    tensor2_int32(%t241) => {
      %789 = arange(%lower4, %upper4, 1, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][25], dtype="int32");
      %790 = take(%t241, %789, axis=0);
      tensor2_int32(%790)
    },
    tensor3_int32(%t341) => {
      %791 = arange(%lower4, %upper4, 1, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][26], dtype="int32");
      %792 = take(%t341, %791, axis=0);
      tensor3_int32(%792)
    },
    tensor4_int32(%t441) => {
      %793 = arange(%lower4, %upper4, 1, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][27], dtype="int32");
      %794 = take(%t441, %793, axis=0);
      tensor4_int32(%794)
    },
    tensor5_int32(%t519) => {
      %795 = arange(%lower4, %upper4, 1, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][28], dtype="int32");
      %796 = take(%t519, %795, axis=0);
      tensor5_int32(%796)
    },
    tensor6_int32(%t65) => {
      %797 = arange(%lower4, %upper4, 1, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][29], dtype="int32");
      %798 = take(%t65, %797, axis=0);
      tensor6_int32(%798)
    },
  }
}

def @tensor_take_int64(%tensor59: tensor_int64_t[], %lower5: int32, %upper5: int32) -> tensor_int64_t[] {
  match? (%tensor59) {
    tensor1_int64(%t142) => {
      %799 = arange(%lower5, %upper5, 1, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][30], dtype="int32");
      %800 = take(%t142, %799);
      tensor1_int64(%800)
    },
    tensor2_int64(%t242) => {
      %801 = arange(%lower5, %upper5, 1, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][31], dtype="int32");
      %802 = take(%t242, %801, axis=0);
      tensor2_int64(%802)
    },
    tensor3_int64(%t342) => {
      %803 = arange(%lower5, %upper5, 1, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][32], dtype="int32");
      %804 = take(%t342, %803, axis=0);
      tensor3_int64(%804)
    },
    tensor4_int64(%t442) => {
      %805 = arange(%lower5, %upper5, 1, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][33], dtype="int32");
      %806 = take(%t442, %805, axis=0);
      tensor4_int64(%806)
    },
    tensor5_int64(%t520) => {
      %807 = arange(%lower5, %upper5, 1, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][34], dtype="int32");
      %808 = take(%t520, %807, axis=0);
      tensor5_int64(%808)
    },
    tensor6_int64(%t66) => {
      %809 = arange(%lower5, %upper5, 1, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][35], dtype="int32");
      %810 = take(%t66, %809, axis=0);
      tensor6_int64(%810)
    },
  }
}

def @tensor_take_int8(%tensor60: tensor_int8_t[], %lower6: int32, %upper6: int32) -> tensor_int8_t[] {
  match? (%tensor60) {
    tensor1_int8(%t143) => {
      %811 = arange(%lower6, %upper6, 1, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][36], dtype="int32");
      %812 = take(%t143, %811);
      tensor1_int8(%812)
    },
    tensor2_int8(%t243) => {
      %813 = arange(%lower6, %upper6, 1, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][37], dtype="int32");
      %814 = take(%t243, %813, axis=0);
      tensor2_int8(%814)
    },
    tensor3_int8(%t343) => {
      %815 = arange(%lower6, %upper6, 1, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][38], dtype="int32");
      %816 = take(%t343, %815, axis=0);
      tensor3_int8(%816)
    },
    tensor4_int8(%t443) => {
      %817 = arange(%lower6, %upper6, 1, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][39], dtype="int32");
      %818 = take(%t443, %817, axis=0);
      tensor4_int8(%818)
    },
    tensor5_int8(%t521) => {
      %819 = arange(%lower6, %upper6, 1, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][40], dtype="int32");
      %820 = take(%t521, %819, axis=0);
      tensor5_int8(%820)
    },
    tensor6_int8(%t67) => {
      %821 = arange(%lower6, %upper6, 1, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][41], dtype="int32");
      %822 = take(%t67, %821, axis=0);
      tensor6_int8(%822)
    },
  }
}

def @tensor_take_uint16(%tensor61: tensor_uint16_t[], %lower7: int32, %upper7: int32) -> tensor_uint16_t[] {
  match? (%tensor61) {
    tensor1_uint16(%t144) => {
      %823 = arange(%lower7, %upper7, 1, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][42], dtype="int32");
      %824 = take(%t144, %823);
      tensor1_uint16(%824)
    },
    tensor2_uint16(%t244) => {
      %825 = arange(%lower7, %upper7, 1, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][43], dtype="int32");
      %826 = take(%t244, %825, axis=0);
      tensor2_uint16(%826)
    },
    tensor3_uint16(%t344) => {
      %827 = arange(%lower7, %upper7, 1, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][44], dtype="int32");
      %828 = take(%t344, %827, axis=0);
      tensor3_uint16(%828)
    },
    tensor4_uint16(%t444) => {
      %829 = arange(%lower7, %upper7, 1, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][45], dtype="int32");
      %830 = take(%t444, %829, axis=0);
      tensor4_uint16(%830)
    },
    tensor5_uint16(%t522) => {
      %831 = arange(%lower7, %upper7, 1, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][46], dtype="int32");
      %832 = take(%t522, %831, axis=0);
      tensor5_uint16(%832)
    },
    tensor6_uint16(%t68) => {
      %833 = arange(%lower7, %upper7, 1, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][47], dtype="int32");
      %834 = take(%t68, %833, axis=0);
      tensor6_uint16(%834)
    },
  }
}

def @tensor_take_uint8(%tensor62: tensor_uint8_t[], %lower8: int32, %upper8: int32) -> tensor_uint8_t[] {
  match? (%tensor62) {
    tensor1_uint8(%t145) => {
      %835 = arange(%lower8, %upper8, 1, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][48], dtype="int32");
      %836 = take(%t145, %835);
      tensor1_uint8(%836)
    },
    tensor2_uint8(%t245) => {
      %837 = arange(%lower8, %upper8, 1, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][49], dtype="int32");
      %838 = take(%t245, %837, axis=0);
      tensor2_uint8(%838)
    },
    tensor3_uint8(%t345) => {
      %839 = arange(%lower8, %upper8, 1, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][50], dtype="int32");
      %840 = take(%t345, %839, axis=0);
      tensor3_uint8(%840)
    },
    tensor4_uint8(%t445) => {
      %841 = arange(%lower8, %upper8, 1, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][51], dtype="int32");
      %842 = take(%t445, %841, axis=0);
      tensor4_uint8(%842)
    },
    tensor5_uint8(%t523) => {
      %843 = arange(%lower8, %upper8, 1, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][52], dtype="int32");
      %844 = take(%t523, %843, axis=0);
      tensor5_uint8(%844)
    },
    tensor6_uint8(%t69) => {
      %845 = arange(%lower8, %upper8, 1, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][53], dtype="int32");
      %846 = take(%t69, %845, axis=0);
      tensor6_uint8(%846)
    },
  }
}

def @tl[A](%xs13: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:59:11 */) -> List[A] {
  match? (%xs13) {
    Cons(_, %rest6: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:60:23 */) => {
      %rest6
    },
  }
}

def @tmap[A, B](%f10: fn (A) -> B /* ty=fn (A) -> B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:280:12 */, %t60: Tree[A] /* ty=Tree[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:275:9 */) -> Tree[B] {
  match (%t60) {
    Rose(%v10: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:280:15 */, %sub_trees1: List[Tree[A]] /* ty=List[Tree[A]] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:280:35 */) => {
      let %list_f: fn (Tree[A]) -> Tree[B] /* ty=fn (Tree[A]) -> Tree[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:280:26 */ = fn (%tt: Tree[A] /* ty=Tree[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:278:19 */) -> Tree[B] {
        @tmap(%f10, %tt) /* ty=Tree[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:278:9 */
      } /* ty=fn (Tree[A]) -> Tree[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:277:7 */;
      %847 = %f10(%v10) /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:280:12 */;
      %848 = @map(%list_f, %sub_trees1) /* ty=List[Tree[B]] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:280:20 */;
      Rose(%847, %848) /* ty=Tree[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:280:7 */
    },
  }
}

def @unfoldl[A, B](%f11: fn (A) -> Option[(A, B)] /* ty=fn (A) -> Option[(A, B)] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:258:17 */, %seed: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:258:21 */) -> List[B] {
  %849 = @unfoldr(%f11, %seed) /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:258:8 */;
  @rev(%849) /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:258:3 */
}

def @unfoldr[A, B](%f12: fn (A) -> Option[(A, B)] /* ty=fn (A) -> Option[(A, B)] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:245:41 */, %seed1: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:244:14 */) -> List[B] {
  %850 = %f12(%seed1) /* ty=Option[(A, B)] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:244:10 */;
  match (%850) {
    Some(%val: (A, B) /* ty=(A, B) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:245:45 */) => {
      %851 = %val.0 /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:245:45 */;
      %852 = %val.1 /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:245:24 */;
      %853 = @unfoldr(%f12, %851) /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:245:32 */;
      Cons(%852, %853) /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:245:19 */
    },
    None => {
      Nil /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:246:13 */
    },
  }
}

def @update[A](%xs14: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:32 */, %n2: int32 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:38 */, %v11: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:46 */) -> List[A] {
  %854 = equal(%n2, 0 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:89:15 */) /* ty=bool span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:89:7 */;
  if (%854) {
    %855 = @tl(%xs14) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:90:14 */;
    Cons(%v11, %855) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:90:5 */
  } else {
    %856 = @tl(%xs14) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:28 */;
    %857 = subtract(%n2, 1 /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:44 */) /* ty=int32 span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:38 */;
    %858 = @hd(%xs14) /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:10 */;
    %859 = @update(%856, %857, %v11) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:20 */;
    Cons(%858, %859) /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:92:5 */
  }
}

def @zip[A, B](%xs15: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:187:11 */, %ys1: List[B] /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:187:16 */) -> List[(A, B)] {
  %860 = (%xs15, %ys1) /* ty=(List[A], List[B]) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:187:10 */;
  match (%860) {
    (Cons(%x57: A /* ty=A span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:188:53 */, %x_rest: List[A] /* ty=List[A] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:188:67 */), Cons(%y10: B /* ty=B span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:188:57 */, %y_rest: List[B] /* ty=List[B] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:188:76 */)) => {
      %861 = (%x57, %y10) /* ty=(A, B) span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:188:52 */;
      %862 = @zip(%x_rest, %y_rest) /* ty=List[(A, B)] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:188:62 */;
      Cons(%861, %862) /* ty=List[(A, B)] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:188:47 */
    },
    _ => {
      Nil /* ty=List[(A, B)] span=/home/pqy/miniconda3/envs/tvm/lib/python3.8/site-packages/tvm/relay/std/prelude.rly:189:10 */
    },
  }
}

#[metadata]
{
  "root": 1, 
  "nodes": [
    {
      "type_key": ""
    }, 
    {
      "type_key": "Map", 
      "keys": [
        "relay.Constant", 
        "relay.Var"
      ], 
      "data": [2, 59]
    }, 
    {
      "type_key": "Array", 
      "data": [
        3, 
        6, 
        7, 
        8, 
        9, 
        10, 
        11, 
        12, 
        13, 
        14, 
        15, 
        16, 
        17, 
        18, 
        19, 
        20, 
        21, 
        22, 
        23, 
        24, 
        25, 
        26, 
        27, 
        28, 
        29, 
        30, 
        31, 
        32, 
        33, 
        34, 
        35, 
        36, 
        37, 
        38, 
        39, 
        40, 
        41, 
        42, 
        43, 
        44, 
        45, 
        46, 
        47, 
        48, 
        49, 
        50, 
        51, 
        52, 
        53, 
        54, 
        55, 
        56, 
        57, 
        58
      ]
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "0", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "VirtualDevice", 
      "attrs": {
        "device_type_int": "-1", 
        "memory_scope": "5", 
        "target": "0", 
        "virtual_device_id": "-1"
      }
    }, 
    {
      "type_key": "runtime.String"
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "1", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "2", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "3", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "4", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "5", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "6", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "7", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "8", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "9", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "10", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "11", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "12", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "13", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "14", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "15", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "16", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "17", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "18", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "19", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "20", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "21", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "22", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "23", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "24", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "25", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "26", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "27", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "28", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "29", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "30", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "31", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "32", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "33", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "34", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "35", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "36", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "37", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "38", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "39", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "40", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "41", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "42", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "43", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "44", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "45", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "46", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "47", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "48", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "49", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "50", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "51", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "52", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "0", 
        "data": "53", 
        "span": "0", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [
        60, 
        65, 
        70, 
        75, 
        80, 
        85, 
        90, 
        95, 
        100, 
        105, 
        110, 
        115, 
        120, 
        125, 
        130, 
        135, 
        140, 
        145
      ]
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "63", 
        "vid": "61", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "62"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "64", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "68", 
        "vid": "66", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "67"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "69", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "73", 
        "vid": "71", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "72"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "74", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "78", 
        "vid": "76", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "77"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "79", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "83", 
        "vid": "81", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "82"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "84", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "88", 
        "vid": "86", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "87"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "89", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "93", 
        "vid": "91", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "92"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "94", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "98", 
        "vid": "96", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "97"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "99", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "103", 
        "vid": "101", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "102"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "104", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "108", 
        "vid": "106", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "107"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "109", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "113", 
        "vid": "111", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "112"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "114", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "118", 
        "vid": "116", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "117"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "119", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "123", 
        "vid": "121", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "122"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "124", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "128", 
        "vid": "126", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "127"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "129", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "133", 
        "vid": "131", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "132"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "134", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "138", 
        "vid": "136", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "137"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "139", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "143", 
        "vid": "141", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "142"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "lower"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "144", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }, 
    {
      "type_key": "relay.Var", 
      "attrs": {
        "_checked_type_": "0", 
        "span": "0", 
        "type_annotation": "148", 
        "vid": "146", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "relay.Id", 
      "attrs": {"name_hint": "147"}
    }, 
    {
      "type_key": "runtime.String", 
      "repr_str": "upper"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "149", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array"
    }
  ], 
  "b64ndarrays": [
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA=", 
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAAAgAQAEAAAAAAAAAAEAAAA="
  ], 
  "attrs": {"tvm_version": "0.13.dev0"}
}