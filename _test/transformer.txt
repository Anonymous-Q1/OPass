#[version = "0.0.5"]
type List[A] {
  Cons(A, List[A]),
  Nil,
}

type Option[A] {
  Some(A),
  None,
}

type Tree[A] {
  Rose(A, List[Tree[A]]),
}

type tensor_float16_t {
  tensor_nil_float16,
  tensor0_float16(float16),
  tensor1_float16(Tensor[(?), float16]),
  tensor2_float16(Tensor[(?, ?), float16]),
  tensor3_float16(Tensor[(?, ?, ?), float16]),
  tensor4_float16(Tensor[(?, ?, ?, ?), float16]),
  tensor5_float16(Tensor[(?, ?, ?, ?, ?), float16]),
  tensor6_float16(Tensor[(?, ?, ?, ?, ?, ?), float16]),
}

type tensor_float32_t {
  tensor_nil_float32,
  tensor0_float32(float32),
  tensor1_float32(Tensor[(?), float32]),
  tensor2_float32(Tensor[(?, ?), float32]),
  tensor3_float32(Tensor[(?, ?, ?), float32]),
  tensor4_float32(Tensor[(?, ?, ?, ?), float32]),
  tensor5_float32(Tensor[(?, ?, ?, ?, ?), float32]),
  tensor6_float32(Tensor[(?, ?, ?, ?, ?, ?), float32]),
}

type tensor_float64_t {
  tensor_nil_float64,
  tensor0_float64(float64),
  tensor1_float64(Tensor[(?), float64]),
  tensor2_float64(Tensor[(?, ?), float64]),
  tensor3_float64(Tensor[(?, ?, ?), float64]),
  tensor4_float64(Tensor[(?, ?, ?, ?), float64]),
  tensor5_float64(Tensor[(?, ?, ?, ?, ?), float64]),
  tensor6_float64(Tensor[(?, ?, ?, ?, ?, ?), float64]),
}

type tensor_int16_t {
  tensor_nil_int16,
  tensor0_int16(int16),
  tensor1_int16(Tensor[(?), int16]),
  tensor2_int16(Tensor[(?, ?), int16]),
  tensor3_int16(Tensor[(?, ?, ?), int16]),
  tensor4_int16(Tensor[(?, ?, ?, ?), int16]),
  tensor5_int16(Tensor[(?, ?, ?, ?, ?), int16]),
  tensor6_int16(Tensor[(?, ?, ?, ?, ?, ?), int16]),
}

type tensor_int32_t {
  tensor_nil_int32,
  tensor0_int32(int32),
  tensor1_int32(Tensor[(?), int32]),
  tensor2_int32(Tensor[(?, ?), int32]),
  tensor3_int32(Tensor[(?, ?, ?), int32]),
  tensor4_int32(Tensor[(?, ?, ?, ?), int32]),
  tensor5_int32(Tensor[(?, ?, ?, ?, ?), int32]),
  tensor6_int32(Tensor[(?, ?, ?, ?, ?, ?), int32]),
}

type tensor_int64_t {
  tensor_nil_int64,
  tensor0_int64(int64),
  tensor1_int64(Tensor[(?), int64]),
  tensor2_int64(Tensor[(?, ?), int64]),
  tensor3_int64(Tensor[(?, ?, ?), int64]),
  tensor4_int64(Tensor[(?, ?, ?, ?), int64]),
  tensor5_int64(Tensor[(?, ?, ?, ?, ?), int64]),
  tensor6_int64(Tensor[(?, ?, ?, ?, ?, ?), int64]),
}

type tensor_int8_t {
  tensor_nil_int8,
  tensor0_int8(int8),
  tensor1_int8(Tensor[(?), int8]),
  tensor2_int8(Tensor[(?, ?), int8]),
  tensor3_int8(Tensor[(?, ?, ?), int8]),
  tensor4_int8(Tensor[(?, ?, ?, ?), int8]),
  tensor5_int8(Tensor[(?, ?, ?, ?, ?), int8]),
  tensor6_int8(Tensor[(?, ?, ?, ?, ?, ?), int8]),
}

type tensor_uint16_t {
  tensor_nil_uint16,
  tensor0_uint16(uint16),
  tensor1_uint16(Tensor[(?), uint16]),
  tensor2_uint16(Tensor[(?, ?), uint16]),
  tensor3_uint16(Tensor[(?, ?, ?), uint16]),
  tensor4_uint16(Tensor[(?, ?, ?, ?), uint16]),
  tensor5_uint16(Tensor[(?, ?, ?, ?, ?), uint16]),
  tensor6_uint16(Tensor[(?, ?, ?, ?, ?, ?), uint16]),
}

type tensor_uint8_t {
  tensor_nil_uint8,
  tensor0_uint8(uint8),
  tensor1_uint8(Tensor[(?), uint8]),
  tensor2_uint8(Tensor[(?, ?), uint8]),
  tensor3_uint8(Tensor[(?, ?, ?), uint8]),
  tensor4_uint8(Tensor[(?, ?, ?, ?), uint8]),
  tensor5_uint8(Tensor[(?, ?, ?, ?, ?), uint8]),
  tensor6_uint8(Tensor[(?, ?, ?, ?, ?, ?), uint8]),
}

def @main(%tgt: Tensor[(20, 32, 512), float32], %src: Tensor[(10, 32, 512), float32], %decoder_layers_0_self_attn_in_proj_weight: Tensor[(1536, 512), float32], %decoder_layers_0_self_attn_in_proj_bias: Tensor[(1536), float32], %decoder_layers_0_self_attn_out_proj_weight: Tensor[(512, 512), float32], %decoder_layers_0_self_attn_out_proj_bias: Tensor[(512), float32], %decoder_layers_0_norm1_weight: Tensor[(512), float32], %decoder_layers_0_norm1_bias: Tensor[(512), float32], %decoder_layers_0_multihead_attn_in_proj_weight: Tensor[(1536, 512), float32], %decoder_layers_0_multihead_attn_in_proj_bias: Tensor[(1536), float32], %encoder_layers_0_self_attn_in_proj_weight: Tensor[(1536, 512), float32], %encoder_layers_0_self_attn_in_proj_bias: Tensor[(1536), float32], %encoder_layers_0_self_attn_out_proj_weight: Tensor[(512, 512), float32], %encoder_layers_0_self_attn_out_proj_bias: Tensor[(512), float32], %encoder_layers_0_norm1_weight: Tensor[(512), float32], %encoder_layers_0_norm1_bias: Tensor[(512), float32], %encoder_layers_0_linear1_weight: Tensor[(2048, 512), float32], %encoder_layers_0_linear1_bias: Tensor[(2048), float32], %encoder_layers_0_linear2_weight: Tensor[(512, 2048), float32], %encoder_layers_0_linear2_bias: Tensor[(512), float32], %encoder_layers_0_norm2_weight: Tensor[(512), float32], %encoder_layers_0_norm2_bias: Tensor[(512), float32], %encoder_layers_1_self_attn_in_proj_weight: Tensor[(1536, 512), float32], %encoder_layers_1_self_attn_in_proj_bias: Tensor[(1536), float32], %encoder_layers_1_self_attn_out_proj_weight: Tensor[(512, 512), float32], %encoder_layers_1_self_attn_out_proj_bias: Tensor[(512), float32], %encoder_layers_1_norm1_weight: Tensor[(512), float32], %encoder_layers_1_norm1_bias: Tensor[(512), float32], %encoder_layers_1_linear1_weight: Tensor[(2048, 512), float32], %encoder_layers_1_linear1_bias: Tensor[(2048), float32], %encoder_layers_1_linear2_weight: Tensor[(512, 2048), float32], %encoder_layers_1_linear2_bias: Tensor[(512), float32], %encoder_layers_1_norm2_weight: Tensor[(512), float32], %encoder_layers_1_norm2_bias: Tensor[(512), float32], %encoder_layers_2_self_attn_in_proj_weight: Tensor[(1536, 512), float32], %encoder_layers_2_self_attn_in_proj_bias: Tensor[(1536), float32], %encoder_layers_2_self_attn_out_proj_weight: Tensor[(512, 512), float32], %encoder_layers_2_self_attn_out_proj_bias: Tensor[(512), float32], %encoder_layers_2_norm1_weight: Tensor[(512), float32], %encoder_layers_2_norm1_bias: Tensor[(512), float32], %encoder_layers_2_linear1_weight: Tensor[(2048, 512), float32], %encoder_layers_2_linear1_bias: Tensor[(2048), float32], %encoder_layers_2_linear2_weight: Tensor[(512, 2048), float32], %encoder_layers_2_linear2_bias: Tensor[(512), float32], %encoder_layers_2_norm2_weight: Tensor[(512), float32], %encoder_layers_2_norm2_bias: Tensor[(512), float32], %encoder_layers_3_self_attn_in_proj_weight: Tensor[(1536, 512), float32], %encoder_layers_3_self_attn_in_proj_bias: Tensor[(1536), float32], %encoder_layers_3_self_attn_out_proj_weight: Tensor[(512, 512), float32], %encoder_layers_3_self_attn_out_proj_bias: Tensor[(512), float32], %encoder_layers_3_norm1_weight: Tensor[(512), float32], %encoder_layers_3_norm1_bias: Tensor[(512), float32], %encoder_layers_3_linear1_weight: Tensor[(2048, 512), float32], %encoder_layers_3_linear1_bias: Tensor[(2048), float32], %encoder_layers_3_linear2_weight: Tensor[(512, 2048), float32], %encoder_layers_3_linear2_bias: Tensor[(512), float32], %encoder_layers_3_norm2_weight: Tensor[(512), float32], %encoder_layers_3_norm2_bias: Tensor[(512), float32], %encoder_layers_4_self_attn_in_proj_weight: Tensor[(1536, 512), float32], %encoder_layers_4_self_attn_in_proj_bias: Tensor[(1536), float32], %encoder_layers_4_self_attn_out_proj_weight: Tensor[(512, 512), float32], %encoder_layers_4_self_attn_out_proj_bias: Tensor[(512), float32], %encoder_layers_4_norm1_weight: Tensor[(512), float32], %encoder_layers_4_norm1_bias: Tensor[(512), float32], %encoder_layers_4_linear1_weight: Tensor[(2048, 512), float32], %encoder_layers_4_linear1_bias: Tensor[(2048), float32], %encoder_layers_4_linear2_weight: Tensor[(512, 2048), float32], %encoder_layers_4_linear2_bias: Tensor[(512), float32], %encoder_layers_4_norm2_weight: Tensor[(512), float32], %encoder_layers_4_norm2_bias: Tensor[(512), float32], %encoder_layers_5_self_attn_in_proj_weight: Tensor[(1536, 512), float32], %encoder_layers_5_self_attn_in_proj_bias: Tensor[(1536), float32], %encoder_layers_5_self_attn_out_proj_weight: Tensor[(512, 512), float32], %encoder_layers_5_self_attn_out_proj_bias: Tensor[(512), float32], %encoder_layers_5_norm1_weight: Tensor[(512), float32], %encoder_layers_5_norm1_bias: Tensor[(512), float32], %encoder_layers_5_linear1_weight: Tensor[(2048, 512), float32], %encoder_layers_5_linear1_bias: Tensor[(2048), float32], %encoder_layers_5_linear2_weight: Tensor[(512, 2048), float32], %encoder_layers_5_linear2_bias: Tensor[(512), float32], %encoder_layers_5_norm2_weight: Tensor[(512), float32], %encoder_layers_5_norm2_bias: Tensor[(512), float32], %encoder_layers_6_self_attn_in_proj_weight: Tensor[(1536, 512), float32], %encoder_layers_6_self_attn_in_proj_bias: Tensor[(1536), float32], %encoder_layers_6_self_attn_out_proj_weight: Tensor[(512, 512), float32], %encoder_layers_6_self_attn_out_proj_bias: Tensor[(512), float32], %encoder_layers_6_norm1_weight: Tensor[(512), float32], %encoder_layers_6_norm1_bias: Tensor[(512), float32], %encoder_layers_6_linear1_weight: Tensor[(2048, 512), float32], %encoder_layers_6_linear1_bias: Tensor[(2048), float32], %encoder_layers_6_linear2_weight: Tensor[(512, 2048), float32], %encoder_layers_6_linear2_bias: Tensor[(512), float32], %encoder_layers_6_norm2_weight: Tensor[(512), float32], %encoder_layers_6_norm2_bias: Tensor[(512), float32], %encoder_layers_7_self_attn_in_proj_weight: Tensor[(1536, 512), float32], %encoder_layers_7_self_attn_in_proj_bias: Tensor[(1536), float32], %encoder_layers_7_self_attn_out_proj_weight: Tensor[(512, 512), float32], %encoder_layers_7_self_attn_out_proj_bias: Tensor[(512), float32], %encoder_layers_7_norm1_weight: Tensor[(512), float32], %encoder_layers_7_norm1_bias: Tensor[(512), float32], %encoder_layers_7_linear1_weight: Tensor[(2048, 512), float32], %encoder_layers_7_linear1_bias: Tensor[(2048), float32], %encoder_layers_7_linear2_weight: Tensor[(512, 2048), float32], %encoder_layers_7_linear2_bias: Tensor[(512), float32], %encoder_layers_7_norm2_weight: Tensor[(512), float32], %encoder_layers_7_norm2_bias: Tensor[(512), float32], %encoder_layers_8_self_attn_in_proj_weight: Tensor[(1536, 512), float32], %encoder_layers_8_self_attn_in_proj_bias: Tensor[(1536), float32], %encoder_layers_8_self_attn_out_proj_weight: Tensor[(512, 512), float32], %encoder_layers_8_self_attn_out_proj_bias: Tensor[(512), float32], %encoder_layers_8_norm1_weight: Tensor[(512), float32], %encoder_layers_8_norm1_bias: Tensor[(512), float32], %encoder_layers_8_linear1_weight: Tensor[(2048, 512), float32], %encoder_layers_8_linear1_bias: Tensor[(2048), float32], %encoder_layers_8_linear2_weight: Tensor[(512, 2048), float32], %encoder_layers_8_linear2_bias: Tensor[(512), float32], %encoder_layers_8_norm2_weight: Tensor[(512), float32], %encoder_layers_8_norm2_bias: Tensor[(512), float32], %encoder_layers_9_self_attn_in_proj_weight: Tensor[(1536, 512), float32], %encoder_layers_9_self_attn_in_proj_bias: Tensor[(1536), float32], %encoder_layers_9_self_attn_out_proj_weight: Tensor[(512, 512), float32], %encoder_layers_9_self_attn_out_proj_bias: Tensor[(512), float32], %encoder_layers_9_norm1_weight: Tensor[(512), float32], %encoder_layers_9_norm1_bias: Tensor[(512), float32], %encoder_layers_9_linear1_weight: Tensor[(2048, 512), float32], %encoder_layers_9_linear1_bias: Tensor[(2048), float32], %encoder_layers_9_linear2_weight: Tensor[(512, 2048), float32], %encoder_layers_9_linear2_bias: Tensor[(512), float32], %encoder_layers_9_norm2_weight: Tensor[(512), float32], %encoder_layers_9_norm2_bias: Tensor[(512), float32], %encoder_layers_10_self_attn_in_proj_weight: Tensor[(1536, 512), float32], %encoder_layers_10_self_attn_in_proj_bias: Tensor[(1536), float32], %encoder_layers_10_self_attn_out_proj_weight: Tensor[(512, 512), float32], %encoder_layers_10_self_attn_out_proj_bias: Tensor[(512), float32], %encoder_layers_10_norm1_weight: Tensor[(512), float32], %encoder_layers_10_norm1_bias: Tensor[(512), float32], %encoder_layers_10_linear1_weight: Tensor[(2048, 512), float32], %encoder_layers_10_linear1_bias: Tensor[(2048), float32], %encoder_layers_10_linear2_weight: Tensor[(512, 2048), float32], %encoder_layers_10_linear2_bias: Tensor[(512), float32], %encoder_layers_10_norm2_weight: Tensor[(512), float32], %encoder_layers_10_norm2_bias: Tensor[(512), float32], %encoder_layers_11_self_attn_in_proj_weight: Tensor[(1536, 512), float32], %encoder_layers_11_self_attn_in_proj_bias: Tensor[(1536), float32], %encoder_layers_11_self_attn_out_proj_weight: Tensor[(512, 512), float32], %encoder_layers_11_self_attn_out_proj_bias: Tensor[(512), float32], %encoder_layers_11_norm1_weight: Tensor[(512), float32], %encoder_layers_11_norm1_bias: Tensor[(512), float32], %encoder_layers_11_linear1_weight: Tensor[(2048, 512), float32], %encoder_layers_11_linear1_bias: Tensor[(2048), float32], %encoder_layers_11_linear2_weight: Tensor[(512, 2048), float32], %encoder_layers_11_linear2_bias: Tensor[(512), float32], %encoder_layers_11_norm2_weight: Tensor[(512), float32], %encoder_layers_11_norm2_bias: Tensor[(512), float32], %encoder_norm_weight: Tensor[(512), float32], %encoder_norm_bias: Tensor[(512), float32], %decoder_layers_0_multihead_attn_out_proj_weight: Tensor[(512, 512), float32], %decoder_layers_0_multihead_attn_out_proj_bias: Tensor[(512), float32], %decoder_layers_0_norm2_weight: Tensor[(512), float32], %decoder_layers_0_norm2_bias: Tensor[(512), float32], %decoder_layers_0_linear1_weight: Tensor[(2048, 512), float32], %decoder_layers_0_linear1_bias: Tensor[(2048), float32], %decoder_layers_0_linear2_weight: Tensor[(512, 2048), float32], %decoder_layers_0_linear2_bias: Tensor[(512), float32], %decoder_layers_0_norm3_weight: Tensor[(512), float32], %decoder_layers_0_norm3_bias: Tensor[(512), float32], %decoder_layers_1_self_attn_in_proj_weight: Tensor[(1536, 512), float32], %decoder_layers_1_self_attn_in_proj_bias: Tensor[(1536), float32], %decoder_layers_1_self_attn_out_proj_weight: Tensor[(512, 512), float32], %decoder_layers_1_self_attn_out_proj_bias: Tensor[(512), float32], %decoder_layers_1_norm1_weight: Tensor[(512), float32], %decoder_layers_1_norm1_bias: Tensor[(512), float32], %decoder_layers_1_multihead_attn_in_proj_weight: Tensor[(1536, 512), float32], %decoder_layers_1_multihead_attn_in_proj_bias: Tensor[(1536), float32], %decoder_layers_1_multihead_attn_out_proj_weight: Tensor[(512, 512), float32], %decoder_layers_1_multihead_attn_out_proj_bias: Tensor[(512), float32], %decoder_layers_1_norm2_weight: Tensor[(512), float32], %decoder_layers_1_norm2_bias: Tensor[(512), float32], %decoder_layers_1_linear1_weight: Tensor[(2048, 512), float32], %decoder_layers_1_linear1_bias: Tensor[(2048), float32], %decoder_layers_1_linear2_weight: Tensor[(512, 2048), float32], %decoder_layers_1_linear2_bias: Tensor[(512), float32], %decoder_layers_1_norm3_weight: Tensor[(512), float32], %decoder_layers_1_norm3_bias: Tensor[(512), float32], %decoder_layers_2_self_attn_in_proj_weight: Tensor[(1536, 512), float32], %decoder_layers_2_self_attn_in_proj_bias: Tensor[(1536), float32], %decoder_layers_2_self_attn_out_proj_weight: Tensor[(512, 512), float32], %decoder_layers_2_self_attn_out_proj_bias: Tensor[(512), float32], %decoder_layers_2_norm1_weight: Tensor[(512), float32], %decoder_layers_2_norm1_bias: Tensor[(512), float32], %decoder_layers_2_multihead_attn_in_proj_weight: Tensor[(1536, 512), float32], %decoder_layers_2_multihead_attn_in_proj_bias: Tensor[(1536), float32], %decoder_layers_2_multihead_attn_out_proj_weight: Tensor[(512, 512), float32], %decoder_layers_2_multihead_attn_out_proj_bias: Tensor[(512), float32], %decoder_layers_2_norm2_weight: Tensor[(512), float32], %decoder_layers_2_norm2_bias: Tensor[(512), float32], %decoder_layers_2_linear1_weight: Tensor[(2048, 512), float32], %decoder_layers_2_linear1_bias: Tensor[(2048), float32], %decoder_layers_2_linear2_weight: Tensor[(512, 2048), float32], %decoder_layers_2_linear2_bias: Tensor[(512), float32], %decoder_layers_2_norm3_weight: Tensor[(512), float32], %decoder_layers_2_norm3_bias: Tensor[(512), float32], %decoder_layers_3_self_attn_in_proj_weight: Tensor[(1536, 512), float32], %decoder_layers_3_self_attn_in_proj_bias: Tensor[(1536), float32], %decoder_layers_3_self_attn_out_proj_weight: Tensor[(512, 512), float32], %decoder_layers_3_self_attn_out_proj_bias: Tensor[(512), float32], %decoder_layers_3_norm1_weight: Tensor[(512), float32], %decoder_layers_3_norm1_bias: Tensor[(512), float32], %decoder_layers_3_multihead_attn_in_proj_weight: Tensor[(1536, 512), float32], %decoder_layers_3_multihead_attn_in_proj_bias: Tensor[(1536), float32], %decoder_layers_3_multihead_attn_out_proj_weight: Tensor[(512, 512), float32], %decoder_layers_3_multihead_attn_out_proj_bias: Tensor[(512), float32], %decoder_layers_3_norm2_weight: Tensor[(512), float32], %decoder_layers_3_norm2_bias: Tensor[(512), float32], %decoder_layers_3_linear1_weight: Tensor[(2048, 512), float32], %decoder_layers_3_linear1_bias: Tensor[(2048), float32], %decoder_layers_3_linear2_weight: Tensor[(512, 2048), float32], %decoder_layers_3_linear2_bias: Tensor[(512), float32], %decoder_layers_3_norm3_weight: Tensor[(512), float32], %decoder_layers_3_norm3_bias: Tensor[(512), float32], %decoder_layers_4_self_attn_in_proj_weight: Tensor[(1536, 512), float32], %decoder_layers_4_self_attn_in_proj_bias: Tensor[(1536), float32], %decoder_layers_4_self_attn_out_proj_weight: Tensor[(512, 512), float32], %decoder_layers_4_self_attn_out_proj_bias: Tensor[(512), float32], %decoder_layers_4_norm1_weight: Tensor[(512), float32], %decoder_layers_4_norm1_bias: Tensor[(512), float32], %decoder_layers_4_multihead_attn_in_proj_weight: Tensor[(1536, 512), float32], %decoder_layers_4_multihead_attn_in_proj_bias: Tensor[(1536), float32], %decoder_layers_4_multihead_attn_out_proj_weight: Tensor[(512, 512), float32], %decoder_layers_4_multihead_attn_out_proj_bias: Tensor[(512), float32], %decoder_layers_4_norm2_weight: Tensor[(512), float32], %decoder_layers_4_norm2_bias: Tensor[(512), float32], %decoder_layers_4_linear1_weight: Tensor[(2048, 512), float32], %decoder_layers_4_linear1_bias: Tensor[(2048), float32], %decoder_layers_4_linear2_weight: Tensor[(512, 2048), float32], %decoder_layers_4_linear2_bias: Tensor[(512), float32], %decoder_layers_4_norm3_weight: Tensor[(512), float32], %decoder_layers_4_norm3_bias: Tensor[(512), float32], %decoder_layers_5_self_attn_in_proj_weight: Tensor[(1536, 512), float32], %decoder_layers_5_self_attn_in_proj_bias: Tensor[(1536), float32], %decoder_layers_5_self_attn_out_proj_weight: Tensor[(512, 512), float32], %decoder_layers_5_self_attn_out_proj_bias: Tensor[(512), float32], %decoder_layers_5_norm1_weight: Tensor[(512), float32], %decoder_layers_5_norm1_bias: Tensor[(512), float32], %decoder_layers_5_multihead_attn_in_proj_weight: Tensor[(1536, 512), float32], %decoder_layers_5_multihead_attn_in_proj_bias: Tensor[(1536), float32], %decoder_layers_5_multihead_attn_out_proj_weight: Tensor[(512, 512), float32], %decoder_layers_5_multihead_attn_out_proj_bias: Tensor[(512), float32], %decoder_layers_5_norm2_weight: Tensor[(512), float32], %decoder_layers_5_norm2_bias: Tensor[(512), float32], %decoder_layers_5_linear1_weight: Tensor[(2048, 512), float32], %decoder_layers_5_linear1_bias: Tensor[(2048), float32], %decoder_layers_5_linear2_weight: Tensor[(512, 2048), float32], %decoder_layers_5_linear2_bias: Tensor[(512), float32], %decoder_layers_5_norm3_weight: Tensor[(512), float32], %decoder_layers_5_norm3_bias: Tensor[(512), float32], %decoder_norm_weight: Tensor[(512), float32], %decoder_norm_bias: Tensor[(512), float32]) {
  %0 = transpose(%decoder_layers_0_self_attn_in_proj_weight, axes=[1, 0]);
  %1 = reshape(%tgt, newshape=[-1, 512]);
  %2 = transpose(%0, axes=[1, 0]);
  %3 = nn.dense(%1, %2, units=None);
  %4 = reshape(%3, newshape=[20, 32, 1536]);
  %5 = add(%4, %decoder_layers_0_self_attn_in_proj_bias);
  %6 = split(%5, indices_or_sections=[512, 1024], axis=-1);
  %7 = %6.0;
  %8 = multiply(%7, 0.176777f);
  %9 = reshape(%8, newshape=[20, 512, 32]);
  %10 = %6.1;
  %11 = reshape(%10, newshape=[-1, 512, 32]);
  %12 = transpose(%11, axes=[1, 0, 2]);
  %13 = transpose(%12, axes=[0, 2, 1]);
  %14 = transpose(%9, axes=[1, 0, 2]);
  %15 = transpose(%13, axes=[0, 2, 1]);
  %16 = nn.batch_matmul(%14, %15, transpose_b=True);
  %17 = nn.softmax(%16);
  %18 = nn.dropout(%17, rate=0.1f);
  %19 = %6.2;
  %20 = reshape(%19, newshape=[-1, 512, 32]);
  %21 = transpose(%20, axes=[1, 0, 2]);
  %22 = %18.0;
  %23 = transpose(%21, axes=[0, 2, 1]);
  %24 = nn.batch_matmul(%22, %23, transpose_b=True);
  %25 = transpose(%24, axes=[1, 0, 2]);
  %26 = reshape(%25, newshape=[20, 32, 512]);
  %27 = transpose(%decoder_layers_0_self_attn_out_proj_weight, axes=[1, 0]);
  %28 = reshape(%26, newshape=[-1, 512]);
  %29 = transpose(%27, axes=[1, 0]);
  %30 = nn.dense(%28, %29, units=None);
  %31 = reshape(%30, newshape=[20, 32, 512]);
  %32 = add(%31, %decoder_layers_0_self_attn_out_proj_bias);
  %33 = nn.dropout(%32, rate=0.1f);
  %34 = %33.0;
  %35 = add(%tgt, %34);
  %36 = nn.layer_norm(%35, %decoder_layers_0_norm1_weight, %decoder_layers_0_norm1_bias);
  %37 = strided_slice(%decoder_layers_0_multihead_attn_in_proj_weight, begin=[0, 0], end=[512, 512], strides=[1, 1], axes=None);
  %38 = transpose(%37, axes=[1, 0]);
  %39 = reshape(%36, newshape=[-1, 512]);
  %40 = transpose(%38, axes=[1, 0]);
  %41 = nn.dense(%39, %40, units=None);
  %42 = reshape(%41, newshape=[20, 32, 512]);
  %43 = strided_slice(%decoder_layers_0_multihead_attn_in_proj_bias, begin=[0], end=[512], strides=[1], axes=None);
  %44 = add(%42, %43);
  %45 = multiply(%44, 0.176777f);
  %46 = reshape(%45, newshape=[20, 512, 32]);
  %47 = transpose(%encoder_layers_0_self_attn_in_proj_weight, axes=[1, 0]);
  %48 = reshape(%src, newshape=[-1, 512]);
  %49 = transpose(%47, axes=[1, 0]);
  %50 = nn.dense(%48, %49, units=None);
  %51 = reshape(%50, newshape=[10, 32, 1536]);
  %52 = add(%51, %encoder_layers_0_self_attn_in_proj_bias);
  %53 = split(%52, indices_or_sections=[512, 1024], axis=-1);
  %54 = %53.0;
  %55 = multiply(%54, 0.176777f);
  %56 = reshape(%55, newshape=[10, 512, 32]);
  %57 = %53.1;
  %58 = reshape(%57, newshape=[-1, 512, 32]);
  %59 = transpose(%58, axes=[1, 0, 2]);
  %60 = transpose(%59, axes=[0, 2, 1]);
  %61 = transpose(%56, axes=[1, 0, 2]);
  %62 = transpose(%60, axes=[0, 2, 1]);
  %63 = nn.batch_matmul(%61, %62, transpose_b=True);
  %64 = nn.softmax(%63);
  %65 = nn.dropout(%64, rate=0.1f);
  %66 = %53.2;
  %67 = reshape(%66, newshape=[-1, 512, 32]);
  %68 = transpose(%67, axes=[1, 0, 2]);
  %69 = %65.0;
  %70 = transpose(%68, axes=[0, 2, 1]);
  %71 = nn.batch_matmul(%69, %70, transpose_b=True);
  %72 = transpose(%71, axes=[1, 0, 2]);
  %73 = reshape(%72, newshape=[10, 32, 512]);
  %74 = transpose(%encoder_layers_0_self_attn_out_proj_weight, axes=[1, 0]);
  %75 = reshape(%73, newshape=[-1, 512]);
  %76 = transpose(%74, axes=[1, 0]);
  %77 = nn.dense(%75, %76, units=None);
  %78 = reshape(%77, newshape=[10, 32, 512]);
  %79 = add(%78, %encoder_layers_0_self_attn_out_proj_bias);
  %80 = nn.dropout(%79, rate=0.1f);
  %81 = %80.0;
  %82 = add(%src, %81);
  %83 = nn.layer_norm(%82, %encoder_layers_0_norm1_weight, %encoder_layers_0_norm1_bias);
  %84 = transpose(%encoder_layers_0_linear1_weight, axes=[1, 0]);
  %85 = reshape(%83, newshape=[-1, 512]);
  %86 = transpose(%84, axes=[1, 0]);
  %87 = nn.dense(%85, %86, units=None);
  %88 = reshape(%87, newshape=[10, 32, 2048]);
  %89 = add(%88, %encoder_layers_0_linear1_bias);
  %90 = nn.relu(%89);
  %91 = nn.dropout(%90, rate=0.1f);
  %92 = %91.0;
  %93 = transpose(%encoder_layers_0_linear2_weight, axes=[1, 0]);
  %94 = reshape(%92, newshape=[-1, 2048]);
  %95 = transpose(%93, axes=[1, 0]);
  %96 = nn.dense(%94, %95, units=None);
  %97 = reshape(%96, newshape=[10, 32, 512]);
  %98 = add(%97, %encoder_layers_0_linear2_bias);
  %99 = nn.dropout(%98, rate=0.1f);
  %100 = %99.0;
  %101 = add(%83, %100);
  %102 = nn.layer_norm(%101, %encoder_layers_0_norm2_weight, %encoder_layers_0_norm2_bias);
  %103 = transpose(%encoder_layers_1_self_attn_in_proj_weight, axes=[1, 0]);
  %104 = reshape(%102, newshape=[-1, 512]);
  %105 = transpose(%103, axes=[1, 0]);
  %106 = nn.dense(%104, %105, units=None);
  %107 = reshape(%106, newshape=[10, 32, 1536]);
  %108 = add(%107, %encoder_layers_1_self_attn_in_proj_bias);
  %109 = split(%108, indices_or_sections=[512, 1024], axis=-1);
  %110 = %109.0;
  %111 = multiply(%110, 0.176777f);
  %112 = reshape(%111, newshape=[10, 512, 32]);
  %113 = %109.1;
  %114 = reshape(%113, newshape=[-1, 512, 32]);
  %115 = transpose(%114, axes=[1, 0, 2]);
  %116 = transpose(%115, axes=[0, 2, 1]);
  %117 = transpose(%112, axes=[1, 0, 2]);
  %118 = transpose(%116, axes=[0, 2, 1]);
  %119 = nn.batch_matmul(%117, %118, transpose_b=True);
  %120 = nn.softmax(%119);
  %121 = nn.dropout(%120, rate=0.1f);
  %122 = %109.2;
  %123 = reshape(%122, newshape=[-1, 512, 32]);
  %124 = transpose(%123, axes=[1, 0, 2]);
  %125 = %121.0;
  %126 = transpose(%124, axes=[0, 2, 1]);
  %127 = nn.batch_matmul(%125, %126, transpose_b=True);
  %128 = transpose(%127, axes=[1, 0, 2]);
  %129 = reshape(%128, newshape=[10, 32, 512]);
  %130 = transpose(%encoder_layers_1_self_attn_out_proj_weight, axes=[1, 0]);
  %131 = reshape(%129, newshape=[-1, 512]);
  %132 = transpose(%130, axes=[1, 0]);
  %133 = nn.dense(%131, %132, units=None);
  %134 = reshape(%133, newshape=[10, 32, 512]);
  %135 = add(%134, %encoder_layers_1_self_attn_out_proj_bias);
  %136 = nn.dropout(%135, rate=0.1f);
  %137 = %136.0;
  %138 = add(%102, %137);
  %139 = nn.layer_norm(%138, %encoder_layers_1_norm1_weight, %encoder_layers_1_norm1_bias);
  %140 = transpose(%encoder_layers_1_linear1_weight, axes=[1, 0]);
  %141 = reshape(%139, newshape=[-1, 512]);
  %142 = transpose(%140, axes=[1, 0]);
  %143 = nn.dense(%141, %142, units=None);
  %144 = reshape(%143, newshape=[10, 32, 2048]);
  %145 = add(%144, %encoder_layers_1_linear1_bias);
  %146 = nn.relu(%145);
  %147 = nn.dropout(%146, rate=0.1f);
  %148 = %147.0;
  %149 = transpose(%encoder_layers_1_linear2_weight, axes=[1, 0]);
  %150 = reshape(%148, newshape=[-1, 2048]);
  %151 = transpose(%149, axes=[1, 0]);
  %152 = nn.dense(%150, %151, units=None);
  %153 = reshape(%152, newshape=[10, 32, 512]);
  %154 = add(%153, %encoder_layers_1_linear2_bias);
  %155 = nn.dropout(%154, rate=0.1f);
  %156 = %155.0;
  %157 = add(%139, %156);
  %158 = nn.layer_norm(%157, %encoder_layers_1_norm2_weight, %encoder_layers_1_norm2_bias);
  %159 = transpose(%encoder_layers_2_self_attn_in_proj_weight, axes=[1, 0]);
  %160 = reshape(%158, newshape=[-1, 512]);
  %161 = transpose(%159, axes=[1, 0]);
  %162 = nn.dense(%160, %161, units=None);
  %163 = reshape(%162, newshape=[10, 32, 1536]);
  %164 = add(%163, %encoder_layers_2_self_attn_in_proj_bias);
  %165 = split(%164, indices_or_sections=[512, 1024], axis=-1);
  %166 = %165.0;
  %167 = multiply(%166, 0.176777f);
  %168 = reshape(%167, newshape=[10, 512, 32]);
  %169 = %165.1;
  %170 = reshape(%169, newshape=[-1, 512, 32]);
  %171 = transpose(%170, axes=[1, 0, 2]);
  %172 = transpose(%171, axes=[0, 2, 1]);
  %173 = transpose(%168, axes=[1, 0, 2]);
  %174 = transpose(%172, axes=[0, 2, 1]);
  %175 = nn.batch_matmul(%173, %174, transpose_b=True);
  %176 = nn.softmax(%175);
  %177 = nn.dropout(%176, rate=0.1f);
  %178 = %165.2;
  %179 = reshape(%178, newshape=[-1, 512, 32]);
  %180 = transpose(%179, axes=[1, 0, 2]);
  %181 = %177.0;
  %182 = transpose(%180, axes=[0, 2, 1]);
  %183 = nn.batch_matmul(%181, %182, transpose_b=True);
  %184 = transpose(%183, axes=[1, 0, 2]);
  %185 = reshape(%184, newshape=[10, 32, 512]);
  %186 = transpose(%encoder_layers_2_self_attn_out_proj_weight, axes=[1, 0]);
  %187 = reshape(%185, newshape=[-1, 512]);
  %188 = transpose(%186, axes=[1, 0]);
  %189 = nn.dense(%187, %188, units=None);
  %190 = reshape(%189, newshape=[10, 32, 512]);
  %191 = add(%190, %encoder_layers_2_self_attn_out_proj_bias);
  %192 = nn.dropout(%191, rate=0.1f);
  %193 = %192.0;
  %194 = add(%158, %193);
  %195 = nn.layer_norm(%194, %encoder_layers_2_norm1_weight, %encoder_layers_2_norm1_bias);
  %196 = transpose(%encoder_layers_2_linear1_weight, axes=[1, 0]);
  %197 = reshape(%195, newshape=[-1, 512]);
  %198 = transpose(%196, axes=[1, 0]);
  %199 = nn.dense(%197, %198, units=None);
  %200 = reshape(%199, newshape=[10, 32, 2048]);
  %201 = add(%200, %encoder_layers_2_linear1_bias);
  %202 = nn.relu(%201);
  %203 = nn.dropout(%202, rate=0.1f);
  %204 = %203.0;
  %205 = transpose(%encoder_layers_2_linear2_weight, axes=[1, 0]);
  %206 = reshape(%204, newshape=[-1, 2048]);
  %207 = transpose(%205, axes=[1, 0]);
  %208 = nn.dense(%206, %207, units=None);
  %209 = reshape(%208, newshape=[10, 32, 512]);
  %210 = add(%209, %encoder_layers_2_linear2_bias);
  %211 = nn.dropout(%210, rate=0.1f);
  %212 = %211.0;
  %213 = add(%195, %212);
  %214 = nn.layer_norm(%213, %encoder_layers_2_norm2_weight, %encoder_layers_2_norm2_bias);
  %215 = transpose(%encoder_layers_3_self_attn_in_proj_weight, axes=[1, 0]);
  %216 = reshape(%214, newshape=[-1, 512]);
  %217 = transpose(%215, axes=[1, 0]);
  %218 = nn.dense(%216, %217, units=None);
  %219 = reshape(%218, newshape=[10, 32, 1536]);
  %220 = add(%219, %encoder_layers_3_self_attn_in_proj_bias);
  %221 = split(%220, indices_or_sections=[512, 1024], axis=-1);
  %222 = %221.0;
  %223 = multiply(%222, 0.176777f);
  %224 = reshape(%223, newshape=[10, 512, 32]);
  %225 = %221.1;
  %226 = reshape(%225, newshape=[-1, 512, 32]);
  %227 = transpose(%226, axes=[1, 0, 2]);
  %228 = transpose(%227, axes=[0, 2, 1]);
  %229 = transpose(%224, axes=[1, 0, 2]);
  %230 = transpose(%228, axes=[0, 2, 1]);
  %231 = nn.batch_matmul(%229, %230, transpose_b=True);
  %232 = nn.softmax(%231);
  %233 = nn.dropout(%232, rate=0.1f);
  %234 = %221.2;
  %235 = reshape(%234, newshape=[-1, 512, 32]);
  %236 = transpose(%235, axes=[1, 0, 2]);
  %237 = %233.0;
  %238 = transpose(%236, axes=[0, 2, 1]);
  %239 = nn.batch_matmul(%237, %238, transpose_b=True);
  %240 = transpose(%239, axes=[1, 0, 2]);
  %241 = reshape(%240, newshape=[10, 32, 512]);
  %242 = transpose(%encoder_layers_3_self_attn_out_proj_weight, axes=[1, 0]);
  %243 = reshape(%241, newshape=[-1, 512]);
  %244 = transpose(%242, axes=[1, 0]);
  %245 = nn.dense(%243, %244, units=None);
  %246 = reshape(%245, newshape=[10, 32, 512]);
  %247 = add(%246, %encoder_layers_3_self_attn_out_proj_bias);
  %248 = nn.dropout(%247, rate=0.1f);
  %249 = %248.0;
  %250 = add(%214, %249);
  %251 = nn.layer_norm(%250, %encoder_layers_3_norm1_weight, %encoder_layers_3_norm1_bias);
  %252 = transpose(%encoder_layers_3_linear1_weight, axes=[1, 0]);
  %253 = reshape(%251, newshape=[-1, 512]);
  %254 = transpose(%252, axes=[1, 0]);
  %255 = nn.dense(%253, %254, units=None);
  %256 = reshape(%255, newshape=[10, 32, 2048]);
  %257 = add(%256, %encoder_layers_3_linear1_bias);
  %258 = nn.relu(%257);
  %259 = nn.dropout(%258, rate=0.1f);
  %260 = %259.0;
  %261 = transpose(%encoder_layers_3_linear2_weight, axes=[1, 0]);
  %262 = reshape(%260, newshape=[-1, 2048]);
  %263 = transpose(%261, axes=[1, 0]);
  %264 = nn.dense(%262, %263, units=None);
  %265 = reshape(%264, newshape=[10, 32, 512]);
  %266 = add(%265, %encoder_layers_3_linear2_bias);
  %267 = nn.dropout(%266, rate=0.1f);
  %268 = %267.0;
  %269 = add(%251, %268);
  %270 = nn.layer_norm(%269, %encoder_layers_3_norm2_weight, %encoder_layers_3_norm2_bias);
  %271 = transpose(%encoder_layers_4_self_attn_in_proj_weight, axes=[1, 0]);
  %272 = reshape(%270, newshape=[-1, 512]);
  %273 = transpose(%271, axes=[1, 0]);
  %274 = nn.dense(%272, %273, units=None);
  %275 = reshape(%274, newshape=[10, 32, 1536]);
  %276 = add(%275, %encoder_layers_4_self_attn_in_proj_bias);
  %277 = split(%276, indices_or_sections=[512, 1024], axis=-1);
  %278 = %277.0;
  %279 = multiply(%278, 0.176777f);
  %280 = reshape(%279, newshape=[10, 512, 32]);
  %281 = %277.1;
  %282 = reshape(%281, newshape=[-1, 512, 32]);
  %283 = transpose(%282, axes=[1, 0, 2]);
  %284 = transpose(%283, axes=[0, 2, 1]);
  %285 = transpose(%280, axes=[1, 0, 2]);
  %286 = transpose(%284, axes=[0, 2, 1]);
  %287 = nn.batch_matmul(%285, %286, transpose_b=True);
  %288 = nn.softmax(%287);
  %289 = nn.dropout(%288, rate=0.1f);
  %290 = %277.2;
  %291 = reshape(%290, newshape=[-1, 512, 32]);
  %292 = transpose(%291, axes=[1, 0, 2]);
  %293 = %289.0;
  %294 = transpose(%292, axes=[0, 2, 1]);
  %295 = nn.batch_matmul(%293, %294, transpose_b=True);
  %296 = transpose(%295, axes=[1, 0, 2]);
  %297 = reshape(%296, newshape=[10, 32, 512]);
  %298 = transpose(%encoder_layers_4_self_attn_out_proj_weight, axes=[1, 0]);
  %299 = reshape(%297, newshape=[-1, 512]);
  %300 = transpose(%298, axes=[1, 0]);
  %301 = nn.dense(%299, %300, units=None);
  %302 = reshape(%301, newshape=[10, 32, 512]);
  %303 = add(%302, %encoder_layers_4_self_attn_out_proj_bias);
  %304 = nn.dropout(%303, rate=0.1f);
  %305 = %304.0;
  %306 = add(%270, %305);
  %307 = nn.layer_norm(%306, %encoder_layers_4_norm1_weight, %encoder_layers_4_norm1_bias);
  %308 = transpose(%encoder_layers_4_linear1_weight, axes=[1, 0]);
  %309 = reshape(%307, newshape=[-1, 512]);
  %310 = transpose(%308, axes=[1, 0]);
  %311 = nn.dense(%309, %310, units=None);
  %312 = reshape(%311, newshape=[10, 32, 2048]);
  %313 = add(%312, %encoder_layers_4_linear1_bias);
  %314 = nn.relu(%313);
  %315 = nn.dropout(%314, rate=0.1f);
  %316 = %315.0;
  %317 = transpose(%encoder_layers_4_linear2_weight, axes=[1, 0]);
  %318 = reshape(%316, newshape=[-1, 2048]);
  %319 = transpose(%317, axes=[1, 0]);
  %320 = nn.dense(%318, %319, units=None);
  %321 = reshape(%320, newshape=[10, 32, 512]);
  %322 = add(%321, %encoder_layers_4_linear2_bias);
  %323 = nn.dropout(%322, rate=0.1f);
  %324 = %323.0;
  %325 = add(%307, %324);
  %326 = nn.layer_norm(%325, %encoder_layers_4_norm2_weight, %encoder_layers_4_norm2_bias);
  %327 = transpose(%encoder_layers_5_self_attn_in_proj_weight, axes=[1, 0]);
  %328 = reshape(%326, newshape=[-1, 512]);
  %329 = transpose(%327, axes=[1, 0]);
  %330 = nn.dense(%328, %329, units=None);
  %331 = reshape(%330, newshape=[10, 32, 1536]);
  %332 = add(%331, %encoder_layers_5_self_attn_in_proj_bias);
  %333 = split(%332, indices_or_sections=[512, 1024], axis=-1);
  %334 = %333.0;
  %335 = multiply(%334, 0.176777f);
  %336 = reshape(%335, newshape=[10, 512, 32]);
  %337 = %333.1;
  %338 = reshape(%337, newshape=[-1, 512, 32]);
  %339 = transpose(%338, axes=[1, 0, 2]);
  %340 = transpose(%339, axes=[0, 2, 1]);
  %341 = transpose(%336, axes=[1, 0, 2]);
  %342 = transpose(%340, axes=[0, 2, 1]);
  %343 = nn.batch_matmul(%341, %342, transpose_b=True);
  %344 = nn.softmax(%343);
  %345 = nn.dropout(%344, rate=0.1f);
  %346 = %333.2;
  %347 = reshape(%346, newshape=[-1, 512, 32]);
  %348 = transpose(%347, axes=[1, 0, 2]);
  %349 = %345.0;
  %350 = transpose(%348, axes=[0, 2, 1]);
  %351 = nn.batch_matmul(%349, %350, transpose_b=True);
  %352 = transpose(%351, axes=[1, 0, 2]);
  %353 = reshape(%352, newshape=[10, 32, 512]);
  %354 = transpose(%encoder_layers_5_self_attn_out_proj_weight, axes=[1, 0]);
  %355 = reshape(%353, newshape=[-1, 512]);
  %356 = transpose(%354, axes=[1, 0]);
  %357 = nn.dense(%355, %356, units=None);
  %358 = reshape(%357, newshape=[10, 32, 512]);
  %359 = add(%358, %encoder_layers_5_self_attn_out_proj_bias);
  %360 = nn.dropout(%359, rate=0.1f);
  %361 = %360.0;
  %362 = add(%326, %361);
  %363 = nn.layer_norm(%362, %encoder_layers_5_norm1_weight, %encoder_layers_5_norm1_bias);
  %364 = transpose(%encoder_layers_5_linear1_weight, axes=[1, 0]);
  %365 = reshape(%363, newshape=[-1, 512]);
  %366 = transpose(%364, axes=[1, 0]);
  %367 = nn.dense(%365, %366, units=None);
  %368 = reshape(%367, newshape=[10, 32, 2048]);
  %369 = add(%368, %encoder_layers_5_linear1_bias);
  %370 = nn.relu(%369);
  %371 = nn.dropout(%370, rate=0.1f);
  %372 = %371.0;
  %373 = transpose(%encoder_layers_5_linear2_weight, axes=[1, 0]);
  %374 = reshape(%372, newshape=[-1, 2048]);
  %375 = transpose(%373, axes=[1, 0]);
  %376 = nn.dense(%374, %375, units=None);
  %377 = reshape(%376, newshape=[10, 32, 512]);
  %378 = add(%377, %encoder_layers_5_linear2_bias);
  %379 = nn.dropout(%378, rate=0.1f);
  %380 = %379.0;
  %381 = add(%363, %380);
  %382 = nn.layer_norm(%381, %encoder_layers_5_norm2_weight, %encoder_layers_5_norm2_bias);
  %383 = transpose(%encoder_layers_6_self_attn_in_proj_weight, axes=[1, 0]);
  %384 = reshape(%382, newshape=[-1, 512]);
  %385 = transpose(%383, axes=[1, 0]);
  %386 = nn.dense(%384, %385, units=None);
  %387 = reshape(%386, newshape=[10, 32, 1536]);
  %388 = add(%387, %encoder_layers_6_self_attn_in_proj_bias);
  %389 = split(%388, indices_or_sections=[512, 1024], axis=-1);
  %390 = %389.0;
  %391 = multiply(%390, 0.176777f);
  %392 = reshape(%391, newshape=[10, 512, 32]);
  %393 = %389.1;
  %394 = reshape(%393, newshape=[-1, 512, 32]);
  %395 = transpose(%394, axes=[1, 0, 2]);
  %396 = transpose(%395, axes=[0, 2, 1]);
  %397 = transpose(%392, axes=[1, 0, 2]);
  %398 = transpose(%396, axes=[0, 2, 1]);
  %399 = nn.batch_matmul(%397, %398, transpose_b=True);
  %400 = nn.softmax(%399);
  %401 = nn.dropout(%400, rate=0.1f);
  %402 = %389.2;
  %403 = reshape(%402, newshape=[-1, 512, 32]);
  %404 = transpose(%403, axes=[1, 0, 2]);
  %405 = %401.0;
  %406 = transpose(%404, axes=[0, 2, 1]);
  %407 = nn.batch_matmul(%405, %406, transpose_b=True);
  %408 = transpose(%407, axes=[1, 0, 2]);
  %409 = reshape(%408, newshape=[10, 32, 512]);
  %410 = transpose(%encoder_layers_6_self_attn_out_proj_weight, axes=[1, 0]);
  %411 = reshape(%409, newshape=[-1, 512]);
  %412 = transpose(%410, axes=[1, 0]);
  %413 = nn.dense(%411, %412, units=None);
  %414 = reshape(%413, newshape=[10, 32, 512]);
  %415 = add(%414, %encoder_layers_6_self_attn_out_proj_bias);
  %416 = nn.dropout(%415, rate=0.1f);
  %417 = %416.0;
  %418 = add(%382, %417);
  %419 = nn.layer_norm(%418, %encoder_layers_6_norm1_weight, %encoder_layers_6_norm1_bias);
  %420 = transpose(%encoder_layers_6_linear1_weight, axes=[1, 0]);
  %421 = reshape(%419, newshape=[-1, 512]);
  %422 = transpose(%420, axes=[1, 0]);
  %423 = nn.dense(%421, %422, units=None);
  %424 = reshape(%423, newshape=[10, 32, 2048]);
  %425 = add(%424, %encoder_layers_6_linear1_bias);
  %426 = nn.relu(%425);
  %427 = nn.dropout(%426, rate=0.1f);
  %428 = %427.0;
  %429 = transpose(%encoder_layers_6_linear2_weight, axes=[1, 0]);
  %430 = reshape(%428, newshape=[-1, 2048]);
  %431 = transpose(%429, axes=[1, 0]);
  %432 = nn.dense(%430, %431, units=None);
  %433 = reshape(%432, newshape=[10, 32, 512]);
  %434 = add(%433, %encoder_layers_6_linear2_bias);
  %435 = nn.dropout(%434, rate=0.1f);
  %436 = %435.0;
  %437 = add(%419, %436);
  %438 = nn.layer_norm(%437, %encoder_layers_6_norm2_weight, %encoder_layers_6_norm2_bias);
  %439 = transpose(%encoder_layers_7_self_attn_in_proj_weight, axes=[1, 0]);
  %440 = reshape(%438, newshape=[-1, 512]);
  %441 = transpose(%439, axes=[1, 0]);
  %442 = nn.dense(%440, %441, units=None);
  %443 = reshape(%442, newshape=[10, 32, 1536]);
  %444 = add(%443, %encoder_layers_7_self_attn_in_proj_bias);
  %445 = split(%444, indices_or_sections=[512, 1024], axis=-1);
  %446 = %445.0;
  %447 = multiply(%446, 0.176777f);
  %448 = reshape(%447, newshape=[10, 512, 32]);
  %449 = %445.1;
  %450 = reshape(%449, newshape=[-1, 512, 32]);
  %451 = transpose(%450, axes=[1, 0, 2]);
  %452 = transpose(%451, axes=[0, 2, 1]);
  %453 = transpose(%448, axes=[1, 0, 2]);
  %454 = transpose(%452, axes=[0, 2, 1]);
  %455 = nn.batch_matmul(%453, %454, transpose_b=True);
  %456 = nn.softmax(%455);
  %457 = nn.dropout(%456, rate=0.1f);
  %458 = %445.2;
  %459 = reshape(%458, newshape=[-1, 512, 32]);
  %460 = transpose(%459, axes=[1, 0, 2]);
  %461 = %457.0;
  %462 = transpose(%460, axes=[0, 2, 1]);
  %463 = nn.batch_matmul(%461, %462, transpose_b=True);
  %464 = transpose(%463, axes=[1, 0, 2]);
  %465 = reshape(%464, newshape=[10, 32, 512]);
  %466 = transpose(%encoder_layers_7_self_attn_out_proj_weight, axes=[1, 0]);
  %467 = reshape(%465, newshape=[-1, 512]);
  %468 = transpose(%466, axes=[1, 0]);
  %469 = nn.dense(%467, %468, units=None);
  %470 = reshape(%469, newshape=[10, 32, 512]);
  %471 = add(%470, %encoder_layers_7_self_attn_out_proj_bias);
  %472 = nn.dropout(%471, rate=0.1f);
  %473 = %472.0;
  %474 = add(%438, %473);
  %475 = nn.layer_norm(%474, %encoder_layers_7_norm1_weight, %encoder_layers_7_norm1_bias);
  %476 = transpose(%encoder_layers_7_linear1_weight, axes=[1, 0]);
  %477 = reshape(%475, newshape=[-1, 512]);
  %478 = transpose(%476, axes=[1, 0]);
  %479 = nn.dense(%477, %478, units=None);
  %480 = reshape(%479, newshape=[10, 32, 2048]);
  %481 = add(%480, %encoder_layers_7_linear1_bias);
  %482 = nn.relu(%481);
  %483 = nn.dropout(%482, rate=0.1f);
  %484 = %483.0;
  %485 = transpose(%encoder_layers_7_linear2_weight, axes=[1, 0]);
  %486 = reshape(%484, newshape=[-1, 2048]);
  %487 = transpose(%485, axes=[1, 0]);
  %488 = nn.dense(%486, %487, units=None);
  %489 = reshape(%488, newshape=[10, 32, 512]);
  %490 = add(%489, %encoder_layers_7_linear2_bias);
  %491 = nn.dropout(%490, rate=0.1f);
  %492 = %491.0;
  %493 = add(%475, %492);
  %494 = nn.layer_norm(%493, %encoder_layers_7_norm2_weight, %encoder_layers_7_norm2_bias);
  %495 = transpose(%encoder_layers_8_self_attn_in_proj_weight, axes=[1, 0]);
  %496 = reshape(%494, newshape=[-1, 512]);
  %497 = transpose(%495, axes=[1, 0]);
  %498 = nn.dense(%496, %497, units=None);
  %499 = reshape(%498, newshape=[10, 32, 1536]);
  %500 = add(%499, %encoder_layers_8_self_attn_in_proj_bias);
  %501 = split(%500, indices_or_sections=[512, 1024], axis=-1);
  %502 = %501.0;
  %503 = multiply(%502, 0.176777f);
  %504 = reshape(%503, newshape=[10, 512, 32]);
  %505 = %501.1;
  %506 = reshape(%505, newshape=[-1, 512, 32]);
  %507 = transpose(%506, axes=[1, 0, 2]);
  %508 = transpose(%507, axes=[0, 2, 1]);
  %509 = transpose(%504, axes=[1, 0, 2]);
  %510 = transpose(%508, axes=[0, 2, 1]);
  %511 = nn.batch_matmul(%509, %510, transpose_b=True);
  %512 = nn.softmax(%511);
  %513 = nn.dropout(%512, rate=0.1f);
  %514 = %501.2;
  %515 = reshape(%514, newshape=[-1, 512, 32]);
  %516 = transpose(%515, axes=[1, 0, 2]);
  %517 = %513.0;
  %518 = transpose(%516, axes=[0, 2, 1]);
  %519 = nn.batch_matmul(%517, %518, transpose_b=True);
  %520 = transpose(%519, axes=[1, 0, 2]);
  %521 = reshape(%520, newshape=[10, 32, 512]);
  %522 = transpose(%encoder_layers_8_self_attn_out_proj_weight, axes=[1, 0]);
  %523 = reshape(%521, newshape=[-1, 512]);
  %524 = transpose(%522, axes=[1, 0]);
  %525 = nn.dense(%523, %524, units=None);
  %526 = reshape(%525, newshape=[10, 32, 512]);
  %527 = add(%526, %encoder_layers_8_self_attn_out_proj_bias);
  %528 = nn.dropout(%527, rate=0.1f);
  %529 = %528.0;
  %530 = add(%494, %529);
  %531 = nn.layer_norm(%530, %encoder_layers_8_norm1_weight, %encoder_layers_8_norm1_bias);
  %532 = transpose(%encoder_layers_8_linear1_weight, axes=[1, 0]);
  %533 = reshape(%531, newshape=[-1, 512]);
  %534 = transpose(%532, axes=[1, 0]);
  %535 = nn.dense(%533, %534, units=None);
  %536 = reshape(%535, newshape=[10, 32, 2048]);
  %537 = add(%536, %encoder_layers_8_linear1_bias);
  %538 = nn.relu(%537);
  %539 = nn.dropout(%538, rate=0.1f);
  %540 = %539.0;
  %541 = transpose(%encoder_layers_8_linear2_weight, axes=[1, 0]);
  %542 = reshape(%540, newshape=[-1, 2048]);
  %543 = transpose(%541, axes=[1, 0]);
  %544 = nn.dense(%542, %543, units=None);
  %545 = reshape(%544, newshape=[10, 32, 512]);
  %546 = add(%545, %encoder_layers_8_linear2_bias);
  %547 = nn.dropout(%546, rate=0.1f);
  %548 = %547.0;
  %549 = add(%531, %548);
  %550 = nn.layer_norm(%549, %encoder_layers_8_norm2_weight, %encoder_layers_8_norm2_bias);
  %551 = transpose(%encoder_layers_9_self_attn_in_proj_weight, axes=[1, 0]);
  %552 = reshape(%550, newshape=[-1, 512]);
  %553 = transpose(%551, axes=[1, 0]);
  %554 = nn.dense(%552, %553, units=None);
  %555 = reshape(%554, newshape=[10, 32, 1536]);
  %556 = add(%555, %encoder_layers_9_self_attn_in_proj_bias);
  %557 = split(%556, indices_or_sections=[512, 1024], axis=-1);
  %558 = %557.0;
  %559 = multiply(%558, 0.176777f);
  %560 = reshape(%559, newshape=[10, 512, 32]);
  %561 = %557.1;
  %562 = reshape(%561, newshape=[-1, 512, 32]);
  %563 = transpose(%562, axes=[1, 0, 2]);
  %564 = transpose(%563, axes=[0, 2, 1]);
  %565 = transpose(%560, axes=[1, 0, 2]);
  %566 = transpose(%564, axes=[0, 2, 1]);
  %567 = nn.batch_matmul(%565, %566, transpose_b=True);
  %568 = nn.softmax(%567);
  %569 = nn.dropout(%568, rate=0.1f);
  %570 = %557.2;
  %571 = reshape(%570, newshape=[-1, 512, 32]);
  %572 = transpose(%571, axes=[1, 0, 2]);
  %573 = %569.0;
  %574 = transpose(%572, axes=[0, 2, 1]);
  %575 = nn.batch_matmul(%573, %574, transpose_b=True);
  %576 = transpose(%575, axes=[1, 0, 2]);
  %577 = reshape(%576, newshape=[10, 32, 512]);
  %578 = transpose(%encoder_layers_9_self_attn_out_proj_weight, axes=[1, 0]);
  %579 = reshape(%577, newshape=[-1, 512]);
  %580 = transpose(%578, axes=[1, 0]);
  %581 = nn.dense(%579, %580, units=None);
  %582 = reshape(%581, newshape=[10, 32, 512]);
  %583 = add(%582, %encoder_layers_9_self_attn_out_proj_bias);
  %584 = nn.dropout(%583, rate=0.1f);
  %585 = %584.0;
  %586 = add(%550, %585);
  %587 = nn.layer_norm(%586, %encoder_layers_9_norm1_weight, %encoder_layers_9_norm1_bias);
  %588 = transpose(%encoder_layers_9_linear1_weight, axes=[1, 0]);
  %589 = reshape(%587, newshape=[-1, 512]);
  %590 = transpose(%588, axes=[1, 0]);
  %591 = nn.dense(%589, %590, units=None);
  %592 = reshape(%591, newshape=[10, 32, 2048]);
  %593 = add(%592, %encoder_layers_9_linear1_bias);
  %594 = nn.relu(%593);
  %595 = nn.dropout(%594, rate=0.1f);
  %596 = %595.0;
  %597 = transpose(%encoder_layers_9_linear2_weight, axes=[1, 0]);
  %598 = reshape(%596, newshape=[-1, 2048]);
  %599 = transpose(%597, axes=[1, 0]);
  %600 = nn.dense(%598, %599, units=None);
  %601 = reshape(%600, newshape=[10, 32, 512]);
  %602 = add(%601, %encoder_layers_9_linear2_bias);
  %603 = nn.dropout(%602, rate=0.1f);
  %604 = %603.0;
  %605 = add(%587, %604);
  %606 = nn.layer_norm(%605, %encoder_layers_9_norm2_weight, %encoder_layers_9_norm2_bias);
  %607 = transpose(%encoder_layers_10_self_attn_in_proj_weight, axes=[1, 0]);
  %608 = reshape(%606, newshape=[-1, 512]);
  %609 = transpose(%607, axes=[1, 0]);
  %610 = nn.dense(%608, %609, units=None);
  %611 = reshape(%610, newshape=[10, 32, 1536]);
  %612 = add(%611, %encoder_layers_10_self_attn_in_proj_bias);
  %613 = split(%612, indices_or_sections=[512, 1024], axis=-1);
  %614 = %613.0;
  %615 = multiply(%614, 0.176777f);
  %616 = reshape(%615, newshape=[10, 512, 32]);
  %617 = %613.1;
  %618 = reshape(%617, newshape=[-1, 512, 32]);
  %619 = transpose(%618, axes=[1, 0, 2]);
  %620 = transpose(%619, axes=[0, 2, 1]);
  %621 = transpose(%616, axes=[1, 0, 2]);
  %622 = transpose(%620, axes=[0, 2, 1]);
  %623 = nn.batch_matmul(%621, %622, transpose_b=True);
  %624 = nn.softmax(%623);
  %625 = nn.dropout(%624, rate=0.1f);
  %626 = %613.2;
  %627 = reshape(%626, newshape=[-1, 512, 32]);
  %628 = transpose(%627, axes=[1, 0, 2]);
  %629 = %625.0;
  %630 = transpose(%628, axes=[0, 2, 1]);
  %631 = nn.batch_matmul(%629, %630, transpose_b=True);
  %632 = transpose(%631, axes=[1, 0, 2]);
  %633 = reshape(%632, newshape=[10, 32, 512]);
  %634 = transpose(%encoder_layers_10_self_attn_out_proj_weight, axes=[1, 0]);
  %635 = reshape(%633, newshape=[-1, 512]);
  %636 = transpose(%634, axes=[1, 0]);
  %637 = nn.dense(%635, %636, units=None);
  %638 = reshape(%637, newshape=[10, 32, 512]);
  %639 = add(%638, %encoder_layers_10_self_attn_out_proj_bias);
  %640 = nn.dropout(%639, rate=0.1f);
  %641 = %640.0;
  %642 = add(%606, %641);
  %643 = nn.layer_norm(%642, %encoder_layers_10_norm1_weight, %encoder_layers_10_norm1_bias);
  %644 = transpose(%encoder_layers_10_linear1_weight, axes=[1, 0]);
  %645 = reshape(%643, newshape=[-1, 512]);
  %646 = transpose(%644, axes=[1, 0]);
  %647 = nn.dense(%645, %646, units=None);
  %648 = reshape(%647, newshape=[10, 32, 2048]);
  %649 = add(%648, %encoder_layers_10_linear1_bias);
  %650 = nn.relu(%649);
  %651 = nn.dropout(%650, rate=0.1f);
  %652 = %651.0;
  %653 = transpose(%encoder_layers_10_linear2_weight, axes=[1, 0]);
  %654 = reshape(%652, newshape=[-1, 2048]);
  %655 = transpose(%653, axes=[1, 0]);
  %656 = nn.dense(%654, %655, units=None);
  %657 = reshape(%656, newshape=[10, 32, 512]);
  %658 = add(%657, %encoder_layers_10_linear2_bias);
  %659 = nn.dropout(%658, rate=0.1f);
  %660 = %659.0;
  %661 = add(%643, %660);
  %662 = nn.layer_norm(%661, %encoder_layers_10_norm2_weight, %encoder_layers_10_norm2_bias);
  %663 = transpose(%encoder_layers_11_self_attn_in_proj_weight, axes=[1, 0]);
  %664 = reshape(%662, newshape=[-1, 512]);
  %665 = transpose(%663, axes=[1, 0]);
  %666 = nn.dense(%664, %665, units=None);
  %667 = reshape(%666, newshape=[10, 32, 1536]);
  %668 = add(%667, %encoder_layers_11_self_attn_in_proj_bias);
  %669 = split(%668, indices_or_sections=[512, 1024], axis=-1);
  %670 = %669.0;
  %671 = multiply(%670, 0.176777f);
  %672 = reshape(%671, newshape=[10, 512, 32]);
  %673 = %669.1;
  %674 = reshape(%673, newshape=[-1, 512, 32]);
  %675 = transpose(%674, axes=[1, 0, 2]);
  %676 = transpose(%675, axes=[0, 2, 1]);
  %677 = transpose(%672, axes=[1, 0, 2]);
  %678 = transpose(%676, axes=[0, 2, 1]);
  %679 = nn.batch_matmul(%677, %678, transpose_b=True);
  %680 = nn.softmax(%679);
  %681 = nn.dropout(%680, rate=0.1f);
  %682 = %669.2;
  %683 = reshape(%682, newshape=[-1, 512, 32]);
  %684 = transpose(%683, axes=[1, 0, 2]);
  %685 = %681.0;
  %686 = transpose(%684, axes=[0, 2, 1]);
  %687 = nn.batch_matmul(%685, %686, transpose_b=True);
  %688 = transpose(%687, axes=[1, 0, 2]);
  %689 = reshape(%688, newshape=[10, 32, 512]);
  %690 = transpose(%encoder_layers_11_self_attn_out_proj_weight, axes=[1, 0]);
  %691 = reshape(%689, newshape=[-1, 512]);
  %692 = transpose(%690, axes=[1, 0]);
  %693 = nn.dense(%691, %692, units=None);
  %694 = reshape(%693, newshape=[10, 32, 512]);
  %695 = add(%694, %encoder_layers_11_self_attn_out_proj_bias);
  %696 = nn.dropout(%695, rate=0.1f);
  %697 = %696.0;
  %698 = add(%662, %697);
  %699 = nn.layer_norm(%698, %encoder_layers_11_norm1_weight, %encoder_layers_11_norm1_bias);
  %700 = transpose(%encoder_layers_11_linear1_weight, axes=[1, 0]);
  %701 = reshape(%699, newshape=[-1, 512]);
  %702 = transpose(%700, axes=[1, 0]);
  %703 = nn.dense(%701, %702, units=None);
  %704 = reshape(%703, newshape=[10, 32, 2048]);
  %705 = add(%704, %encoder_layers_11_linear1_bias);
  %706 = nn.relu(%705);
  %707 = nn.dropout(%706, rate=0.1f);
  %708 = %707.0;
  %709 = transpose(%encoder_layers_11_linear2_weight, axes=[1, 0]);
  %710 = reshape(%708, newshape=[-1, 2048]);
  %711 = transpose(%709, axes=[1, 0]);
  %712 = nn.dense(%710, %711, units=None);
  %713 = reshape(%712, newshape=[10, 32, 512]);
  %714 = add(%713, %encoder_layers_11_linear2_bias);
  %715 = nn.dropout(%714, rate=0.1f);
  %716 = %715.0;
  %717 = add(%699, %716);
  %718 = nn.layer_norm(%717, %encoder_layers_11_norm2_weight, %encoder_layers_11_norm2_bias);
  %719 = nn.layer_norm(%718, %encoder_norm_weight, %encoder_norm_bias);
  %720 = strided_slice(%decoder_layers_0_multihead_attn_in_proj_weight, begin=[512, 0], end=[1536, 512], strides=[1, 1], axes=None);
  %721 = transpose(%720, axes=[1, 0]);
  %722 = reshape(%719, newshape=[-1, 512]);
  %723 = transpose(%721, axes=[1, 0]);
  %724 = nn.dense(%722, %723, units=None);
  %725 = reshape(%724, newshape=[10, 32, 1024]);
  %726 = strided_slice(%decoder_layers_0_multihead_attn_in_proj_bias, begin=[512], end=[1536], strides=[1], axes=None);
  %727 = add(%725, %726);
  %728 = split(%727, indices_or_sections=[512], axis=-1);
  %729 = %728.0;
  %730 = reshape(%729, newshape=[-1, 512, 32]);
  %731 = transpose(%730, axes=[1, 0, 2]);
  %732 = transpose(%731, axes=[0, 2, 1]);
  %733 = transpose(%46, axes=[1, 0, 2]);
  %734 = transpose(%732, axes=[0, 2, 1]);
  %735 = nn.batch_matmul(%733, %734, transpose_b=True);
  %736 = nn.softmax(%735);
  %737 = nn.dropout(%736, rate=0.1f);
  %738 = %728.1;
  %739 = reshape(%738, newshape=[-1, 512, 32]);
  %740 = transpose(%739, axes=[1, 0, 2]);
  %741 = %737.0;
  %742 = transpose(%740, axes=[0, 2, 1]);
  %743 = nn.batch_matmul(%741, %742, transpose_b=True);
  %744 = transpose(%743, axes=[1, 0, 2]);
  %745 = reshape(%744, newshape=[20, 32, 512]);
  %746 = transpose(%decoder_layers_0_multihead_attn_out_proj_weight, axes=[1, 0]);
  %747 = reshape(%745, newshape=[-1, 512]);
  %748 = transpose(%746, axes=[1, 0]);
  %749 = nn.dense(%747, %748, units=None);
  %750 = reshape(%749, newshape=[20, 32, 512]);
  %751 = add(%750, %decoder_layers_0_multihead_attn_out_proj_bias);
  %752 = nn.dropout(%751, rate=0.1f);
  %753 = %752.0;
  %754 = add(%36, %753);
  %755 = nn.layer_norm(%754, %decoder_layers_0_norm2_weight, %decoder_layers_0_norm2_bias);
  %756 = transpose(%decoder_layers_0_linear1_weight, axes=[1, 0]);
  %757 = reshape(%755, newshape=[-1, 512]);
  %758 = transpose(%756, axes=[1, 0]);
  %759 = nn.dense(%757, %758, units=None);
  %760 = reshape(%759, newshape=[20, 32, 2048]);
  %761 = add(%760, %decoder_layers_0_linear1_bias);
  %762 = nn.relu(%761);
  %763 = nn.dropout(%762, rate=0.1f);
  %764 = %763.0;
  %765 = transpose(%decoder_layers_0_linear2_weight, axes=[1, 0]);
  %766 = reshape(%764, newshape=[-1, 2048]);
  %767 = transpose(%765, axes=[1, 0]);
  %768 = nn.dense(%766, %767, units=None);
  %769 = reshape(%768, newshape=[20, 32, 512]);
  %770 = add(%769, %decoder_layers_0_linear2_bias);
  %771 = nn.dropout(%770, rate=0.1f);
  %772 = %771.0;
  %773 = add(%755, %772);
  %774 = nn.layer_norm(%773, %decoder_layers_0_norm3_weight, %decoder_layers_0_norm3_bias);
  %775 = transpose(%decoder_layers_1_self_attn_in_proj_weight, axes=[1, 0]);
  %776 = reshape(%774, newshape=[-1, 512]);
  %777 = transpose(%775, axes=[1, 0]);
  %778 = nn.dense(%776, %777, units=None);
  %779 = reshape(%778, newshape=[20, 32, 1536]);
  %780 = add(%779, %decoder_layers_1_self_attn_in_proj_bias);
  %781 = split(%780, indices_or_sections=[512, 1024], axis=-1);
  %782 = %781.0;
  %783 = multiply(%782, 0.176777f);
  %784 = reshape(%783, newshape=[20, 512, 32]);
  %785 = %781.1;
  %786 = reshape(%785, newshape=[-1, 512, 32]);
  %787 = transpose(%786, axes=[1, 0, 2]);
  %788 = transpose(%787, axes=[0, 2, 1]);
  %789 = transpose(%784, axes=[1, 0, 2]);
  %790 = transpose(%788, axes=[0, 2, 1]);
  %791 = nn.batch_matmul(%789, %790, transpose_b=True);
  %792 = nn.softmax(%791);
  %793 = nn.dropout(%792, rate=0.1f);
  %794 = %781.2;
  %795 = reshape(%794, newshape=[-1, 512, 32]);
  %796 = transpose(%795, axes=[1, 0, 2]);
  %797 = %793.0;
  %798 = transpose(%796, axes=[0, 2, 1]);
  %799 = nn.batch_matmul(%797, %798, transpose_b=True);
  %800 = transpose(%799, axes=[1, 0, 2]);
  %801 = reshape(%800, newshape=[20, 32, 512]);
  %802 = transpose(%decoder_layers_1_self_attn_out_proj_weight, axes=[1, 0]);
  %803 = reshape(%801, newshape=[-1, 512]);
  %804 = transpose(%802, axes=[1, 0]);
  %805 = nn.dense(%803, %804, units=None);
  %806 = reshape(%805, newshape=[20, 32, 512]);
  %807 = add(%806, %decoder_layers_1_self_attn_out_proj_bias);
  %808 = nn.dropout(%807, rate=0.1f);
  %809 = %808.0;
  %810 = add(%774, %809);
  %811 = nn.layer_norm(%810, %decoder_layers_1_norm1_weight, %decoder_layers_1_norm1_bias);
  %812 = strided_slice(%decoder_layers_1_multihead_attn_in_proj_weight, begin=[0, 0], end=[512, 512], strides=[1, 1], axes=None);
  %813 = transpose(%812, axes=[1, 0]);
  %814 = reshape(%811, newshape=[-1, 512]);
  %815 = transpose(%813, axes=[1, 0]);
  %816 = nn.dense(%814, %815, units=None);
  %817 = reshape(%816, newshape=[20, 32, 512]);
  %818 = strided_slice(%decoder_layers_1_multihead_attn_in_proj_bias, begin=[0], end=[512], strides=[1], axes=None);
  %819 = add(%817, %818);
  %820 = multiply(%819, 0.176777f);
  %821 = reshape(%820, newshape=[20, 512, 32]);
  %822 = strided_slice(%decoder_layers_1_multihead_attn_in_proj_weight, begin=[512, 0], end=[1536, 512], strides=[1, 1], axes=None);
  %823 = transpose(%822, axes=[1, 0]);
  %824 = reshape(%719, newshape=[-1, 512]);
  %825 = transpose(%823, axes=[1, 0]);
  %826 = nn.dense(%824, %825, units=None);
  %827 = reshape(%826, newshape=[10, 32, 1024]);
  %828 = strided_slice(%decoder_layers_1_multihead_attn_in_proj_bias, begin=[512], end=[1536], strides=[1], axes=None);
  %829 = add(%827, %828);
  %830 = split(%829, indices_or_sections=[512], axis=-1);
  %831 = %830.0;
  %832 = reshape(%831, newshape=[-1, 512, 32]);
  %833 = transpose(%832, axes=[1, 0, 2]);
  %834 = transpose(%833, axes=[0, 2, 1]);
  %835 = transpose(%821, axes=[1, 0, 2]);
  %836 = transpose(%834, axes=[0, 2, 1]);
  %837 = nn.batch_matmul(%835, %836, transpose_b=True);
  %838 = nn.softmax(%837);
  %839 = nn.dropout(%838, rate=0.1f);
  %840 = %830.1;
  %841 = reshape(%840, newshape=[-1, 512, 32]);
  %842 = transpose(%841, axes=[1, 0, 2]);
  %843 = %839.0;
  %844 = transpose(%842, axes=[0, 2, 1]);
  %845 = nn.batch_matmul(%843, %844, transpose_b=True);
  %846 = transpose(%845, axes=[1, 0, 2]);
  %847 = reshape(%846, newshape=[20, 32, 512]);
  %848 = transpose(%decoder_layers_1_multihead_attn_out_proj_weight, axes=[1, 0]);
  %849 = reshape(%847, newshape=[-1, 512]);
  %850 = transpose(%848, axes=[1, 0]);
  %851 = nn.dense(%849, %850, units=None);
  %852 = reshape(%851, newshape=[20, 32, 512]);
  %853 = add(%852, %decoder_layers_1_multihead_attn_out_proj_bias);
  %854 = nn.dropout(%853, rate=0.1f);
  %855 = %854.0;
  %856 = add(%811, %855);
  %857 = nn.layer_norm(%856, %decoder_layers_1_norm2_weight, %decoder_layers_1_norm2_bias);
  %858 = transpose(%decoder_layers_1_linear1_weight, axes=[1, 0]);
  %859 = reshape(%857, newshape=[-1, 512]);
  %860 = transpose(%858, axes=[1, 0]);
  %861 = nn.dense(%859, %860, units=None);
  %862 = reshape(%861, newshape=[20, 32, 2048]);
  %863 = add(%862, %decoder_layers_1_linear1_bias);
  %864 = nn.relu(%863);
  %865 = nn.dropout(%864, rate=0.1f);
  %866 = %865.0;
  %867 = transpose(%decoder_layers_1_linear2_weight, axes=[1, 0]);
  %868 = reshape(%866, newshape=[-1, 2048]);
  %869 = transpose(%867, axes=[1, 0]);
  %870 = nn.dense(%868, %869, units=None);
  %871 = reshape(%870, newshape=[20, 32, 512]);
  %872 = add(%871, %decoder_layers_1_linear2_bias);
  %873 = nn.dropout(%872, rate=0.1f);
  %874 = %873.0;
  %875 = add(%857, %874);
  %876 = nn.layer_norm(%875, %decoder_layers_1_norm3_weight, %decoder_layers_1_norm3_bias);
  %877 = transpose(%decoder_layers_2_self_attn_in_proj_weight, axes=[1, 0]);
  %878 = reshape(%876, newshape=[-1, 512]);
  %879 = transpose(%877, axes=[1, 0]);
  %880 = nn.dense(%878, %879, units=None);
  %881 = reshape(%880, newshape=[20, 32, 1536]);
  %882 = add(%881, %decoder_layers_2_self_attn_in_proj_bias);
  %883 = split(%882, indices_or_sections=[512, 1024], axis=-1);
  %884 = %883.0;
  %885 = multiply(%884, 0.176777f);
  %886 = reshape(%885, newshape=[20, 512, 32]);
  %887 = %883.1;
  %888 = reshape(%887, newshape=[-1, 512, 32]);
  %889 = transpose(%888, axes=[1, 0, 2]);
  %890 = transpose(%889, axes=[0, 2, 1]);
  %891 = transpose(%886, axes=[1, 0, 2]);
  %892 = transpose(%890, axes=[0, 2, 1]);
  %893 = nn.batch_matmul(%891, %892, transpose_b=True);
  %894 = nn.softmax(%893);
  %895 = nn.dropout(%894, rate=0.1f);
  %896 = %883.2;
  %897 = reshape(%896, newshape=[-1, 512, 32]);
  %898 = transpose(%897, axes=[1, 0, 2]);
  %899 = %895.0;
  %900 = transpose(%898, axes=[0, 2, 1]);
  %901 = nn.batch_matmul(%899, %900, transpose_b=True);
  %902 = transpose(%901, axes=[1, 0, 2]);
  %903 = reshape(%902, newshape=[20, 32, 512]);
  %904 = transpose(%decoder_layers_2_self_attn_out_proj_weight, axes=[1, 0]);
  %905 = reshape(%903, newshape=[-1, 512]);
  %906 = transpose(%904, axes=[1, 0]);
  %907 = nn.dense(%905, %906, units=None);
  %908 = reshape(%907, newshape=[20, 32, 512]);
  %909 = add(%908, %decoder_layers_2_self_attn_out_proj_bias);
  %910 = nn.dropout(%909, rate=0.1f);
  %911 = %910.0;
  %912 = add(%876, %911);
  %913 = nn.layer_norm(%912, %decoder_layers_2_norm1_weight, %decoder_layers_2_norm1_bias);
  %914 = strided_slice(%decoder_layers_2_multihead_attn_in_proj_weight, begin=[0, 0], end=[512, 512], strides=[1, 1], axes=None);
  %915 = transpose(%914, axes=[1, 0]);
  %916 = reshape(%913, newshape=[-1, 512]);
  %917 = transpose(%915, axes=[1, 0]);
  %918 = nn.dense(%916, %917, units=None);
  %919 = reshape(%918, newshape=[20, 32, 512]);
  %920 = strided_slice(%decoder_layers_2_multihead_attn_in_proj_bias, begin=[0], end=[512], strides=[1], axes=None);
  %921 = add(%919, %920);
  %922 = multiply(%921, 0.176777f);
  %923 = reshape(%922, newshape=[20, 512, 32]);
  %924 = strided_slice(%decoder_layers_2_multihead_attn_in_proj_weight, begin=[512, 0], end=[1536, 512], strides=[1, 1], axes=None);
  %925 = transpose(%924, axes=[1, 0]);
  %926 = reshape(%719, newshape=[-1, 512]);
  %927 = transpose(%925, axes=[1, 0]);
  %928 = nn.dense(%926, %927, units=None);
  %929 = reshape(%928, newshape=[10, 32, 1024]);
  %930 = strided_slice(%decoder_layers_2_multihead_attn_in_proj_bias, begin=[512], end=[1536], strides=[1], axes=None);
  %931 = add(%929, %930);
  %932 = split(%931, indices_or_sections=[512], axis=-1);
  %933 = %932.0;
  %934 = reshape(%933, newshape=[-1, 512, 32]);
  %935 = transpose(%934, axes=[1, 0, 2]);
  %936 = transpose(%935, axes=[0, 2, 1]);
  %937 = transpose(%923, axes=[1, 0, 2]);
  %938 = transpose(%936, axes=[0, 2, 1]);
  %939 = nn.batch_matmul(%937, %938, transpose_b=True);
  %940 = nn.softmax(%939);
  %941 = nn.dropout(%940, rate=0.1f);
  %942 = %932.1;
  %943 = reshape(%942, newshape=[-1, 512, 32]);
  %944 = transpose(%943, axes=[1, 0, 2]);
  %945 = %941.0;
  %946 = transpose(%944, axes=[0, 2, 1]);
  %947 = nn.batch_matmul(%945, %946, transpose_b=True);
  %948 = transpose(%947, axes=[1, 0, 2]);
  %949 = reshape(%948, newshape=[20, 32, 512]);
  %950 = transpose(%decoder_layers_2_multihead_attn_out_proj_weight, axes=[1, 0]);
  %951 = reshape(%949, newshape=[-1, 512]);
  %952 = transpose(%950, axes=[1, 0]);
  %953 = nn.dense(%951, %952, units=None);
  %954 = reshape(%953, newshape=[20, 32, 512]);
  %955 = add(%954, %decoder_layers_2_multihead_attn_out_proj_bias);
  %956 = nn.dropout(%955, rate=0.1f);
  %957 = %956.0;
  %958 = add(%913, %957);
  %959 = nn.layer_norm(%958, %decoder_layers_2_norm2_weight, %decoder_layers_2_norm2_bias);
  %960 = transpose(%decoder_layers_2_linear1_weight, axes=[1, 0]);
  %961 = reshape(%959, newshape=[-1, 512]);
  %962 = transpose(%960, axes=[1, 0]);
  %963 = nn.dense(%961, %962, units=None);
  %964 = reshape(%963, newshape=[20, 32, 2048]);
  %965 = add(%964, %decoder_layers_2_linear1_bias);
  %966 = nn.relu(%965);
  %967 = nn.dropout(%966, rate=0.1f);
  %968 = %967.0;
  %969 = transpose(%decoder_layers_2_linear2_weight, axes=[1, 0]);
  %970 = reshape(%968, newshape=[-1, 2048]);
  %971 = transpose(%969, axes=[1, 0]);
  %972 = nn.dense(%970, %971, units=None);
  %973 = reshape(%972, newshape=[20, 32, 512]);
  %974 = add(%973, %decoder_layers_2_linear2_bias);
  %975 = nn.dropout(%974, rate=0.1f);
  %976 = %975.0;
  %977 = add(%959, %976);
  %978 = nn.layer_norm(%977, %decoder_layers_2_norm3_weight, %decoder_layers_2_norm3_bias);
  %979 = transpose(%decoder_layers_3_self_attn_in_proj_weight, axes=[1, 0]);
  %980 = reshape(%978, newshape=[-1, 512]);
  %981 = transpose(%979, axes=[1, 0]);
  %982 = nn.dense(%980, %981, units=None);
  %983 = reshape(%982, newshape=[20, 32, 1536]);
  %984 = add(%983, %decoder_layers_3_self_attn_in_proj_bias);
  %985 = split(%984, indices_or_sections=[512, 1024], axis=-1);
  %986 = %985.0;
  %987 = multiply(%986, 0.176777f);
  %988 = reshape(%987, newshape=[20, 512, 32]);
  %989 = %985.1;
  %990 = reshape(%989, newshape=[-1, 512, 32]);
  %991 = transpose(%990, axes=[1, 0, 2]);
  %992 = transpose(%991, axes=[0, 2, 1]);
  %993 = transpose(%988, axes=[1, 0, 2]);
  %994 = transpose(%992, axes=[0, 2, 1]);
  %995 = nn.batch_matmul(%993, %994, transpose_b=True);
  %996 = nn.softmax(%995);
  %997 = nn.dropout(%996, rate=0.1f);
  %998 = %985.2;
  %999 = reshape(%998, newshape=[-1, 512, 32]);
  %1000 = transpose(%999, axes=[1, 0, 2]);
  %1001 = %997.0;
  %1002 = transpose(%1000, axes=[0, 2, 1]);
  %1003 = nn.batch_matmul(%1001, %1002, transpose_b=True);
  %1004 = transpose(%1003, axes=[1, 0, 2]);
  %1005 = reshape(%1004, newshape=[20, 32, 512]);
  %1006 = transpose(%decoder_layers_3_self_attn_out_proj_weight, axes=[1, 0]);
  %1007 = reshape(%1005, newshape=[-1, 512]);
  %1008 = transpose(%1006, axes=[1, 0]);
  %1009 = nn.dense(%1007, %1008, units=None);
  %1010 = reshape(%1009, newshape=[20, 32, 512]);
  %1011 = add(%1010, %decoder_layers_3_self_attn_out_proj_bias);
  %1012 = nn.dropout(%1011, rate=0.1f);
  %1013 = %1012.0;
  %1014 = add(%978, %1013);
  %1015 = nn.layer_norm(%1014, %decoder_layers_3_norm1_weight, %decoder_layers_3_norm1_bias);
  %1016 = strided_slice(%decoder_layers_3_multihead_attn_in_proj_weight, begin=[0, 0], end=[512, 512], strides=[1, 1], axes=None);
  %1017 = transpose(%1016, axes=[1, 0]);
  %1018 = reshape(%1015, newshape=[-1, 512]);
  %1019 = transpose(%1017, axes=[1, 0]);
  %1020 = nn.dense(%1018, %1019, units=None);
  %1021 = reshape(%1020, newshape=[20, 32, 512]);
  %1022 = strided_slice(%decoder_layers_3_multihead_attn_in_proj_bias, begin=[0], end=[512], strides=[1], axes=None);
  %1023 = add(%1021, %1022);
  %1024 = multiply(%1023, 0.176777f);
  %1025 = reshape(%1024, newshape=[20, 512, 32]);
  %1026 = strided_slice(%decoder_layers_3_multihead_attn_in_proj_weight, begin=[512, 0], end=[1536, 512], strides=[1, 1], axes=None);
  %1027 = transpose(%1026, axes=[1, 0]);
  %1028 = reshape(%719, newshape=[-1, 512]);
  %1029 = transpose(%1027, axes=[1, 0]);
  %1030 = nn.dense(%1028, %1029, units=None);
  %1031 = reshape(%1030, newshape=[10, 32, 1024]);
  %1032 = strided_slice(%decoder_layers_3_multihead_attn_in_proj_bias, begin=[512], end=[1536], strides=[1], axes=None);
  %1033 = add(%1031, %1032);
  %1034 = split(%1033, indices_or_sections=[512], axis=-1);
  %1035 = %1034.0;
  %1036 = reshape(%1035, newshape=[-1, 512, 32]);
  %1037 = transpose(%1036, axes=[1, 0, 2]);
  %1038 = transpose(%1037, axes=[0, 2, 1]);
  %1039 = transpose(%1025, axes=[1, 0, 2]);
  %1040 = transpose(%1038, axes=[0, 2, 1]);
  %1041 = nn.batch_matmul(%1039, %1040, transpose_b=True);
  %1042 = nn.softmax(%1041);
  %1043 = nn.dropout(%1042, rate=0.1f);
  %1044 = %1034.1;
  %1045 = reshape(%1044, newshape=[-1, 512, 32]);
  %1046 = transpose(%1045, axes=[1, 0, 2]);
  %1047 = %1043.0;
  %1048 = transpose(%1046, axes=[0, 2, 1]);
  %1049 = nn.batch_matmul(%1047, %1048, transpose_b=True);
  %1050 = transpose(%1049, axes=[1, 0, 2]);
  %1051 = reshape(%1050, newshape=[20, 32, 512]);
  %1052 = transpose(%decoder_layers_3_multihead_attn_out_proj_weight, axes=[1, 0]);
  %1053 = reshape(%1051, newshape=[-1, 512]);
  %1054 = transpose(%1052, axes=[1, 0]);
  %1055 = nn.dense(%1053, %1054, units=None);
  %1056 = reshape(%1055, newshape=[20, 32, 512]);
  %1057 = add(%1056, %decoder_layers_3_multihead_attn_out_proj_bias);
  %1058 = nn.dropout(%1057, rate=0.1f);
  %1059 = %1058.0;
  %1060 = add(%1015, %1059);
  %1061 = nn.layer_norm(%1060, %decoder_layers_3_norm2_weight, %decoder_layers_3_norm2_bias);
  %1062 = transpose(%decoder_layers_3_linear1_weight, axes=[1, 0]);
  %1063 = reshape(%1061, newshape=[-1, 512]);
  %1064 = transpose(%1062, axes=[1, 0]);
  %1065 = nn.dense(%1063, %1064, units=None);
  %1066 = reshape(%1065, newshape=[20, 32, 2048]);
  %1067 = add(%1066, %decoder_layers_3_linear1_bias);
  %1068 = nn.relu(%1067);
  %1069 = nn.dropout(%1068, rate=0.1f);
  %1070 = %1069.0;
  %1071 = transpose(%decoder_layers_3_linear2_weight, axes=[1, 0]);
  %1072 = reshape(%1070, newshape=[-1, 2048]);
  %1073 = transpose(%1071, axes=[1, 0]);
  %1074 = nn.dense(%1072, %1073, units=None);
  %1075 = reshape(%1074, newshape=[20, 32, 512]);
  %1076 = add(%1075, %decoder_layers_3_linear2_bias);
  %1077 = nn.dropout(%1076, rate=0.1f);
  %1078 = %1077.0;
  %1079 = add(%1061, %1078);
  %1080 = nn.layer_norm(%1079, %decoder_layers_3_norm3_weight, %decoder_layers_3_norm3_bias);
  %1081 = transpose(%decoder_layers_4_self_attn_in_proj_weight, axes=[1, 0]);
  %1082 = reshape(%1080, newshape=[-1, 512]);
  %1083 = transpose(%1081, axes=[1, 0]);
  %1084 = nn.dense(%1082, %1083, units=None);
  %1085 = reshape(%1084, newshape=[20, 32, 1536]);
  %1086 = add(%1085, %decoder_layers_4_self_attn_in_proj_bias);
  %1087 = split(%1086, indices_or_sections=[512, 1024], axis=-1);
  %1088 = %1087.0;
  %1089 = multiply(%1088, 0.176777f);
  %1090 = reshape(%1089, newshape=[20, 512, 32]);
  %1091 = %1087.1;
  %1092 = reshape(%1091, newshape=[-1, 512, 32]);
  %1093 = transpose(%1092, axes=[1, 0, 2]);
  %1094 = transpose(%1093, axes=[0, 2, 1]);
  %1095 = transpose(%1090, axes=[1, 0, 2]);
  %1096 = transpose(%1094, axes=[0, 2, 1]);
  %1097 = nn.batch_matmul(%1095, %1096, transpose_b=True);
  %1098 = nn.softmax(%1097);
  %1099 = nn.dropout(%1098, rate=0.1f);
  %1100 = %1087.2;
  %1101 = reshape(%1100, newshape=[-1, 512, 32]);
  %1102 = transpose(%1101, axes=[1, 0, 2]);
  %1103 = %1099.0;
  %1104 = transpose(%1102, axes=[0, 2, 1]);
  %1105 = nn.batch_matmul(%1103, %1104, transpose_b=True);
  %1106 = transpose(%1105, axes=[1, 0, 2]);
  %1107 = reshape(%1106, newshape=[20, 32, 512]);
  %1108 = transpose(%decoder_layers_4_self_attn_out_proj_weight, axes=[1, 0]);
  %1109 = reshape(%1107, newshape=[-1, 512]);
  %1110 = transpose(%1108, axes=[1, 0]);
  %1111 = nn.dense(%1109, %1110, units=None);
  %1112 = reshape(%1111, newshape=[20, 32, 512]);
  %1113 = add(%1112, %decoder_layers_4_self_attn_out_proj_bias);
  %1114 = nn.dropout(%1113, rate=0.1f);
  %1115 = %1114.0;
  %1116 = add(%1080, %1115);
  %1117 = nn.layer_norm(%1116, %decoder_layers_4_norm1_weight, %decoder_layers_4_norm1_bias);
  %1118 = strided_slice(%decoder_layers_4_multihead_attn_in_proj_weight, begin=[0, 0], end=[512, 512], strides=[1, 1], axes=None);
  %1119 = transpose(%1118, axes=[1, 0]);
  %1120 = reshape(%1117, newshape=[-1, 512]);
  %1121 = transpose(%1119, axes=[1, 0]);
  %1122 = nn.dense(%1120, %1121, units=None);
  %1123 = reshape(%1122, newshape=[20, 32, 512]);
  %1124 = strided_slice(%decoder_layers_4_multihead_attn_in_proj_bias, begin=[0], end=[512], strides=[1], axes=None);
  %1125 = add(%1123, %1124);
  %1126 = multiply(%1125, 0.176777f);
  %1127 = reshape(%1126, newshape=[20, 512, 32]);
  %1128 = strided_slice(%decoder_layers_4_multihead_attn_in_proj_weight, begin=[512, 0], end=[1536, 512], strides=[1, 1], axes=None);
  %1129 = transpose(%1128, axes=[1, 0]);
  %1130 = reshape(%719, newshape=[-1, 512]);
  %1131 = transpose(%1129, axes=[1, 0]);
  %1132 = nn.dense(%1130, %1131, units=None);
  %1133 = reshape(%1132, newshape=[10, 32, 1024]);
  %1134 = strided_slice(%decoder_layers_4_multihead_attn_in_proj_bias, begin=[512], end=[1536], strides=[1], axes=None);
  %1135 = add(%1133, %1134);
  %1136 = split(%1135, indices_or_sections=[512], axis=-1);
  %1137 = %1136.0;
  %1138 = reshape(%1137, newshape=[-1, 512, 32]);
  %1139 = transpose(%1138, axes=[1, 0, 2]);
  %1140 = transpose(%1139, axes=[0, 2, 1]);
  %1141 = transpose(%1127, axes=[1, 0, 2]);
  %1142 = transpose(%1140, axes=[0, 2, 1]);
  %1143 = nn.batch_matmul(%1141, %1142, transpose_b=True);
  %1144 = nn.softmax(%1143);
  %1145 = nn.dropout(%1144, rate=0.1f);
  %1146 = %1136.1;
  %1147 = reshape(%1146, newshape=[-1, 512, 32]);
  %1148 = transpose(%1147, axes=[1, 0, 2]);
  %1149 = %1145.0;
  %1150 = transpose(%1148, axes=[0, 2, 1]);
  %1151 = nn.batch_matmul(%1149, %1150, transpose_b=True);
  %1152 = transpose(%1151, axes=[1, 0, 2]);
  %1153 = reshape(%1152, newshape=[20, 32, 512]);
  %1154 = transpose(%decoder_layers_4_multihead_attn_out_proj_weight, axes=[1, 0]);
  %1155 = reshape(%1153, newshape=[-1, 512]);
  %1156 = transpose(%1154, axes=[1, 0]);
  %1157 = nn.dense(%1155, %1156, units=None);
  %1158 = reshape(%1157, newshape=[20, 32, 512]);
  %1159 = add(%1158, %decoder_layers_4_multihead_attn_out_proj_bias);
  %1160 = nn.dropout(%1159, rate=0.1f);
  %1161 = %1160.0;
  %1162 = add(%1117, %1161);
  %1163 = nn.layer_norm(%1162, %decoder_layers_4_norm2_weight, %decoder_layers_4_norm2_bias);
  %1164 = transpose(%decoder_layers_4_linear1_weight, axes=[1, 0]);
  %1165 = reshape(%1163, newshape=[-1, 512]);
  %1166 = transpose(%1164, axes=[1, 0]);
  %1167 = nn.dense(%1165, %1166, units=None);
  %1168 = reshape(%1167, newshape=[20, 32, 2048]);
  %1169 = add(%1168, %decoder_layers_4_linear1_bias);
  %1170 = nn.relu(%1169);
  %1171 = nn.dropout(%1170, rate=0.1f);
  %1172 = %1171.0;
  %1173 = transpose(%decoder_layers_4_linear2_weight, axes=[1, 0]);
  %1174 = reshape(%1172, newshape=[-1, 2048]);
  %1175 = transpose(%1173, axes=[1, 0]);
  %1176 = nn.dense(%1174, %1175, units=None);
  %1177 = reshape(%1176, newshape=[20, 32, 512]);
  %1178 = add(%1177, %decoder_layers_4_linear2_bias);
  %1179 = nn.dropout(%1178, rate=0.1f);
  %1180 = %1179.0;
  %1181 = add(%1163, %1180);
  %1182 = nn.layer_norm(%1181, %decoder_layers_4_norm3_weight, %decoder_layers_4_norm3_bias);
  %1183 = transpose(%decoder_layers_5_self_attn_in_proj_weight, axes=[1, 0]);
  %1184 = reshape(%1182, newshape=[-1, 512]);
  %1185 = transpose(%1183, axes=[1, 0]);
  %1186 = nn.dense(%1184, %1185, units=None);
  %1187 = reshape(%1186, newshape=[20, 32, 1536]);
  %1188 = add(%1187, %decoder_layers_5_self_attn_in_proj_bias);
  %1189 = split(%1188, indices_or_sections=[512, 1024], axis=-1);
  %1190 = %1189.0;
  %1191 = multiply(%1190, 0.176777f);
  %1192 = reshape(%1191, newshape=[20, 512, 32]);
  %1193 = %1189.1;
  %1194 = reshape(%1193, newshape=[-1, 512, 32]);
  %1195 = transpose(%1194, axes=[1, 0, 2]);
  %1196 = transpose(%1195, axes=[0, 2, 1]);
  %1197 = transpose(%1192, axes=[1, 0, 2]);
  %1198 = transpose(%1196, axes=[0, 2, 1]);
  %1199 = nn.batch_matmul(%1197, %1198, transpose_b=True);
  %1200 = nn.softmax(%1199);
  %1201 = nn.dropout(%1200, rate=0.1f);
  %1202 = %1189.2;
  %1203 = reshape(%1202, newshape=[-1, 512, 32]);
  %1204 = transpose(%1203, axes=[1, 0, 2]);
  %1205 = %1201.0;
  %1206 = transpose(%1204, axes=[0, 2, 1]);
  %1207 = nn.batch_matmul(%1205, %1206, transpose_b=True);
  %1208 = transpose(%1207, axes=[1, 0, 2]);
  %1209 = reshape(%1208, newshape=[20, 32, 512]);
  %1210 = transpose(%decoder_layers_5_self_attn_out_proj_weight, axes=[1, 0]);
  %1211 = reshape(%1209, newshape=[-1, 512]);
  %1212 = transpose(%1210, axes=[1, 0]);
  %1213 = nn.dense(%1211, %1212, units=None);
  %1214 = reshape(%1213, newshape=[20, 32, 512]);
  %1215 = add(%1214, %decoder_layers_5_self_attn_out_proj_bias);
  %1216 = nn.dropout(%1215, rate=0.1f);
  %1217 = %1216.0;
  %1218 = add(%1182, %1217);
  %1219 = nn.layer_norm(%1218, %decoder_layers_5_norm1_weight, %decoder_layers_5_norm1_bias);
  %1220 = strided_slice(%decoder_layers_5_multihead_attn_in_proj_weight, begin=[0, 0], end=[512, 512], strides=[1, 1], axes=None);
  %1221 = transpose(%1220, axes=[1, 0]);
  %1222 = reshape(%1219, newshape=[-1, 512]);
  %1223 = transpose(%1221, axes=[1, 0]);
  %1224 = nn.dense(%1222, %1223, units=None);
  %1225 = reshape(%1224, newshape=[20, 32, 512]);
  %1226 = strided_slice(%decoder_layers_5_multihead_attn_in_proj_bias, begin=[0], end=[512], strides=[1], axes=None);
  %1227 = add(%1225, %1226);
  %1228 = multiply(%1227, 0.176777f);
  %1229 = reshape(%1228, newshape=[20, 512, 32]);
  %1230 = strided_slice(%decoder_layers_5_multihead_attn_in_proj_weight, begin=[512, 0], end=[1536, 512], strides=[1, 1], axes=None);
  %1231 = transpose(%1230, axes=[1, 0]);
  %1232 = reshape(%719, newshape=[-1, 512]);
  %1233 = transpose(%1231, axes=[1, 0]);
  %1234 = nn.dense(%1232, %1233, units=None);
  %1235 = reshape(%1234, newshape=[10, 32, 1024]);
  %1236 = strided_slice(%decoder_layers_5_multihead_attn_in_proj_bias, begin=[512], end=[1536], strides=[1], axes=None);
  %1237 = add(%1235, %1236);
  %1238 = split(%1237, indices_or_sections=[512], axis=-1);
  %1239 = %1238.0;
  %1240 = reshape(%1239, newshape=[-1, 512, 32]);
  %1241 = transpose(%1240, axes=[1, 0, 2]);
  %1242 = transpose(%1241, axes=[0, 2, 1]);
  %1243 = transpose(%1229, axes=[1, 0, 2]);
  %1244 = transpose(%1242, axes=[0, 2, 1]);
  %1245 = nn.batch_matmul(%1243, %1244, transpose_b=True);
  %1246 = nn.softmax(%1245);
  %1247 = nn.dropout(%1246, rate=0.1f);
  %1248 = %1238.1;
  %1249 = reshape(%1248, newshape=[-1, 512, 32]);
  %1250 = transpose(%1249, axes=[1, 0, 2]);
  %1251 = %1247.0;
  %1252 = transpose(%1250, axes=[0, 2, 1]);
  %1253 = nn.batch_matmul(%1251, %1252, transpose_b=True);
  %1254 = transpose(%1253, axes=[1, 0, 2]);
  %1255 = reshape(%1254, newshape=[20, 32, 512]);
  %1256 = transpose(%decoder_layers_5_multihead_attn_out_proj_weight, axes=[1, 0]);
  %1257 = reshape(%1255, newshape=[-1, 512]);
  %1258 = transpose(%1256, axes=[1, 0]);
  %1259 = nn.dense(%1257, %1258, units=None);
  %1260 = reshape(%1259, newshape=[20, 32, 512]);
  %1261 = add(%1260, %decoder_layers_5_multihead_attn_out_proj_bias);
  %1262 = nn.dropout(%1261, rate=0.1f);
  %1263 = %1262.0;
  %1264 = add(%1219, %1263);
  %1265 = nn.layer_norm(%1264, %decoder_layers_5_norm2_weight, %decoder_layers_5_norm2_bias);
  %1266 = transpose(%decoder_layers_5_linear1_weight, axes=[1, 0]);
  %1267 = reshape(%1265, newshape=[-1, 512]);
  %1268 = transpose(%1266, axes=[1, 0]);
  %1269 = nn.dense(%1267, %1268, units=None);
  %1270 = reshape(%1269, newshape=[20, 32, 2048]);
  %1271 = add(%1270, %decoder_layers_5_linear1_bias);
  %1272 = nn.relu(%1271);
  %1273 = nn.dropout(%1272, rate=0.1f);
  %1274 = %1273.0;
  %1275 = transpose(%decoder_layers_5_linear2_weight, axes=[1, 0]);
  %1276 = reshape(%1274, newshape=[-1, 2048]);
  %1277 = transpose(%1275, axes=[1, 0]);
  %1278 = nn.dense(%1276, %1277, units=None);
  %1279 = reshape(%1278, newshape=[20, 32, 512]);
  %1280 = add(%1279, %decoder_layers_5_linear2_bias);
  %1281 = nn.dropout(%1280, rate=0.1f);
  %1282 = %1281.0;
  %1283 = add(%1265, %1282);
  %1284 = nn.layer_norm(%1283, %decoder_layers_5_norm3_weight, %decoder_layers_5_norm3_bias);
  nn.layer_norm(%1284, %decoder_norm_weight, %decoder_norm_bias)
}
